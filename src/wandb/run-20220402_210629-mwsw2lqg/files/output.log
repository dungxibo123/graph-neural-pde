GrandExtendDiscritizedNet
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
mol_list.0.alpha_train
torch.Size([])
mol_list.0.beta_train
torch.Size([])
mol_list.0.alpha_sc
torch.Size([1])
mol_list.0.beta_sc
torch.Size([1])
mol_list.0.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.0.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.V.bias
torch.Size([128])
mol_list.0.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.K.bias
torch.Size([128])
mol_list.0.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.0.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.1.alpha_train
torch.Size([])
mol_list.1.beta_train
torch.Size([])
mol_list.1.alpha_sc
torch.Size([1])
mol_list.1.beta_sc
torch.Size([1])
mol_list.1.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.1.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.V.bias
torch.Size([128])
mol_list.1.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.K.bias
torch.Size([128])
mol_list.1.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.1.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.2.alpha_train
torch.Size([])
mol_list.2.beta_train
torch.Size([])
mol_list.2.alpha_sc
torch.Size([1])
mol_list.2.beta_sc
torch.Size([1])
mol_list.2.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.2.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.V.bias
torch.Size([128])
mol_list.2.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.K.bias
torch.Size([128])
mol_list.2.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.2.multihead_att_layer.Wout.bias
torch.Size([80])
  0%|                                      | 0/100 [00:00<?, ?it/s]
Epoch: 001, Runtime 1.456755, Loss 5842.557617, Train: 0.3086, Val: 0.1266, Test: 0.1629, Best time: 18.2948
Epoch: 002, Runtime 0.026875, Loss 5395572337389143051993088.000000, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 003, Runtime 0.028525, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 004, Runtime 0.025391, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 005, Runtime 0.037826, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 006, Runtime 0.024929, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 007, Runtime 0.023716, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 008, Runtime 0.027602, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 009, Runtime 0.032163, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 010, Runtime 0.025157, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 011, Runtime 0.023996, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 012, Runtime 0.023691, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 013, Runtime 0.025393, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 014, Runtime 0.029253, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 015, Runtime 0.028173, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 016, Runtime 0.024547, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 017, Runtime 0.023744, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 018, Runtime 0.024637, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 019, Runtime 0.025335, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 020, Runtime 0.026319, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 021, Runtime 0.026955, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 022, Runtime 0.026669, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 023, Runtime 0.025492, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 024, Runtime 0.041861, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 025, Runtime 0.028874, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 026, Runtime 0.025687, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 027, Runtime 0.024643, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 028, Runtime 0.028697, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 029, Runtime 0.030300, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 030, Runtime 0.029921, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 031, Runtime 0.029957, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 032, Runtime 0.022909, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 033, Runtime 0.029202, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 034, Runtime 0.023824, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 035, Runtime 0.023814, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 036, Runtime 0.035250, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 037, Runtime 0.027438, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 038, Runtime 0.025319, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 039, Runtime 0.024924, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 040, Runtime 0.024953, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 041, Runtime 0.028346, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 042, Runtime 0.039777, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 043, Runtime 0.028292, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 044, Runtime 0.026091, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 045, Runtime 0.025180, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 046, Runtime 0.026994, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 047, Runtime 0.025237, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 048, Runtime 0.026314, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 049, Runtime 0.028126, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 050, Runtime 0.029621, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 051, Runtime 0.025839, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 052, Runtime 0.026165, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 053, Runtime 0.025264, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 054, Runtime 0.025339, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 055, Runtime 0.024255, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 056, Runtime 0.023709, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 057, Runtime 0.026704, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 058, Runtime 0.026190, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948


100%|████████████████████████████| 100/100 [00:04<00:00, 23.74it/s]
Epoch: 060, Runtime 0.040653, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 061, Runtime 0.027044, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 062, Runtime 0.025011, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 063, Runtime 0.024281, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 064, Runtime 0.029407, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 065, Runtime 0.026917, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 066, Runtime 0.023254, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 067, Runtime 0.024944, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 068, Runtime 0.024039, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 069, Runtime 0.023631, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 070, Runtime 0.025016, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 071, Runtime 0.023146, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 072, Runtime 0.023093, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 073, Runtime 0.024725, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 074, Runtime 0.023400, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 075, Runtime 0.024679, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 076, Runtime 0.025076, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 077, Runtime 0.024111, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 078, Runtime 0.023628, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 079, Runtime 0.063819, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 080, Runtime 0.025906, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 081, Runtime 0.026522, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 082, Runtime 0.026352, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 083, Runtime 0.026971, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 084, Runtime 0.024643, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 085, Runtime 0.026846, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 086, Runtime 0.026315, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 087, Runtime 0.024729, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 088, Runtime 0.030195, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 089, Runtime 0.027802, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 090, Runtime 0.022130, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 091, Runtime 0.025549, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 092, Runtime 0.026374, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 093, Runtime 0.029704, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 094, Runtime 0.028099, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 095, Runtime 0.028397, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 096, Runtime 0.030408, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 097, Runtime 0.035699, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 098, Runtime 0.026155, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 099, Runtime 0.023270, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 100, Runtime 0.023139, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
best val accuracy 0.140822 with test accuracy 0.127835 at epoch 2 and best time 18.294754