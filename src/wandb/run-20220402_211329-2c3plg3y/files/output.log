GrandExtendDiscritizedNet
m1.weight
torch.Size([80, 3703])
m1.bias
torch.Size([80])
m2.weight
torch.Size([6, 80])
m2.bias
torch.Size([6])
mol_list.0.alpha_train
torch.Size([])
mol_list.0.beta_train
torch.Size([])
mol_list.0.alpha_sc
torch.Size([1])
mol_list.0.beta_sc
torch.Size([1])
mol_list.0.multihead_att_layer.Q.weight
torch.Size([32, 80])
mol_list.0.multihead_att_layer.Q.bias
torch.Size([32])
mol_list.0.multihead_att_layer.V.weight
torch.Size([32, 80])
mol_list.0.multihead_att_layer.V.bias
torch.Size([32])
mol_list.0.multihead_att_layer.K.weight
torch.Size([32, 80])
mol_list.0.multihead_att_layer.K.bias
torch.Size([32])
mol_list.0.multihead_att_layer.Wout.weight
torch.Size([80, 4])
mol_list.0.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.1.alpha_train
torch.Size([])
mol_list.1.beta_train
torch.Size([])
mol_list.1.alpha_sc
torch.Size([1])
mol_list.1.beta_sc
torch.Size([1])
mol_list.1.multihead_att_layer.Q.weight
torch.Size([32, 80])
mol_list.1.multihead_att_layer.Q.bias
torch.Size([32])
mol_list.1.multihead_att_layer.V.weight
torch.Size([32, 80])
mol_list.1.multihead_att_layer.V.bias
torch.Size([32])
mol_list.1.multihead_att_layer.K.weight
torch.Size([32, 80])
mol_list.1.multihead_att_layer.K.bias
torch.Size([32])
mol_list.1.multihead_att_layer.Wout.weight
torch.Size([80, 4])
mol_list.1.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.2.alpha_train
torch.Size([])
mol_list.2.beta_train
torch.Size([])
mol_list.2.alpha_sc
torch.Size([1])
mol_list.2.beta_sc
torch.Size([1])
mol_list.2.multihead_att_layer.Q.weight
torch.Size([32, 80])
mol_list.2.multihead_att_layer.Q.bias
torch.Size([32])
mol_list.2.multihead_att_layer.V.weight
torch.Size([32, 80])
mol_list.2.multihead_att_layer.V.bias
torch.Size([32])
mol_list.2.multihead_att_layer.K.weight
torch.Size([32, 80])
mol_list.2.multihead_att_layer.K.bias
torch.Size([32])
mol_list.2.multihead_att_layer.Wout.weight
torch.Size([80, 4])
mol_list.2.multihead_att_layer.Wout.bias
torch.Size([80])

 33%|█████████▌                   | 82/250 [00:03<00:04, 40.66it/s]
Epoch: 001, Runtime 1.439215, Loss 410231936.000000, Train: 0.2400, Val: 0.2000, Test: 0.2167, Best time: 7.8741
Epoch: 002, Runtime 0.033689, Loss 275500400640.000000, Train: 0.2867, Val: 0.1941, Test: 0.2333, Best time: 7.8741
Epoch: 003, Runtime 0.028039, Loss 526831321088.000000, Train: 0.3333, Val: 0.1951, Test: 0.2417, Best time: 7.8741
Epoch: 004, Runtime 0.023267, Loss 853198635008.000000, Train: 0.3800, Val: 0.1989, Test: 0.2583, Best time: 7.8741
Epoch: 005, Runtime 0.021583, Loss 875648712704.000000, Train: 0.4133, Val: 0.2081, Test: 0.2417, Best time: 7.8741
Epoch: 006, Runtime 0.022580, Loss 641139277824.000000, Train: 0.4133, Val: 0.2130, Test: 0.2667, Best time: 7.8741
Epoch: 007, Runtime 0.033477, Loss 552681340928.000000, Train: 0.3867, Val: 0.2168, Test: 0.2167, Best time: 7.8741
Epoch: 008, Runtime 0.021073, Loss 290805841920.000000, Train: 0.3667, Val: 0.2211, Test: 0.2083, Best time: 7.8741
Epoch: 009, Runtime 0.021172, Loss 497020928000.000000, Train: 0.3667, Val: 0.2216, Test: 0.2333, Best time: 7.8741
Epoch: 010, Runtime 0.020829, Loss 738434220032.000000, Train: 0.3733, Val: 0.2054, Test: 0.2333, Best time: 7.8741
Epoch: 011, Runtime 0.023953, Loss 524280856576.000000, Train: 0.3867, Val: 0.1973, Test: 0.2417, Best time: 7.8741
Epoch: 012, Runtime 0.022188, Loss 305124737024.000000, Train: 0.3333, Val: 0.1881, Test: 0.2333, Best time: 7.8741
Epoch: 013, Runtime 0.021000, Loss 227031318528.000000, Train: 0.3200, Val: 0.1946, Test: 0.2333, Best time: 7.8741
Epoch: 014, Runtime 0.028938, Loss 443675082752.000000, Train: 0.3400, Val: 0.2049, Test: 0.2250, Best time: 7.8741
Epoch: 015, Runtime 0.022103, Loss 310872834048.000000, Train: 0.3333, Val: 0.2097, Test: 0.2833, Best time: 7.8741
Epoch: 016, Runtime 0.020805, Loss 178775375872.000000, Train: 0.3533, Val: 0.2232, Test: 0.3000, Best time: 7.8741
Epoch: 017, Runtime 0.026931, Loss 159217876992.000000, Train: 0.3333, Val: 0.2362, Test: 0.2917, Best time: 7.8741
Epoch: 018, Runtime 0.031852, Loss 170216931328.000000, Train: 0.3200, Val: 0.2346, Test: 0.2917, Best time: 7.8741
Epoch: 019, Runtime 0.023267, Loss 198834552832.000000, Train: 0.3333, Val: 0.2384, Test: 0.3333, Best time: 7.8741
Epoch: 020, Runtime 0.018602, Loss 119436877824.000000, Train: 0.3467, Val: 0.2314, Test: 0.3333, Best time: 7.8741
Epoch: 021, Runtime 0.018988, Loss 189007282176.000000, Train: 0.3533, Val: 0.2168, Test: 0.2750, Best time: 7.8741
Epoch: 022, Runtime 0.018991, Loss 285284106240.000000, Train: 0.3467, Val: 0.2157, Test: 0.2583, Best time: 7.8741
Epoch: 023, Runtime 0.030961, Loss 188942106624.000000, Train: 0.3067, Val: 0.2076, Test: 0.2333, Best time: 7.8741
Epoch: 024, Runtime 0.020600, Loss 148844052480.000000, Train: 0.3467, Val: 0.1989, Test: 0.2083, Best time: 7.8741
Epoch: 025, Runtime 0.019922, Loss 214448963584.000000, Train: 0.3000, Val: 0.1914, Test: 0.1500, Best time: 7.8741
Epoch: 026, Runtime 0.019529, Loss 119752761344.000000, Train: 0.2733, Val: 0.1919, Test: 0.1667, Best time: 7.8741
Epoch: 027, Runtime 0.023420, Loss 128254599168.000000, Train: 0.2667, Val: 0.1941, Test: 0.1833, Best time: 7.8741
Epoch: 028, Runtime 0.019483, Loss 134177480704.000000, Train: 0.2800, Val: 0.1951, Test: 0.2000, Best time: 7.8741
Epoch: 029, Runtime 0.021937, Loss 85967151104.000000, Train: 0.2800, Val: 0.1946, Test: 0.2000, Best time: 7.8741
Epoch: 030, Runtime 0.024505, Loss 120987385856.000000, Train: 0.2933, Val: 0.1870, Test: 0.1917, Best time: 7.8741
Epoch: 031, Runtime 0.023041, Loss 128823377920.000000, Train: 0.2733, Val: 0.1919, Test: 0.1750, Best time: 7.8741
Epoch: 032, Runtime 0.022170, Loss 109937131520.000000, Train: 0.2667, Val: 0.1946, Test: 0.1917, Best time: 7.8741
Epoch: 033, Runtime 0.020470, Loss 88565121024.000000, Train: 0.2667, Val: 0.1946, Test: 0.2000, Best time: 7.8741
Epoch: 034, Runtime 0.021412, Loss 81653055488.000000, Train: 0.2600, Val: 0.1881, Test: 0.2000, Best time: 7.8741
Epoch: 035, Runtime 0.022064, Loss 88192532480.000000, Train: 0.2533, Val: 0.1892, Test: 0.1917, Best time: 7.8741
Epoch: 036, Runtime 0.021464, Loss 75436548096.000000, Train: 0.2467, Val: 0.1854, Test: 0.1750, Best time: 7.8741
Epoch: 037, Runtime 0.021511, Loss 66780807168.000000, Train: 0.2600, Val: 0.1778, Test: 0.1667, Best time: 7.8741
Epoch: 038, Runtime 0.021220, Loss 123435106304.000000, Train: 0.2800, Val: 0.1865, Test: 0.1500, Best time: 7.8741
Epoch: 039, Runtime 0.020680, Loss 73360760832.000000, Train: 0.2800, Val: 0.1822, Test: 0.1583, Best time: 7.8741
Epoch: 040, Runtime 0.021476, Loss 54627553280.000000, Train: 0.2800, Val: 0.1843, Test: 0.1667, Best time: 7.8741
Epoch: 041, Runtime 0.020560, Loss 78346510336.000000, Train: 0.2867, Val: 0.2005, Test: 0.1917, Best time: 7.8741
Epoch: 042, Runtime 0.024852, Loss 81457184768.000000, Train: 0.2800, Val: 0.2254, Test: 0.2750, Best time: 7.8741
Epoch: 043, Runtime 0.020566, Loss 49151295488.000000, Train: 0.2800, Val: 0.2373, Test: 0.2667, Best time: 7.8741
Epoch: 044, Runtime 0.045243, Loss 55787794432.000000, Train: 0.2600, Val: 0.2384, Test: 0.2667, Best time: 7.8741
Epoch: 045, Runtime 0.021085, Loss 66851696640.000000, Train: 0.2667, Val: 0.2335, Test: 0.2667, Best time: 7.8741
Epoch: 046, Runtime 0.022402, Loss 76960342016.000000, Train: 0.3267, Val: 0.2086, Test: 0.2417, Best time: 7.8741
Epoch: 047, Runtime 0.024452, Loss 55223029760.000000, Train: 0.2867, Val: 0.1989, Test: 0.2250, Best time: 7.8741
Epoch: 048, Runtime 0.029999, Loss 58090786816.000000, Train: 0.2933, Val: 0.1914, Test: 0.2167, Best time: 7.8741
Epoch: 049, Runtime 0.026983, Loss 37294977024.000000, Train: 0.2733, Val: 0.1892, Test: 0.2083, Best time: 7.8741
Epoch: 050, Runtime 0.028092, Loss 29115805696.000000, Train: 0.2800, Val: 0.1827, Test: 0.2167, Best time: 7.8741
Epoch: 051, Runtime 0.024356, Loss 34235426816.000000, Train: 0.2867, Val: 0.1811, Test: 0.2250, Best time: 7.8741
Epoch: 052, Runtime 0.024195, Loss 31637768192.000000, Train: 0.3000, Val: 0.1741, Test: 0.2417, Best time: 7.8741
Epoch: 053, Runtime 0.022351, Loss 31704381440.000000, Train: 0.3000, Val: 0.1724, Test: 0.2417, Best time: 7.8741
Epoch: 054, Runtime 0.021811, Loss 38726479872.000000, Train: 0.3067, Val: 0.1757, Test: 0.2333, Best time: 7.8741
Epoch: 055, Runtime 0.024638, Loss 20298745856.000000, Train: 0.2733, Val: 0.1816, Test: 0.2167, Best time: 7.8741
Epoch: 056, Runtime 0.023402, Loss 16269742080.000000, Train: 0.3067, Val: 0.1843, Test: 0.2083, Best time: 7.8741
Epoch: 057, Runtime 0.022278, Loss 15891238912.000000, Train: 0.3067, Val: 0.1843, Test: 0.1917, Best time: 7.8741
Epoch: 058, Runtime 0.021950, Loss 21568585728.000000, Train: 0.3000, Val: 0.2000, Test: 0.1750, Best time: 7.8741
Epoch: 059, Runtime 0.021817, Loss 20302641152.000000, Train: 0.2867, Val: 0.2076, Test: 0.1750, Best time: 7.8741
Epoch: 060, Runtime 0.024194, Loss 11633034240.000000, Train: 0.2733, Val: 0.2114, Test: 0.1750, Best time: 7.8741
Epoch: 061, Runtime 0.021598, Loss 14248510464.000000, Train: 0.2800, Val: 0.2119, Test: 0.1833, Best time: 7.8741
Epoch: 062, Runtime 0.026708, Loss 8818251776.000000, Train: 0.2933, Val: 0.2130, Test: 0.2000, Best time: 7.8741
Epoch: 063, Runtime 0.023889, Loss 9541725184.000000, Train: 0.2733, Val: 0.2146, Test: 0.2000, Best time: 7.8741
Epoch: 064, Runtime 0.033846, Loss 8875560960.000000, Train: 0.3000, Val: 0.2038, Test: 0.2083, Best time: 7.8741
Epoch: 065, Runtime 0.023866, Loss 5806647808.000000, Train: 0.3267, Val: 0.1951, Test: 0.2000, Best time: 7.8741
Epoch: 066, Runtime 0.021177, Loss 3556923904.000000, Train: 0.3333, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 067, Runtime 0.021572, Loss 2935569664.000000, Train: 0.3667, Val: 0.1843, Test: 0.1583, Best time: 7.8741
Epoch: 068, Runtime 0.021601, Loss 2443014400.000000, Train: 0.3467, Val: 0.1886, Test: 0.1750, Best time: 7.8741
Epoch: 069, Runtime 0.021982, Loss 460341248.000000, Train: 0.3133, Val: 0.1865, Test: 0.1583, Best time: 7.8741
Epoch: 070, Runtime 0.020647, Loss 690690816.000000, Train: 0.3133, Val: 0.1870, Test: 0.1917, Best time: 7.8741
Epoch: 071, Runtime 0.024696, Loss 1451203456.000000, Train: 0.2933, Val: 0.1859, Test: 0.2167, Best time: 7.8741
Epoch: 072, Runtime 0.022899, Loss 4606059008.000000, Train: 0.2933, Val: 0.1881, Test: 0.2083, Best time: 7.8741
Epoch: 073, Runtime 0.022539, Loss 4651367936.000000, Train: 0.2933, Val: 0.1903, Test: 0.2083, Best time: 7.8741
Epoch: 074, Runtime 0.023997, Loss 3576061952.000000, Train: 0.2733, Val: 0.1914, Test: 0.2083, Best time: 7.8741
Epoch: 075, Runtime 0.022382, Loss 4413092352.000000, Train: 0.2800, Val: 0.1886, Test: 0.2167, Best time: 7.8741
Epoch: 076, Runtime 0.022153, Loss 4189857280.000000, Train: 0.2867, Val: 0.1951, Test: 0.2167, Best time: 7.8741
Epoch: 077, Runtime 0.024161, Loss 6316643328.000000, Train: 0.2933, Val: 0.1978, Test: 0.2167, Best time: 7.8741
Epoch: 078, Runtime 0.025681, Loss 4049744640.000000, Train: 0.3200, Val: 0.1914, Test: 0.2000, Best time: 7.8741
Epoch: 079, Runtime 0.023158, Loss 2620709632.000000, Train: 0.3200, Val: 0.1914, Test: 0.1750, Best time: 7.8741
Epoch: 080, Runtime 0.027395, Loss 2874487040.000000, Train: 0.2933, Val: 0.1957, Test: 0.1750, Best time: 7.8741
Epoch: 081, Runtime 0.022593, Loss 1625830912.000000, Train: 0.2933, Val: 0.2011, Test: 0.1833, Best time: 7.8741
Epoch: 082, Runtime 0.023086, Loss 1163552384.000000, Train: 0.2800, Val: 0.2027, Test: 0.1917, Best time: 7.8741
Epoch: 083, Runtime 0.026837, Loss 462820640.000000, Train: 0.2867, Val: 0.2038, Test: 0.1667, Best time: 7.8741
Epoch: 084, Runtime 0.063391, Loss 276940416.000000, Train: 0.2800, Val: 0.2070, Test: 0.1583, Best time: 7.8741
Epoch: 085, Runtime 0.028680, Loss 446132736.000000, Train: 0.2667, Val: 0.2103, Test: 0.1583, Best time: 7.8741
Epoch: 086, Runtime 0.024062, Loss 1547393664.000000, Train: 0.2600, Val: 0.2016, Test: 0.1667, Best time: 7.8741
Epoch: 087, Runtime 0.026487, Loss 1631242240.000000, Train: 0.2467, Val: 0.2005, Test: 0.1917, Best time: 7.8741
Epoch: 088, Runtime 0.023788, Loss 2548297472.000000, Train: 0.2400, Val: 0.1989, Test: 0.1750, Best time: 7.8741
Epoch: 089, Runtime 0.025573, Loss 1705176832.000000, Train: 0.2333, Val: 0.2005, Test: 0.1833, Best time: 7.8741
Epoch: 090, Runtime 0.025547, Loss 1408221184.000000, Train: 0.2400, Val: 0.1989, Test: 0.1750, Best time: 7.8741
Epoch: 091, Runtime 0.023548, Loss 1643401984.000000, Train: 0.2400, Val: 0.1995, Test: 0.1667, Best time: 7.8741
Epoch: 092, Runtime 0.024373, Loss 2007430656.000000, Train: 0.2400, Val: 0.2022, Test: 0.1667, Best time: 7.8741
Epoch: 093, Runtime 0.021861, Loss 978663424.000000, Train: 0.2333, Val: 0.2011, Test: 0.1667, Best time: 7.8741
Epoch: 094, Runtime 0.026945, Loss 933466048.000000, Train: 0.2467, Val: 0.2016, Test: 0.1500, Best time: 7.8741
Epoch: 095, Runtime 0.026530, Loss 446896896.000000, Train: 0.2533, Val: 0.2022, Test: 0.1333, Best time: 7.8741
Epoch: 096, Runtime 0.021765, Loss 264620928.000000, Train: 0.2467, Val: 0.2005, Test: 0.1167, Best time: 7.8741
Epoch: 097, Runtime 0.023650, Loss 83670552.000000, Train: 0.2533, Val: 0.1989, Test: 0.1167, Best time: 7.8741
Epoch: 098, Runtime 0.023624, Loss 578547264.000000, Train: 0.2667, Val: 0.1962, Test: 0.1333, Best time: 7.8741
Epoch: 099, Runtime 0.027655, Loss 435682016.000000, Train: 0.2600, Val: 0.1946, Test: 0.1333, Best time: 7.8741
Epoch: 100, Runtime 0.024565, Loss 844531392.000000, Train: 0.2600, Val: 0.1914, Test: 0.1417, Best time: 7.8741
Epoch: 101, Runtime 0.027290, Loss 692181056.000000, Train: 0.2667, Val: 0.1897, Test: 0.1417, Best time: 7.8741
Epoch: 102, Runtime 0.032633, Loss 425979488.000000, Train: 0.2600, Val: 0.1924, Test: 0.1417, Best time: 7.8741
Epoch: 103, Runtime 0.036914, Loss 310569728.000000, Train: 0.2600, Val: 0.1908, Test: 0.1500, Best time: 7.8741
Epoch: 104, Runtime 0.026948, Loss 252934112.000000, Train: 0.2733, Val: 0.1914, Test: 0.1500, Best time: 7.8741
Epoch: 105, Runtime 0.025654, Loss 11524918.000000, Train: 0.2733, Val: 0.1930, Test: 0.1500, Best time: 7.8741
Epoch: 106, Runtime 0.025463, Loss 163523344.000000, Train: 0.2733, Val: 0.1903, Test: 0.1500, Best time: 7.8741
Epoch: 107, Runtime 0.026298, Loss 222716976.000000, Train: 0.2667, Val: 0.1897, Test: 0.1500, Best time: 7.8741
Epoch: 108, Runtime 0.024750, Loss 190442784.000000, Train: 0.2667, Val: 0.1908, Test: 0.1500, Best time: 7.8741
Epoch: 109, Runtime 0.027219, Loss 215134976.000000, Train: 0.2667, Val: 0.1886, Test: 0.1500, Best time: 7.8741
Epoch: 110, Runtime 0.026740, Loss 26310274.000000, Train: 0.2733, Val: 0.1897, Test: 0.1500, Best time: 7.8741
Epoch: 111, Runtime 0.024341, Loss 107540000.000000, Train: 0.2733, Val: 0.1908, Test: 0.1500, Best time: 7.8741
Epoch: 112, Runtime 0.025250, Loss 160082752.000000, Train: 0.2867, Val: 0.1903, Test: 0.1417, Best time: 7.8741
Epoch: 113, Runtime 0.025030, Loss 343671904.000000, Train: 0.2867, Val: 0.1914, Test: 0.1417, Best time: 7.8741
Epoch: 114, Runtime 0.025512, Loss 282067776.000000, Train: 0.2800, Val: 0.1908, Test: 0.1583, Best time: 7.8741
Epoch: 115, Runtime 0.025330, Loss 35099712.000000, Train: 0.2800, Val: 0.1924, Test: 0.1667, Best time: 7.8741
Epoch: 116, Runtime 0.035650, Loss 194029808.000000, Train: 0.2733, Val: 0.1919, Test: 0.1833, Best time: 7.8741
Epoch: 117, Runtime 0.030728, Loss 331622240.000000, Train: 0.2800, Val: 0.1908, Test: 0.1833, Best time: 7.8741
Epoch: 118, Runtime 0.028997, Loss 412952928.000000, Train: 0.2800, Val: 0.1935, Test: 0.1833, Best time: 7.8741
Epoch: 119, Runtime 0.027250, Loss 280023392.000000, Train: 0.2733, Val: 0.1946, Test: 0.1833, Best time: 7.8741
Epoch: 120, Runtime 0.029791, Loss 248543072.000000, Train: 0.2667, Val: 0.1941, Test: 0.1833, Best time: 7.8741
Epoch: 121, Runtime 0.161516, Loss 138620272.000000, Train: 0.2667, Val: 0.1968, Test: 0.1833, Best time: 7.8741
Epoch: 122, Runtime 0.029749, Loss 137755280.000000, Train: 0.2667, Val: 0.2005, Test: 0.1750, Best time: 7.8741
Epoch: 123, Runtime 0.027518, Loss 49954024.000000, Train: 0.2667, Val: 0.2011, Test: 0.1750, Best time: 7.8741
Epoch: 124, Runtime 0.025948, Loss 96267248.000000, Train: 0.2733, Val: 0.2022, Test: 0.1750, Best time: 7.8741
Epoch: 125, Runtime 0.024768, Loss 217344576.000000, Train: 0.2667, Val: 0.2016, Test: 0.1833, Best time: 7.8741
Epoch: 126, Runtime 0.032106, Loss 402960768.000000, Train: 0.2533, Val: 0.2016, Test: 0.1833, Best time: 7.8741
Epoch: 127, Runtime 0.026631, Loss 171974400.000000, Train: 0.2533, Val: 0.2022, Test: 0.1833, Best time: 7.8741
Epoch: 128, Runtime 0.024328, Loss 163080848.000000, Train: 0.2467, Val: 0.2038, Test: 0.2083, Best time: 7.8741
Epoch: 129, Runtime 0.024518, Loss 88064288.000000, Train: 0.2400, Val: 0.2065, Test: 0.2083, Best time: 7.8741
Epoch: 130, Runtime 0.024222, Loss 71212520.000000, Train: 0.2400, Val: 0.2081, Test: 0.2000, Best time: 7.8741
Epoch: 131, Runtime 0.023442, Loss 75412800.000000, Train: 0.2400, Val: 0.2059, Test: 0.1917, Best time: 7.8741
Epoch: 132, Runtime 0.027158, Loss 117759400.000000, Train: 0.2400, Val: 0.2076, Test: 0.1917, Best time: 7.8741
Epoch: 133, Runtime 0.030291, Loss 128014592.000000, Train: 0.2467, Val: 0.2086, Test: 0.1917, Best time: 7.8741
Epoch: 134, Runtime 0.026096, Loss 46030780.000000, Train: 0.2467, Val: 0.2076, Test: 0.1917, Best time: 7.8741
Epoch: 135, Runtime 0.025050, Loss 74633176.000000, Train: 0.2533, Val: 0.2081, Test: 0.2000, Best time: 7.8741
Epoch: 136, Runtime 0.026319, Loss 119175048.000000, Train: 0.2533, Val: 0.2092, Test: 0.2000, Best time: 7.8741
Epoch: 137, Runtime 0.024792, Loss 196241552.000000, Train: 0.2533, Val: 0.2114, Test: 0.2000, Best time: 7.8741
Epoch: 138, Runtime 0.030778, Loss 49201080.000000, Train: 0.2467, Val: 0.2114, Test: 0.2000, Best time: 7.8741


 90%|█████████████████████████▎  | 226/250 [00:07<00:00, 42.16it/s]
Epoch: 140, Runtime 0.039952, Loss 79345368.000000, Train: 0.2533, Val: 0.2092, Test: 0.2000, Best time: 7.8741
Epoch: 141, Runtime 0.026115, Loss 45595324.000000, Train: 0.2533, Val: 0.2086, Test: 0.2000, Best time: 7.8741
Epoch: 142, Runtime 0.025032, Loss 7815335.500000, Train: 0.2533, Val: 0.2086, Test: 0.2000, Best time: 7.8741
Epoch: 143, Runtime 0.025767, Loss 27894434.000000, Train: 0.2467, Val: 0.2097, Test: 0.2000, Best time: 7.8741
Epoch: 144, Runtime 0.025704, Loss 11371020.000000, Train: 0.2467, Val: 0.2086, Test: 0.2000, Best time: 7.8741
Epoch: 145, Runtime 0.023976, Loss 62599688.000000, Train: 0.2467, Val: 0.2097, Test: 0.2083, Best time: 7.8741
Epoch: 146, Runtime 0.024812, Loss 23808018.000000, Train: 0.2467, Val: 0.2076, Test: 0.2083, Best time: 7.8741
Epoch: 147, Runtime 0.030056, Loss 55993972.000000, Train: 0.2467, Val: 0.2076, Test: 0.2083, Best time: 7.8741
Epoch: 148, Runtime 0.027616, Loss 92914392.000000, Train: 0.2467, Val: 0.2092, Test: 0.2083, Best time: 7.8741
Epoch: 149, Runtime 0.026164, Loss 89802120.000000, Train: 0.2467, Val: 0.2097, Test: 0.2083, Best time: 7.8741
Epoch: 150, Runtime 0.029670, Loss 74322408.000000, Train: 0.2467, Val: 0.2103, Test: 0.2083, Best time: 7.8741
Epoch: 151, Runtime 0.052191, Loss 14899535.000000, Train: 0.2467, Val: 0.2092, Test: 0.2083, Best time: 7.8741
Epoch: 152, Runtime 0.026708, Loss 39227376.000000, Train: 0.2467, Val: 0.2103, Test: 0.2000, Best time: 7.8741
Epoch: 153, Runtime 0.025962, Loss 24236146.000000, Train: 0.2467, Val: 0.2114, Test: 0.2000, Best time: 7.8741
Epoch: 154, Runtime 0.025502, Loss 28531136.000000, Train: 0.2467, Val: 0.2114, Test: 0.2000, Best time: 7.8741
Epoch: 155, Runtime 0.035979, Loss 55837732.000000, Train: 0.2467, Val: 0.2108, Test: 0.2000, Best time: 7.8741
Epoch: 156, Runtime 0.023016, Loss 16147077.000000, Train: 0.2400, Val: 0.2114, Test: 0.2083, Best time: 7.8741
Epoch: 157, Runtime 0.033074, Loss 45403092.000000, Train: 0.2467, Val: 0.2097, Test: 0.2083, Best time: 7.8741
Epoch: 158, Runtime 0.023959, Loss 69402696.000000, Train: 0.2467, Val: 0.2103, Test: 0.2083, Best time: 7.8741
Epoch: 159, Runtime 0.022605, Loss 89829024.000000, Train: 0.2400, Val: 0.2092, Test: 0.2083, Best time: 7.8741
Epoch: 160, Runtime 0.023081, Loss 89795512.000000, Train: 0.2400, Val: 0.2097, Test: 0.2000, Best time: 7.8741
Epoch: 161, Runtime 0.025310, Loss 43838208.000000, Train: 0.2400, Val: 0.2086, Test: 0.2000, Best time: 7.8741
Epoch: 162, Runtime 0.027745, Loss 9011143.000000, Train: 0.2400, Val: 0.2086, Test: 0.2000, Best time: 7.8741
Epoch: 163, Runtime 0.028343, Loss 4876998.000000, Train: 0.2467, Val: 0.2092, Test: 0.2000, Best time: 7.8741
Epoch: 164, Runtime 0.022506, Loss 51440744.000000, Train: 0.2467, Val: 0.2092, Test: 0.1917, Best time: 7.8741
Epoch: 165, Runtime 0.024887, Loss 79296440.000000, Train: 0.2467, Val: 0.2092, Test: 0.1917, Best time: 7.8741
Epoch: 166, Runtime 0.026811, Loss 26640378.000000, Train: 0.2467, Val: 0.2092, Test: 0.1917, Best time: 7.8741
Epoch: 167, Runtime 0.024560, Loss 25104404.000000, Train: 0.2467, Val: 0.2092, Test: 0.1917, Best time: 7.8741
Epoch: 168, Runtime 0.039981, Loss 33076200.000000, Train: 0.2467, Val: 0.2097, Test: 0.1917, Best time: 7.8741
Epoch: 169, Runtime 0.025686, Loss 4565928.500000, Train: 0.2467, Val: 0.2092, Test: 0.1917, Best time: 7.8741
Epoch: 170, Runtime 0.029525, Loss 61091484.000000, Train: 0.2467, Val: 0.2092, Test: 0.1917, Best time: 7.8741
Epoch: 171, Runtime 0.026099, Loss 53664944.000000, Train: 0.2467, Val: 0.2086, Test: 0.1917, Best time: 7.8741
Epoch: 172, Runtime 0.026954, Loss 45998544.000000, Train: 0.2467, Val: 0.2092, Test: 0.1917, Best time: 7.8741
Epoch: 173, Runtime 0.027443, Loss 21394616.000000, Train: 0.2467, Val: 0.2086, Test: 0.1917, Best time: 7.8741
Epoch: 174, Runtime 0.023978, Loss 22155710.000000, Train: 0.2467, Val: 0.2092, Test: 0.1917, Best time: 7.8741
Epoch: 175, Runtime 0.032756, Loss 31233212.000000, Train: 0.2467, Val: 0.2086, Test: 0.1917, Best time: 7.8741
Epoch: 176, Runtime 0.028121, Loss 76065672.000000, Train: 0.2467, Val: 0.2070, Test: 0.1917, Best time: 7.8741
Epoch: 177, Runtime 0.027211, Loss 12255558.000000, Train: 0.2467, Val: 0.2065, Test: 0.1917, Best time: 7.8741
Epoch: 178, Runtime 0.022779, Loss 11019889.000000, Train: 0.2467, Val: 0.2081, Test: 0.1917, Best time: 7.8741
Epoch: 179, Runtime 0.021041, Loss 19959042.000000, Train: 0.2467, Val: 0.2081, Test: 0.1917, Best time: 7.8741
Epoch: 180, Runtime 0.022005, Loss 9017021.000000, Train: 0.2467, Val: 0.2076, Test: 0.1917, Best time: 7.8741
Epoch: 181, Runtime 0.021152, Loss 68161368.000000, Train: 0.2467, Val: 0.2076, Test: 0.1917, Best time: 7.8741
Epoch: 182, Runtime 0.021059, Loss 120239032.000000, Train: 0.2467, Val: 0.2076, Test: 0.1917, Best time: 7.8741
Epoch: 183, Runtime 0.020843, Loss 88696552.000000, Train: 0.2467, Val: 0.2081, Test: 0.1917, Best time: 7.8741
Epoch: 184, Runtime 0.021670, Loss 18032380.000000, Train: 0.2467, Val: 0.2092, Test: 0.1917, Best time: 7.8741
Epoch: 185, Runtime 0.021346, Loss 50726016.000000, Train: 0.2467, Val: 0.2103, Test: 0.1917, Best time: 7.8741
Epoch: 186, Runtime 0.022098, Loss 79196392.000000, Train: 0.2467, Val: 0.2097, Test: 0.1917, Best time: 7.8741
Epoch: 187, Runtime 0.022437, Loss 1006200.625000, Train: 0.2400, Val: 0.2114, Test: 0.1917, Best time: 7.8741
Epoch: 188, Runtime 0.022677, Loss 80958816.000000, Train: 0.2467, Val: 0.2124, Test: 0.1917, Best time: 7.8741
Epoch: 189, Runtime 0.025251, Loss 113878072.000000, Train: 0.2467, Val: 0.2124, Test: 0.1917, Best time: 7.8741
Epoch: 190, Runtime 0.021800, Loss 173940592.000000, Train: 0.2400, Val: 0.2114, Test: 0.1917, Best time: 7.8741
Epoch: 191, Runtime 0.021256, Loss 165110160.000000, Train: 0.2400, Val: 0.2103, Test: 0.1917, Best time: 7.8741
Epoch: 192, Runtime 0.021000, Loss 81133896.000000, Train: 0.2400, Val: 0.2103, Test: 0.1917, Best time: 7.8741
Epoch: 193, Runtime 0.021617, Loss 19069356.000000, Train: 0.2400, Val: 0.2103, Test: 0.1917, Best time: 7.8741
Epoch: 194, Runtime 0.022798, Loss 98543664.000000, Train: 0.2400, Val: 0.2097, Test: 0.1917, Best time: 7.8741
Epoch: 195, Runtime 0.020616, Loss 132189320.000000, Train: 0.2333, Val: 0.2092, Test: 0.2000, Best time: 7.8741
Epoch: 196, Runtime 0.021411, Loss 69748056.000000, Train: 0.2333, Val: 0.2130, Test: 0.2083, Best time: 7.8741
Epoch: 197, Runtime 0.036298, Loss 49127348.000000, Train: 0.2333, Val: 0.2135, Test: 0.2167, Best time: 7.8741
Epoch: 198, Runtime 0.022638, Loss 20082260.000000, Train: 0.2400, Val: 0.2135, Test: 0.2083, Best time: 7.8741
Epoch: 199, Runtime 0.021086, Loss 35242344.000000, Train: 0.2400, Val: 0.2141, Test: 0.2083, Best time: 7.8741
Epoch: 200, Runtime 0.021243, Loss 33703656.000000, Train: 0.2400, Val: 0.2162, Test: 0.2083, Best time: 7.8741
Epoch: 201, Runtime 0.022001, Loss 18616948.000000, Train: 0.2400, Val: 0.2151, Test: 0.2083, Best time: 7.8741
Epoch: 202, Runtime 0.020897, Loss 31098050.000000, Train: 0.2333, Val: 0.2151, Test: 0.2083, Best time: 7.8741
Epoch: 203, Runtime 0.021109, Loss 74863080.000000, Train: 0.2400, Val: 0.2157, Test: 0.2083, Best time: 7.8741
Epoch: 204, Runtime 0.020041, Loss 44355460.000000, Train: 0.2400, Val: 0.2162, Test: 0.2083, Best time: 7.8741
Epoch: 205, Runtime 0.020844, Loss 23521240.000000, Train: 0.2467, Val: 0.2162, Test: 0.2083, Best time: 7.8741
Epoch: 206, Runtime 0.022195, Loss 39353644.000000, Train: 0.2400, Val: 0.2151, Test: 0.2083, Best time: 7.8741
Epoch: 207, Runtime 0.024829, Loss 20435388.000000, Train: 0.2467, Val: 0.2146, Test: 0.2083, Best time: 7.8741
Epoch: 208, Runtime 0.023927, Loss 9849516.000000, Train: 0.2467, Val: 0.2124, Test: 0.2083, Best time: 7.8741
Epoch: 209, Runtime 0.021092, Loss 14887576.000000, Train: 0.2533, Val: 0.2141, Test: 0.2083, Best time: 7.8741
Epoch: 210, Runtime 0.028783, Loss 10466010.000000, Train: 0.2467, Val: 0.2130, Test: 0.2083, Best time: 7.8741
Epoch: 211, Runtime 0.024705, Loss 4243483.000000, Train: 0.2467, Val: 0.2146, Test: 0.2083, Best time: 7.8741
Epoch: 212, Runtime 0.022230, Loss 14286971.000000, Train: 0.2467, Val: 0.2135, Test: 0.2000, Best time: 7.8741
Epoch: 213, Runtime 0.021181, Loss 7715622.500000, Train: 0.2467, Val: 0.2146, Test: 0.2000, Best time: 7.8741
Epoch: 214, Runtime 0.021415, Loss 1681843.125000, Train: 0.2467, Val: 0.2141, Test: 0.2000, Best time: 7.8741
Epoch: 215, Runtime 0.021263, Loss 23222192.000000, Train: 0.2467, Val: 0.2151, Test: 0.2000, Best time: 7.8741
Epoch: 216, Runtime 0.023132, Loss 3188819.250000, Train: 0.2467, Val: 0.2157, Test: 0.2000, Best time: 7.8741
Epoch: 217, Runtime 0.025003, Loss 22449442.000000, Train: 0.2467, Val: 0.2146, Test: 0.2000, Best time: 7.8741
Epoch: 218, Runtime 0.035990, Loss 68764032.000000, Train: 0.2467, Val: 0.2151, Test: 0.2000, Best time: 7.8741
Epoch: 219, Runtime 0.023682, Loss 18967944.000000, Train: 0.2467, Val: 0.2146, Test: 0.2000, Best time: 7.8741
Epoch: 220, Runtime 0.020849, Loss 64923704.000000, Train: 0.2400, Val: 0.2141, Test: 0.2000, Best time: 7.8741
Epoch: 221, Runtime 0.024211, Loss 81709232.000000, Train: 0.2467, Val: 0.2151, Test: 0.2083, Best time: 7.8741
Epoch: 222, Runtime 0.022544, Loss 76880768.000000, Train: 0.2467, Val: 0.2157, Test: 0.2083, Best time: 7.8741
Epoch: 223, Runtime 0.021432, Loss 16687793.000000, Train: 0.2533, Val: 0.2168, Test: 0.2167, Best time: 7.8741
Epoch: 224, Runtime 0.019975, Loss 82966040.000000, Train: 0.2600, Val: 0.2178, Test: 0.2167, Best time: 7.8741
Epoch: 225, Runtime 0.021446, Loss 211303072.000000, Train: 0.2600, Val: 0.2195, Test: 0.2250, Best time: 7.8741
Epoch: 226, Runtime 0.021442, Loss 107560928.000000, Train: 0.2600, Val: 0.2178, Test: 0.2167, Best time: 7.8741
Epoch: 227, Runtime 0.021486, Loss 65104024.000000, Train: 0.2667, Val: 0.2189, Test: 0.2167, Best time: 7.8741
Epoch: 228, Runtime 0.021881, Loss 27292912.000000, Train: 0.2733, Val: 0.2178, Test: 0.2167, Best time: 7.8741
Epoch: 229, Runtime 0.022181, Loss 38898132.000000, Train: 0.2733, Val: 0.2195, Test: 0.2167, Best time: 7.8741
Epoch: 230, Runtime 0.021994, Loss 139472560.000000, Train: 0.2733, Val: 0.2189, Test: 0.2250, Best time: 7.8741
Epoch: 231, Runtime 0.025873, Loss 137326544.000000, Train: 0.2733, Val: 0.2232, Test: 0.2250, Best time: 7.8741
Epoch: 232, Runtime 0.051693, Loss 71172760.000000, Train: 0.2800, Val: 0.2243, Test: 0.2250, Best time: 7.8741
Epoch: 233, Runtime 0.021063, Loss 1157668.875000, Train: 0.2733, Val: 0.2249, Test: 0.2250, Best time: 7.8741
Epoch: 234, Runtime 0.020879, Loss 130171592.000000, Train: 0.2733, Val: 0.2243, Test: 0.2250, Best time: 7.8741
Epoch: 235, Runtime 0.021236, Loss 152635008.000000, Train: 0.2733, Val: 0.2222, Test: 0.2250, Best time: 7.8741
Epoch: 236, Runtime 0.021739, Loss 181833600.000000, Train: 0.2733, Val: 0.2238, Test: 0.2333, Best time: 7.8741
Epoch: 237, Runtime 0.021769, Loss 176917680.000000, Train: 0.2733, Val: 0.2254, Test: 0.2333, Best time: 7.8741
Epoch: 238, Runtime 0.025197, Loss 289627008.000000, Train: 0.2733, Val: 0.2216, Test: 0.2333, Best time: 7.8741
Epoch: 239, Runtime 0.039249, Loss 95297040.000000, Train: 0.2800, Val: 0.2216, Test: 0.2333, Best time: 7.8741
Epoch: 240, Runtime 0.022621, Loss 65971952.000000, Train: 0.2800, Val: 0.2227, Test: 0.2333, Best time: 7.8741
Epoch: 241, Runtime 0.022512, Loss 116118472.000000, Train: 0.2733, Val: 0.2216, Test: 0.2250, Best time: 7.8741
Epoch: 242, Runtime 0.028195, Loss 105450424.000000, Train: 0.2933, Val: 0.2216, Test: 0.2167, Best time: 7.8741
Epoch: 243, Runtime 0.025844, Loss 52282128.000000, Train: 0.2933, Val: 0.2205, Test: 0.2167, Best time: 7.8741
Epoch: 244, Runtime 0.020407, Loss 6637970.000000, Train: 0.2867, Val: 0.2205, Test: 0.2167, Best time: 7.8741
Epoch: 245, Runtime 0.024909, Loss 56164528.000000, Train: 0.2867, Val: 0.2184, Test: 0.2250, Best time: 7.8741
Epoch: 246, Runtime 0.020134, Loss 39299840.000000, Train: 0.2867, Val: 0.2189, Test: 0.2250, Best time: 7.8741
Epoch: 247, Runtime 0.022759, Loss 98470.726562, Train: 0.2800, Val: 0.2178, Test: 0.2250, Best time: 7.8741
Epoch: 248, Runtime 0.021756, Loss 46020992.000000, Train: 0.2800, Val: 0.2168, Test: 0.2167, Best time: 7.8741
Epoch: 249, Runtime 0.025557, Loss 70343704.000000, Train: 0.2800, Val: 0.2173, Test: 0.2250, Best time: 7.8741
Epoch: 250, Runtime 0.025420, Loss 99201256.000000, Train: 0.2867, Val: 0.2173, Test: 0.2250, Best time: 7.8741

100%|████████████████████████████| 250/250 [00:08<00:00, 31.23it/s]