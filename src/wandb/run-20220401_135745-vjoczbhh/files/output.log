
  0%|                                                                                                          | 0/100 [00:00<?, ?it/s]
GrandExtendDiscritizedNet
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
mol_list.0.alpha_train
torch.Size([])
mol_list.0.beta_train
torch.Size([])
mol_list.0.alpha_sc
torch.Size([1])
mol_list.0.beta_sc
torch.Size([1])
mol_list.0.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.0.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.V.bias
torch.Size([128])
mol_list.0.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.K.bias
torch.Size([128])
mol_list.0.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.0.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.1.alpha_train
torch.Size([])
mol_list.1.beta_train
torch.Size([])
mol_list.1.alpha_sc
torch.Size([1])
mol_list.1.beta_sc
torch.Size([1])
mol_list.1.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.1.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.V.bias
torch.Size([128])
mol_list.1.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.K.bias
torch.Size([128])
mol_list.1.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.1.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.2.alpha_train
torch.Size([])
mol_list.2.beta_train
torch.Size([])
mol_list.2.alpha_sc
torch.Size([1])
mol_list.2.beta_sc
torch.Size([1])
mol_list.2.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.2.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.V.bias
torch.Size([128])
mol_list.2.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.K.bias
torch.Size([128])
mol_list.2.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.2.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.3.alpha_train
torch.Size([])
mol_list.3.beta_train
torch.Size([])
mol_list.3.alpha_sc
torch.Size([1])
mol_list.3.beta_sc
torch.Size([1])
mol_list.3.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.3.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.V.bias
torch.Size([128])
mol_list.3.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.K.bias
torch.Size([128])
mol_list.3.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.3.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.4.alpha_train
torch.Size([])
mol_list.4.beta_train
torch.Size([])
mol_list.4.alpha_sc
torch.Size([1])
mol_list.4.beta_sc
torch.Size([1])
mol_list.4.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.4.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.V.bias
torch.Size([128])
mol_list.4.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.K.bias
torch.Size([128])
mol_list.4.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.4.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.5.alpha_train
torch.Size([])
mol_list.5.beta_train
torch.Size([])
mol_list.5.alpha_sc
torch.Size([1])
mol_list.5.beta_sc
torch.Size([1])
mol_list.5.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.5.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.5.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.5.multihead_att_layer.V.bias
torch.Size([128])
mol_list.5.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.5.multihead_att_layer.K.bias
torch.Size([128])
mol_list.5.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.5.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.6.alpha_train
torch.Size([])
mol_list.6.beta_train
torch.Size([])
mol_list.6.alpha_sc
torch.Size([1])
mol_list.6.beta_sc
torch.Size([1])
mol_list.6.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.6.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.6.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.6.multihead_att_layer.V.bias
torch.Size([128])
mol_list.6.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.6.multihead_att_layer.K.bias
torch.Size([128])
mol_list.6.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.6.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.7.alpha_train
torch.Size([])
mol_list.7.beta_train
torch.Size([])
mol_list.7.alpha_sc
torch.Size([1])
mol_list.7.beta_sc
torch.Size([1])
mol_list.7.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.7.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.7.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.7.multihead_att_layer.V.bias
torch.Size([128])
mol_list.7.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.7.multihead_att_layer.K.bias
torch.Size([128])
mol_list.7.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.7.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.8.alpha_train
torch.Size([])
mol_list.8.beta_train
torch.Size([])
mol_list.8.alpha_sc
torch.Size([1])
mol_list.8.beta_sc
torch.Size([1])
mol_list.8.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.8.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.8.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.8.multihead_att_layer.V.bias
torch.Size([128])
mol_list.8.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.8.multihead_att_layer.K.bias
torch.Size([128])
mol_list.8.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.8.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.9.alpha_train
torch.Size([])
mol_list.9.beta_train
torch.Size([])
mol_list.9.alpha_sc
torch.Size([1])
mol_list.9.beta_sc
torch.Size([1])
mol_list.9.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.9.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.9.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.9.multihead_att_layer.V.bias
torch.Size([128])
mol_list.9.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.9.multihead_att_layer.K.bias
torch.Size([128])
mol_list.9.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.9.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.10.alpha_train
torch.Size([])
mol_list.10.beta_train
torch.Size([])
mol_list.10.alpha_sc
torch.Size([1])
mol_list.10.beta_sc
torch.Size([1])
mol_list.10.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.10.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.10.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.10.multihead_att_layer.V.bias
torch.Size([128])
mol_list.10.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.10.multihead_att_layer.K.bias
torch.Size([128])
mol_list.10.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.10.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.11.alpha_train
torch.Size([])
mol_list.11.beta_train
torch.Size([])
mol_list.11.alpha_sc
torch.Size([1])
mol_list.11.beta_sc
torch.Size([1])
mol_list.11.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.11.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.11.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.11.multihead_att_layer.V.bias
torch.Size([128])
mol_list.11.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.11.multihead_att_layer.K.bias
torch.Size([128])
mol_list.11.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.11.multihead_att_layer.Wout.bias

 19%|██████████████████▍                                                                              | 19/100 [00:02<00:07, 11.54it/s]
Epoch: 001, Runtime 1.564110, Loss 1.950669, Train: 0.8629, Val: 0.4866, Test: 0.4866, Best time: 18.2948
Epoch: 002, Runtime 0.071870, Loss 1.739861, Train: 0.9429, Val: 0.5523, Test: 0.5196, Best time: 18.2948
Epoch: 003, Runtime 0.075082, Loss 1.452241, Train: 0.9657, Val: 0.5721, Test: 0.5464, Best time: 18.2948
Epoch: 004, Runtime 0.074513, Loss 1.132431, Train: 0.9714, Val: 0.5874, Test: 0.5794, Best time: 18.2948
Epoch: 005, Runtime 0.076365, Loss 0.818715, Train: 0.9771, Val: 0.6077, Test: 0.5876, Best time: 18.2948
Epoch: 006, Runtime 0.073686, Loss 0.676256, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 007, Runtime 0.076165, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 008, Runtime 0.076733, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 009, Runtime 0.072669, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 010, Runtime 0.080984, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 011, Runtime 0.078301, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 012, Runtime 0.074024, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 013, Runtime 0.077415, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 014, Runtime 0.086071, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 015, Runtime 0.074248, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 016, Runtime 0.082425, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 017, Runtime 0.079336, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 018, Runtime 0.071130, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 019, Runtime 0.072854, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948

 43%|█████████████████████████████████████████▋                                                       | 43/100 [00:04<00:04, 12.55it/s]
Epoch: 021, Runtime 0.086317, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 022, Runtime 0.076522, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 023, Runtime 0.070684, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 024, Runtime 0.074735, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 025, Runtime 0.075089, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 026, Runtime 0.066215, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 027, Runtime 0.092769, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 028, Runtime 0.192854, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 029, Runtime 0.072956, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 030, Runtime 0.072624, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 031, Runtime 0.074292, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 032, Runtime 0.075847, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 033, Runtime 0.072433, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 034, Runtime 0.072432, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 035, Runtime 0.073873, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 036, Runtime 0.078025, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 037, Runtime 0.075194, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 038, Runtime 0.079342, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 039, Runtime 0.083534, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 040, Runtime 0.076202, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 041, Runtime 0.074782, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 042, Runtime 0.082188, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 043, Runtime 0.075353, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 044, Runtime 0.074710, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 045, Runtime 0.087530, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 046, Runtime 0.068526, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 047, Runtime 0.073756, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 048, Runtime 0.075740, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 049, Runtime 0.076000, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 050, Runtime 0.072347, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 051, Runtime 0.088246, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 052, Runtime 0.081087, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 053, Runtime 0.075497, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 054, Runtime 0.076391, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 055, Runtime 0.073488, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
 56%|██████████████████████████████████████████████████████▎                                          | 56/100 [00:06<00:04,  9.31it/s]
Traceback (most recent call last):
  File "/home/cuongnq1/graph-neural-pde/src/run_grand_ex.py", line 427, in <module>
    main(opt)
  File "/home/cuongnq1/graph-neural-pde/src/run_grand_ex.py", line 233, in main
    tmp_train_acc, tmp_val_acc, tmp_test_acc = this_test(model, data, pos_encoding, opt)
  File "/home/cuongnq1/anaconda3/envs/grand/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 28, in decorate_context
    return func(*args, **kwargs)
  File "/home/cuongnq1/graph-neural-pde/src/run_grand_ex.py", line 140, in test
    logits, accs = model(feat, pos_encoding), []
  File "/home/cuongnq1/anaconda3/envs/grand/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/cuongnq1/graph-neural-pde/src/grand_discritized.py", line 143, in forward
    out = out + self.step_size * self.mol_list[i](out) * torch.norm(out, dim=(-1), keepdim=True)**self.norm_exp
  File "/home/cuongnq1/anaconda3/envs/grand/lib/python3.9/site-packages/torch/functional.py", line 1442, in norm
    return _VF.frobenius_norm(input, _dim, keepdim=keepdim)
KeyboardInterrupt