GrandExtendDiscritizedNet
m1.weight
torch.Size([128, 500])
m1.bias
torch.Size([128])
m2.weight
torch.Size([3, 128])
m2.bias
torch.Size([3])
mol_list.0.alpha_train
torch.Size([])
mol_list.0.beta_train
torch.Size([])
mol_list.0.alpha_sc
torch.Size([1])
mol_list.0.beta_sc
torch.Size([1])
mol_list.0.multihead_att_layer.Q.weight
torch.Size([16, 128])
mol_list.0.multihead_att_layer.Q.bias
torch.Size([16])
mol_list.0.multihead_att_layer.V.weight
torch.Size([16, 128])
mol_list.0.multihead_att_layer.V.bias
torch.Size([16])
mol_list.0.multihead_att_layer.K.weight
torch.Size([16, 128])
mol_list.0.multihead_att_layer.K.bias
torch.Size([16])
mol_list.0.multihead_att_layer.Wout.weight
torch.Size([128, 16])
mol_list.0.multihead_att_layer.Wout.bias
torch.Size([128])
mol_list.1.alpha_train
torch.Size([])
mol_list.1.beta_train
torch.Size([])
mol_list.1.alpha_sc
torch.Size([1])
mol_list.1.beta_sc
torch.Size([1])
mol_list.1.multihead_att_layer.Q.weight
torch.Size([16, 128])
mol_list.1.multihead_att_layer.Q.bias
torch.Size([16])
mol_list.1.multihead_att_layer.V.weight
torch.Size([16, 128])
mol_list.1.multihead_att_layer.V.bias
torch.Size([16])
mol_list.1.multihead_att_layer.K.weight
torch.Size([16, 128])
mol_list.1.multihead_att_layer.K.bias
torch.Size([16])
mol_list.1.multihead_att_layer.Wout.weight
torch.Size([128, 16])
mol_list.1.multihead_att_layer.Wout.bias
torch.Size([128])
mol_list.2.alpha_train
torch.Size([])
mol_list.2.beta_train
torch.Size([])
mol_list.2.alpha_sc
torch.Size([1])
mol_list.2.beta_sc
torch.Size([1])
mol_list.2.multihead_att_layer.Q.weight
torch.Size([16, 128])
mol_list.2.multihead_att_layer.Q.bias
torch.Size([16])
mol_list.2.multihead_att_layer.V.weight
torch.Size([16, 128])
mol_list.2.multihead_att_layer.V.bias
torch.Size([16])
mol_list.2.multihead_att_layer.K.weight
torch.Size([16, 128])
mol_list.2.multihead_att_layer.K.bias
torch.Size([16])
mol_list.2.multihead_att_layer.Wout.weight
torch.Size([128, 16])
mol_list.2.multihead_att_layer.Wout.bias
torch.Size([128])
mol_list.3.alpha_train
torch.Size([])
mol_list.3.beta_train
torch.Size([])
mol_list.3.alpha_sc
torch.Size([1])
mol_list.3.beta_sc
torch.Size([1])
mol_list.3.multihead_att_layer.Q.weight
torch.Size([16, 128])
mol_list.3.multihead_att_layer.Q.bias
torch.Size([16])
mol_list.3.multihead_att_layer.V.weight
torch.Size([16, 128])
mol_list.3.multihead_att_layer.V.bias
torch.Size([16])
mol_list.3.multihead_att_layer.K.weight
torch.Size([16, 128])
mol_list.3.multihead_att_layer.K.bias
torch.Size([16])
mol_list.3.multihead_att_layer.Wout.weight
torch.Size([128, 16])
mol_list.3.multihead_att_layer.Wout.bias
torch.Size([128])
mol_list.4.alpha_train
torch.Size([])
mol_list.4.beta_train
torch.Size([])
mol_list.4.alpha_sc
torch.Size([1])
mol_list.4.beta_sc
torch.Size([1])
mol_list.4.multihead_att_layer.Q.weight
torch.Size([16, 128])
mol_list.4.multihead_att_layer.Q.bias
torch.Size([16])
mol_list.4.multihead_att_layer.V.weight
torch.Size([16, 128])
mol_list.4.multihead_att_layer.V.bias
torch.Size([16])
mol_list.4.multihead_att_layer.K.weight
torch.Size([16, 128])
mol_list.4.multihead_att_layer.K.bias
torch.Size([16])
mol_list.4.multihead_att_layer.Wout.weight
torch.Size([128, 16])
mol_list.4.multihead_att_layer.Wout.bias
torch.Size([128])
mol_list.5.alpha_train
torch.Size([])
mol_list.5.beta_train
torch.Size([])
mol_list.5.alpha_sc
torch.Size([1])
mol_list.5.beta_sc
torch.Size([1])
mol_list.5.multihead_att_layer.Q.weight
torch.Size([16, 128])
mol_list.5.multihead_att_layer.Q.bias
torch.Size([16])
mol_list.5.multihead_att_layer.V.weight
torch.Size([16, 128])
mol_list.5.multihead_att_layer.V.bias
torch.Size([16])
mol_list.5.multihead_att_layer.K.weight
torch.Size([16, 128])
mol_list.5.multihead_att_layer.K.bias
torch.Size([16])
mol_list.5.multihead_att_layer.Wout.weight
torch.Size([128, 16])
mol_list.5.multihead_att_layer.Wout.bias
torch.Size([128])
  0%|                                                                            | 0/600 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/cuongnq1/graph-neural-pde/src/run_grand_ex.py", line 427, in <module>
    main(opt)
  File "/home/cuongnq1/graph-neural-pde/src/run_grand_ex.py", line 232, in main
    loss = train(model, optimizer, data, pos_encoding)
  File "/home/cuongnq1/graph-neural-pde/src/run_grand_ex.py", line 68, in train
    out = model(feat, pos_encoding)
  File "/home/cuongnq1/anaconda3/envs/grand/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/cuongnq1/graph-neural-pde/src/grand_discritized.py", line 121, in forward
    x = self.m1(x)
  File "/home/cuongnq1/anaconda3/envs/grand/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/cuongnq1/anaconda3/envs/grand/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/cuongnq1/anaconda3/envs/grand/lib/python3.9/site-packages/torch/nn/functional.py", line 1848, in linear
    return torch._C._nn.linear(input, weight, bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`