
  0%|                                      | 0/100 [00:00<?, ?it/s]
GrandExtendDiscritizedNet
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
mol_list.0.alpha_train
torch.Size([])
mol_list.0.beta_train
torch.Size([])
mol_list.0.alpha_sc
torch.Size([1])
mol_list.0.beta_sc
torch.Size([1])
mol_list.0.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.0.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.V.bias
torch.Size([128])
mol_list.0.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.K.bias
torch.Size([128])
mol_list.0.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.0.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.1.alpha_train
torch.Size([])
mol_list.1.beta_train
torch.Size([])
mol_list.1.alpha_sc
torch.Size([1])
mol_list.1.beta_sc
torch.Size([1])
mol_list.1.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.1.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.V.bias
torch.Size([128])
mol_list.1.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.K.bias
torch.Size([128])
mol_list.1.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.1.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.2.alpha_train
torch.Size([])
mol_list.2.beta_train
torch.Size([])
mol_list.2.alpha_sc
torch.Size([1])
mol_list.2.beta_sc
torch.Size([1])
mol_list.2.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.2.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.V.bias
torch.Size([128])
mol_list.2.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.K.bias
torch.Size([128])
mol_list.2.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.2.multihead_att_layer.Wout.bias
torch.Size([80])
Epoch: 001, Runtime 1.481692, Loss 1.947088, Train: 0.1714, Val: 0.1321, Test: 0.1567, Best time: 18.2948
Epoch: 002, Runtime 0.031735, Loss 279444.437500, Train: 0.2457, Val: 0.2022, Test: 0.2082, Best time: 18.2948
Epoch: 003, Runtime 0.025817, Loss 769.887024, Train: 0.1657, Val: 0.1052, Test: 0.1052, Best time: 18.2948
Epoch: 004, Runtime 0.024309, Loss 5418482.000000, Train: 0.2000, Val: 0.1699, Test: 0.1505, Best time: 18.2948
Epoch: 005, Runtime 0.022360, Loss 347490877440.000000, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 006, Runtime 0.025137, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 007, Runtime 0.028421, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 008, Runtime 0.028100, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 009, Runtime 0.024055, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 010, Runtime 0.026187, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 011, Runtime 0.022981, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 012, Runtime 0.024280, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 013, Runtime 0.024338, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 014, Runtime 0.025023, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 015, Runtime 0.024547, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 016, Runtime 0.024378, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 017, Runtime 0.022831, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 018, Runtime 0.025182, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 019, Runtime 0.022302, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 020, Runtime 0.044965, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 021, Runtime 0.031266, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 022, Runtime 0.023015, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 023, Runtime 0.022899, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 024, Runtime 0.025448, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 025, Runtime 0.023786, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 026, Runtime 0.023638, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 027, Runtime 0.022523, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 028, Runtime 0.022992, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 029, Runtime 0.023947, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 030, Runtime 0.024548, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 031, Runtime 0.023036, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 032, Runtime 0.027653, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 033, Runtime 0.022407, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 034, Runtime 0.022180, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 035, Runtime 0.022108, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 036, Runtime 0.023198, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 037, Runtime 0.023128, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 038, Runtime 0.024738, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 039, Runtime 0.023639, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 040, Runtime 0.027016, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 041, Runtime 0.041676, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 042, Runtime 0.025510, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 043, Runtime 0.028891, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 044, Runtime 0.026108, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 045, Runtime 0.025893, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 046, Runtime 0.023350, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 047, Runtime 0.023353, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 048, Runtime 0.023891, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 049, Runtime 0.023866, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 050, Runtime 0.024766, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 051, Runtime 0.026240, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 052, Runtime 0.024374, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 053, Runtime 0.028008, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 054, Runtime 0.024714, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 055, Runtime 0.024873, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 056, Runtime 0.023252, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 057, Runtime 0.023764, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 058, Runtime 0.024143, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 059, Runtime 0.042637, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 060, Runtime 0.028562, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 061, Runtime 0.030141, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 062, Runtime 0.024403, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 063, Runtime 0.030014, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 064, Runtime 0.030771, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 065, Runtime 0.032783, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 066, Runtime 0.026495, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 067, Runtime 0.025044, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 068, Runtime 0.026411, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 069, Runtime 0.026917, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 070, Runtime 0.026284, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 071, Runtime 0.025557, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 072, Runtime 0.027016, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 073, Runtime 0.025749, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 074, Runtime 0.028619, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 075, Runtime 0.025135, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948

 92%|██████████████████████████▋  | 92/100 [00:03<00:00, 38.12it/s]
Epoch: 077, Runtime 0.035547, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 078, Runtime 0.029153, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 079, Runtime 0.023854, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 080, Runtime 0.027099, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 081, Runtime 0.023910, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 082, Runtime 0.025954, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 083, Runtime 0.023386, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 084, Runtime 0.024633, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 085, Runtime 0.027053, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 086, Runtime 0.026268, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 087, Runtime 0.024514, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 088, Runtime 0.023209, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 089, Runtime 0.024846, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 090, Runtime 0.023933, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 091, Runtime 0.023482, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 092, Runtime 0.022763, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 093, Runtime 0.023182, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 094, Runtime 0.021600, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 095, Runtime 0.048985, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 096, Runtime 0.044090, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 097, Runtime 0.025522, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 098, Runtime 0.023023, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 099, Runtime 0.029057, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 100, Runtime 0.025824, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948

100%|████████████████████████████| 100/100 [00:04<00:00, 24.07it/s]