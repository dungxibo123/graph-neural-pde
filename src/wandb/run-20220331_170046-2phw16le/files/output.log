GrandExtendDiscritizedNet
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
mol_list.0.alpha_train
torch.Size([])
mol_list.0.beta_train
torch.Size([])
mol_list.0.alpha_sc
torch.Size([1])
mol_list.0.beta_sc
torch.Size([1])
mol_list.0.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.0.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.V.bias
torch.Size([128])
mol_list.0.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.K.bias
torch.Size([128])
mol_list.0.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.0.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.1.alpha_train
torch.Size([])
mol_list.1.beta_train
torch.Size([])
mol_list.1.alpha_sc
torch.Size([1])
mol_list.1.beta_sc
torch.Size([1])
mol_list.1.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.1.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.V.bias
torch.Size([128])
mol_list.1.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.K.bias
torch.Size([128])
mol_list.1.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.1.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.2.alpha_train
torch.Size([])
mol_list.2.beta_train
torch.Size([])
mol_list.2.alpha_sc
torch.Size([1])
mol_list.2.beta_sc
torch.Size([1])
mol_list.2.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.2.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.V.bias
torch.Size([128])
mol_list.2.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.K.bias
torch.Size([128])
mol_list.2.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.2.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.3.alpha_train
torch.Size([])
mol_list.3.beta_train
torch.Size([])
mol_list.3.alpha_sc
torch.Size([1])
mol_list.3.beta_sc
torch.Size([1])
mol_list.3.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.3.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.V.bias
torch.Size([128])
mol_list.3.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.K.bias
torch.Size([128])
mol_list.3.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.3.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.4.alpha_train
torch.Size([])
mol_list.4.beta_train
torch.Size([])
mol_list.4.alpha_sc
torch.Size([1])
mol_list.4.beta_sc
torch.Size([1])
mol_list.4.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.4.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.V.bias
torch.Size([128])
mol_list.4.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.K.bias
torch.Size([128])
mol_list.4.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.4.multihead_att_layer.Wout.bias
torch.Size([80])
 12%|███████████▋                                                                                     | 12/100 [00:01<00:07, 11.22it/s]
Epoch: 001, Runtime 1.381070, Loss 1.945676, Train: 0.8686, Val: 0.3485, Test: 0.3175, Best time: 18.2948
Epoch: 002, Runtime 0.028264, Loss 1.751597, Train: 0.9657, Val: 0.4822, Test: 0.4454, Best time: 18.2948
Epoch: 003, Runtime 0.029132, Loss 1.466910, Train: 0.9600, Val: 0.5162, Test: 0.5010, Best time: 18.2948
Epoch: 004, Runtime 0.029405, Loss 1.137952, Train: 0.9600, Val: 0.5321, Test: 0.5361, Best time: 18.2948
Epoch: 005, Runtime 0.030649, Loss 0.862675, Train: 0.9771, Val: 0.5452, Test: 0.5649, Best time: 18.2948
Epoch: 006, Runtime 0.029948, Loss 0.607218, Train: 0.9829, Val: 0.5584, Test: 0.5711, Best time: 18.2948
Epoch: 007, Runtime 0.034528, Loss 0.440616, Train: 0.9771, Val: 0.5649, Test: 0.5856, Best time: 18.2948
Epoch: 008, Runtime 0.031046, Loss 0.346102, Train: 0.9771, Val: 0.5715, Test: 0.5897, Best time: 18.2948
Epoch: 009, Runtime 0.029506, Loss 0.307560, Train: 0.9943, Val: 0.5753, Test: 0.5897, Best time: 18.2948
Epoch: 010, Runtime 0.033281, Loss 0.225528, Train: 1.0000, Val: 0.5715, Test: 0.5918, Best time: 18.2948
Epoch: 011, Runtime 0.032497, Loss 0.261502, Train: 1.0000, Val: 0.5666, Test: 0.5814, Best time: 18.2948
Epoch: 012, Runtime 0.032863, Loss 0.198828, Train: 1.0000, Val: 0.5693, Test: 0.5856, Best time: 18.2948
Epoch: 013, Runtime 0.031384, Loss 0.204158, Train: 1.0000, Val: 0.5688, Test: 0.5773, Best time: 18.2948
Epoch: 014, Runtime 0.029423, Loss 0.130162, Train: 1.0000, Val: 0.5721, Test: 0.5814, Best time: 18.2948
Epoch: 015, Runtime 0.063778, Loss 0.139481, Train: 1.0000, Val: 0.5759, Test: 0.5794, Best time: 18.2948
Epoch: 016, Runtime 0.033945, Loss 0.143569, Train: 1.0000, Val: 0.5808, Test: 0.5732, Best time: 18.2948
Epoch: 017, Runtime 0.034037, Loss 0.127672, Train: 1.0000, Val: 0.5901, Test: 0.5835, Best time: 18.2948
Epoch: 018, Runtime 0.030805, Loss 0.146136, Train: 1.0000, Val: 0.5962, Test: 0.5835, Best time: 18.2948
Epoch: 019, Runtime 0.029847, Loss 0.195016, Train: 1.0000, Val: 0.5890, Test: 0.5732, Best time: 18.2948
Epoch: 020, Runtime 0.029244, Loss 0.170481, Train: 1.0000, Val: 0.5847, Test: 0.5691, Best time: 18.2948
Epoch: 021, Runtime 0.033531, Loss 0.215237, Train: 1.0000, Val: 0.5710, Test: 0.5691, Best time: 18.2948
Epoch: 022, Runtime 0.030990, Loss 0.175291, Train: 1.0000, Val: 0.5605, Test: 0.5629, Best time: 18.2948
Epoch: 023, Runtime 0.032365, Loss 0.197659, Train: 1.0000, Val: 0.5512, Test: 0.5588, Best time: 18.2948
Epoch: 024, Runtime 0.031496, Loss 0.192139, Train: 1.0000, Val: 0.5425, Test: 0.5526, Best time: 18.2948
Epoch: 025, Runtime 0.031881, Loss 0.218553, Train: 1.0000, Val: 0.5392, Test: 0.5567, Best time: 18.2948
Epoch: 026, Runtime 0.032618, Loss 0.170432, Train: 1.0000, Val: 0.5452, Test: 0.5526, Best time: 18.2948
Epoch: 027, Runtime 0.028743, Loss 0.220348, Train: 1.0000, Val: 0.5479, Test: 0.5567, Best time: 18.2948
Epoch: 028, Runtime 0.033167, Loss 0.187737, Train: 1.0000, Val: 0.5551, Test: 0.5588, Best time: 18.2948
Epoch: 029, Runtime 0.036036, Loss 0.188023, Train: 1.0000, Val: 0.5600, Test: 0.5588, Best time: 18.2948
Epoch: 030, Runtime 0.046112, Loss 0.209434, Train: 1.0000, Val: 0.5710, Test: 0.5649, Best time: 18.2948
Epoch: 031, Runtime 0.030941, Loss 0.207945, Train: 1.0000, Val: 0.5704, Test: 0.5670, Best time: 18.2948
Epoch: 032, Runtime 0.033001, Loss 0.224818, Train: 1.0000, Val: 0.5781, Test: 0.5670, Best time: 18.2948
Epoch: 033, Runtime 0.033590, Loss 0.207938, Train: 1.0000, Val: 0.5786, Test: 0.5691, Best time: 18.2948
Epoch: 034, Runtime 0.030503, Loss 0.191368, Train: 1.0000, Val: 0.5896, Test: 0.5567, Best time: 18.2948
Epoch: 035, Runtime 0.032756, Loss 0.219104, Train: 1.0000, Val: 0.5967, Test: 0.5567, Best time: 18.2948
Epoch: 036, Runtime 0.034699, Loss 0.147682, Train: 1.0000, Val: 0.5858, Test: 0.5443, Best time: 18.2948
Epoch: 037, Runtime 0.032317, Loss 0.173801, Train: 1.0000, Val: 0.5584, Test: 0.5361, Best time: 18.2948
Epoch: 038, Runtime 0.032988, Loss 0.200593, Train: 1.0000, Val: 0.5479, Test: 0.5237, Best time: 18.2948
Epoch: 039, Runtime 0.032325, Loss 0.200381, Train: 1.0000, Val: 0.5370, Test: 0.5175, Best time: 18.2948
Epoch: 040, Runtime 0.031806, Loss 0.218840, Train: 1.0000, Val: 0.5441, Test: 0.5216, Best time: 18.2948
Epoch: 041, Runtime 0.031579, Loss 0.179820, Train: 1.0000, Val: 0.5523, Test: 0.5320, Best time: 18.2948
Epoch: 042, Runtime 0.029827, Loss 0.170189, Train: 1.0000, Val: 0.5589, Test: 0.5423, Best time: 18.2948
Epoch: 043, Runtime 0.031945, Loss 0.190002, Train: 1.0000, Val: 0.5638, Test: 0.5464, Best time: 18.2948
Epoch: 044, Runtime 0.032091, Loss 0.185094, Train: 1.0000, Val: 0.5649, Test: 0.5526, Best time: 18.2948
Epoch: 045, Runtime 0.045990, Loss 0.175806, Train: 1.0000, Val: 0.5638, Test: 0.5588, Best time: 18.2948
Epoch: 046, Runtime 0.031248, Loss 0.190280, Train: 1.0000, Val: 0.5616, Test: 0.5485, Best time: 18.2948
Epoch: 047, Runtime 0.030957, Loss 0.160478, Train: 1.0000, Val: 0.5605, Test: 0.5505, Best time: 18.2948
Epoch: 048, Runtime 0.030372, Loss 0.136334, Train: 1.0000, Val: 0.5567, Test: 0.5485, Best time: 18.2948
Epoch: 049, Runtime 0.031588, Loss 0.149138, Train: 1.0000, Val: 0.5573, Test: 0.5485, Best time: 18.2948
Epoch: 050, Runtime 0.033841, Loss 0.188428, Train: 1.0000, Val: 0.5633, Test: 0.5526, Best time: 18.2948
Epoch: 051, Runtime 0.030064, Loss 0.155479, Train: 1.0000, Val: 0.5649, Test: 0.5505, Best time: 18.2948
Epoch: 052, Runtime 0.031310, Loss 0.210965, Train: 1.0000, Val: 0.5715, Test: 0.5711, Best time: 18.2948
Epoch: 053, Runtime 0.032768, Loss 0.172364, Train: 1.0000, Val: 0.5737, Test: 0.5711, Best time: 18.2948
Epoch: 054, Runtime 0.030082, Loss 0.190294, Train: 1.0000, Val: 0.5721, Test: 0.5794, Best time: 18.2948
Epoch: 055, Runtime 0.033535, Loss 0.152560, Train: 1.0000, Val: 0.5655, Test: 0.5794, Best time: 18.2948
Epoch: 056, Runtime 0.038371, Loss 0.147863, Train: 1.0000, Val: 0.5633, Test: 0.5711, Best time: 18.2948
Epoch: 057, Runtime 0.031515, Loss 0.163494, Train: 1.0000, Val: 0.5567, Test: 0.5691, Best time: 18.2948
Epoch: 058, Runtime 0.032081, Loss 0.134374, Train: 1.0000, Val: 0.5479, Test: 0.5526, Best time: 18.2948


100%|████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:04<00:00, 20.56it/s]
Epoch: 060, Runtime 0.039474, Loss 0.148051, Train: 1.0000, Val: 0.5277, Test: 0.5320, Best time: 18.2948
Epoch: 061, Runtime 0.031948, Loss 0.143493, Train: 1.0000, Val: 0.5249, Test: 0.5299, Best time: 18.2948
Epoch: 062, Runtime 0.038783, Loss 0.141658, Train: 1.0000, Val: 0.5249, Test: 0.5361, Best time: 18.2948
Epoch: 063, Runtime 0.032935, Loss 0.146858, Train: 1.0000, Val: 0.5332, Test: 0.5402, Best time: 18.2948
Epoch: 064, Runtime 0.034410, Loss 0.168441, Train: 1.0000, Val: 0.5370, Test: 0.5608, Best time: 18.2948
Epoch: 065, Runtime 0.032101, Loss 0.128802, Train: 1.0000, Val: 0.5452, Test: 0.5691, Best time: 18.2948
Epoch: 066, Runtime 0.041565, Loss 0.177048, Train: 1.0000, Val: 0.5458, Test: 0.5670, Best time: 18.2948
Epoch: 067, Runtime 0.032875, Loss 0.146078, Train: 1.0000, Val: 0.5523, Test: 0.5711, Best time: 18.2948
Epoch: 068, Runtime 0.035660, Loss 0.152779, Train: 1.0000, Val: 0.5545, Test: 0.5814, Best time: 18.2948
Epoch: 069, Runtime 0.034930, Loss 0.161743, Train: 1.0000, Val: 0.5627, Test: 0.5897, Best time: 18.2948
Epoch: 070, Runtime 0.033598, Loss 0.156632, Train: 1.0000, Val: 0.5688, Test: 0.5876, Best time: 18.2948
Epoch: 071, Runtime 0.034769, Loss 0.142956, Train: 1.0000, Val: 0.5682, Test: 0.5876, Best time: 18.2948
Epoch: 072, Runtime 0.031901, Loss 0.155528, Train: 1.0000, Val: 0.5732, Test: 0.5918, Best time: 18.2948
Epoch: 073, Runtime 0.065489, Loss 0.181027, Train: 1.0000, Val: 0.5759, Test: 0.5856, Best time: 18.2948
Epoch: 074, Runtime 0.035385, Loss 0.160126, Train: 1.0000, Val: 0.5759, Test: 0.5835, Best time: 18.2948
Epoch: 075, Runtime 0.031098, Loss 0.158270, Train: 1.0000, Val: 0.5704, Test: 0.5753, Best time: 18.2948
Epoch: 076, Runtime 0.031827, Loss 0.164546, Train: 1.0000, Val: 0.5622, Test: 0.5773, Best time: 18.2948
Epoch: 077, Runtime 0.034364, Loss 0.168108, Train: 1.0000, Val: 0.5595, Test: 0.5670, Best time: 18.2948
Epoch: 078, Runtime 0.034998, Loss 0.158279, Train: 1.0000, Val: 0.5540, Test: 0.5526, Best time: 18.2948
Epoch: 079, Runtime 0.030866, Loss 0.213410, Train: 1.0000, Val: 0.5512, Test: 0.5464, Best time: 18.2948
Epoch: 080, Runtime 0.033919, Loss 0.180098, Train: 1.0000, Val: 0.5507, Test: 0.5361, Best time: 18.2948
Epoch: 081, Runtime 0.034728, Loss 0.162081, Train: 1.0000, Val: 0.5479, Test: 0.5299, Best time: 18.2948
Epoch: 082, Runtime 0.032294, Loss 0.184041, Train: 1.0000, Val: 0.5496, Test: 0.5278, Best time: 18.2948
Epoch: 083, Runtime 0.031668, Loss 0.143955, Train: 1.0000, Val: 0.5474, Test: 0.5340, Best time: 18.2948
Epoch: 084, Runtime 0.035685, Loss 0.159436, Train: 1.0000, Val: 0.5468, Test: 0.5443, Best time: 18.2948
Epoch: 085, Runtime 0.031439, Loss 0.200241, Train: 1.0000, Val: 0.5468, Test: 0.5402, Best time: 18.2948
Epoch: 086, Runtime 0.031205, Loss 0.157801, Train: 1.0000, Val: 0.5611, Test: 0.5464, Best time: 18.2948
Epoch: 087, Runtime 0.035850, Loss 0.186104, Train: 1.0000, Val: 0.5699, Test: 0.5588, Best time: 18.2948
Epoch: 088, Runtime 0.164595, Loss 0.151541, Train: 1.0000, Val: 0.5742, Test: 0.5732, Best time: 18.2948
Epoch: 089, Runtime 0.030390, Loss 0.127143, Train: 1.0000, Val: 0.5737, Test: 0.5876, Best time: 18.2948
Epoch: 090, Runtime 0.028009, Loss 0.147797, Train: 1.0000, Val: 0.5715, Test: 0.5938, Best time: 18.2948
Epoch: 091, Runtime 0.027900, Loss 0.150908, Train: 1.0000, Val: 0.5693, Test: 0.5856, Best time: 18.2948
Epoch: 092, Runtime 0.025137, Loss 0.126992, Train: 1.0000, Val: 0.5666, Test: 0.5814, Best time: 18.2948
Epoch: 093, Runtime 0.029037, Loss 0.177439, Train: 1.0000, Val: 0.5633, Test: 0.5773, Best time: 18.2948
Epoch: 094, Runtime 0.030463, Loss 0.196841, Train: 1.0000, Val: 0.5512, Test: 0.5753, Best time: 18.2948
Epoch: 095, Runtime 0.032863, Loss 0.141259, Train: 1.0000, Val: 0.5474, Test: 0.5753, Best time: 18.2948
Epoch: 096, Runtime 0.035165, Loss 0.186163, Train: 1.0000, Val: 0.5490, Test: 0.5711, Best time: 18.2948
Epoch: 097, Runtime 0.030340, Loss 0.167856, Train: 1.0000, Val: 0.5501, Test: 0.5711, Best time: 18.2948
Epoch: 098, Runtime 0.026411, Loss 0.173872, Train: 1.0000, Val: 0.5523, Test: 0.5691, Best time: 18.2948
Epoch: 099, Runtime 0.028561, Loss 0.183976, Train: 1.0000, Val: 0.5584, Test: 0.5753, Best time: 18.2948
Epoch: 100, Runtime 0.030416, Loss 0.158526, Train: 1.0000, Val: 0.5600, Test: 0.5732, Best time: 18.2948
best val accuracy 0.560000 with test accuracy 0.573196 at epoch 35 and best time 18.294754