GrandExtendDiscritizedNet
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
mol_list.0.alpha_train
torch.Size([])
mol_list.0.beta_train
torch.Size([])
mol_list.0.alpha_sc
torch.Size([1])
mol_list.0.beta_sc
torch.Size([1])
mol_list.0.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.0.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.V.bias
torch.Size([128])
mol_list.0.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.K.bias
torch.Size([128])
mol_list.0.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.0.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.1.alpha_train
torch.Size([])
mol_list.1.beta_train
torch.Size([])
mol_list.1.alpha_sc
torch.Size([1])
mol_list.1.beta_sc
torch.Size([1])
mol_list.1.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.1.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.V.bias
torch.Size([128])
mol_list.1.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.K.bias
torch.Size([128])
mol_list.1.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.1.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.2.alpha_train
torch.Size([])
mol_list.2.beta_train
torch.Size([])
mol_list.2.alpha_sc
torch.Size([1])
mol_list.2.beta_sc
torch.Size([1])
mol_list.2.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.2.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.V.bias
torch.Size([128])
mol_list.2.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.K.bias
torch.Size([128])
mol_list.2.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.2.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.3.alpha_train
torch.Size([])
mol_list.3.beta_train
torch.Size([])
mol_list.3.alpha_sc
torch.Size([1])
mol_list.3.beta_sc
torch.Size([1])
mol_list.3.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.3.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.V.bias
torch.Size([128])
mol_list.3.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.K.bias
torch.Size([128])
mol_list.3.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.3.multihead_att_layer.Wout.bias
torch.Size([80])

 21%|██████                       | 21/100 [00:02<00:04, 16.59it/s]
Epoch: 001, Runtime 1.352283, Loss 1.948869, Train: 0.8800, Val: 0.4773, Test: 0.4515, Best time: 18.2948
Epoch: 002, Runtime 0.042481, Loss 1.729675, Train: 0.9486, Val: 0.4970, Test: 0.4763, Best time: 18.2948
Epoch: 003, Runtime 0.041587, Loss 1.440226, Train: 0.9714, Val: 0.5129, Test: 0.5052, Best time: 18.2948
Epoch: 004, Runtime 0.041991, Loss 1.106043, Train: 0.9771, Val: 0.5200, Test: 0.5216, Best time: 18.2948
Epoch: 005, Runtime 0.043665, Loss 0.819034, Train: 0.9771, Val: 0.5562, Test: 0.5505, Best time: 18.2948
Epoch: 006, Runtime 0.042656, Loss 0.578387, Train: 0.9886, Val: 0.5858, Test: 0.5814, Best time: 18.2948
Epoch: 007, Runtime 0.045979, Loss 0.432404, Train: 0.9886, Val: 0.5951, Test: 0.5938, Best time: 18.2948
Epoch: 008, Runtime 0.059612, Loss 0.275090, Train: 0.9886, Val: 0.6005, Test: 0.6021, Best time: 18.2948
Epoch: 009, Runtime 0.049142, Loss 0.285956, Train: 0.9886, Val: 0.6038, Test: 0.6144, Best time: 18.2948
Epoch: 010, Runtime 0.042783, Loss 0.179140, Train: 0.9886, Val: 0.6049, Test: 0.6124, Best time: 18.2948
Epoch: 011, Runtime 0.046678, Loss 0.184490, Train: 0.9886, Val: 0.6088, Test: 0.6124, Best time: 18.2948
Epoch: 012, Runtime 0.062492, Loss 0.169256, Train: 0.9886, Val: 0.6093, Test: 0.6165, Best time: 18.2948
Epoch: 013, Runtime 0.054911, Loss 0.117650, Train: 0.9943, Val: 0.6060, Test: 0.6041, Best time: 18.2948
Epoch: 014, Runtime 0.040059, Loss 0.120877, Train: 1.0000, Val: 0.5978, Test: 0.5979, Best time: 18.2948
Epoch: 015, Runtime 0.040397, Loss 0.196433, Train: 1.0000, Val: 0.5825, Test: 0.5876, Best time: 18.2948
Epoch: 016, Runtime 0.043237, Loss 0.109159, Train: 1.0000, Val: 0.5753, Test: 0.6000, Best time: 18.2948
Epoch: 017, Runtime 0.042813, Loss 0.142005, Train: 1.0000, Val: 0.5726, Test: 0.5979, Best time: 18.2948
Epoch: 018, Runtime 0.049728, Loss 0.143571, Train: 1.0000, Val: 0.5704, Test: 0.5938, Best time: 18.2948
Epoch: 019, Runtime 0.050448, Loss 0.140726, Train: 1.0000, Val: 0.5704, Test: 0.5959, Best time: 18.2948
Epoch: 020, Runtime 0.057234, Loss 0.119251, Train: 1.0000, Val: 0.5611, Test: 0.5876, Best time: 18.2948
Epoch: 021, Runtime 0.041977, Loss 0.123881, Train: 1.0000, Val: 0.5540, Test: 0.5856, Best time: 18.2948

 63%|██████████████████▎          | 63/100 [00:04<00:01, 22.97it/s]
Epoch: 023, Runtime 0.065913, Loss 0.115024, Train: 1.0000, Val: 0.5359, Test: 0.5423, Best time: 18.2948
Epoch: 024, Runtime 0.051106, Loss 0.161157, Train: 1.0000, Val: 0.5364, Test: 0.5381, Best time: 18.2948
Epoch: 025, Runtime 0.045084, Loss 0.208882, Train: 1.0000, Val: 0.5288, Test: 0.5320, Best time: 18.2948
Epoch: 026, Runtime 0.039060, Loss 0.130927, Train: 1.0000, Val: 0.5342, Test: 0.5402, Best time: 18.2948
Epoch: 027, Runtime 0.041768, Loss 0.169587, Train: 1.0000, Val: 0.5430, Test: 0.5485, Best time: 18.2948
Epoch: 028, Runtime 0.043033, Loss 0.169067, Train: 1.0000, Val: 0.5540, Test: 0.5588, Best time: 18.2948
Epoch: 029, Runtime 0.054309, Loss 0.187831, Train: 1.0000, Val: 0.5595, Test: 0.5649, Best time: 18.2948
Epoch: 030, Runtime 0.046375, Loss 0.251649, Train: 1.0000, Val: 0.5677, Test: 0.5588, Best time: 18.2948
Epoch: 031, Runtime 0.036204, Loss 0.155690, Train: 1.0000, Val: 0.5710, Test: 0.5649, Best time: 18.2948
Epoch: 032, Runtime 0.045249, Loss 0.153797, Train: 1.0000, Val: 0.5677, Test: 0.5608, Best time: 18.2948
Epoch: 033, Runtime 0.075814, Loss 0.194612, Train: 1.0000, Val: 0.5578, Test: 0.5505, Best time: 18.2948
Epoch: 034, Runtime 0.042758, Loss 0.175057, Train: 1.0000, Val: 0.5507, Test: 0.5485, Best time: 18.2948
Epoch: 035, Runtime 0.042311, Loss 0.142358, Train: 1.0000, Val: 0.5523, Test: 0.5381, Best time: 18.2948
Epoch: 036, Runtime 0.042329, Loss 0.165037, Train: 1.0000, Val: 0.5578, Test: 0.5340, Best time: 18.2948
Epoch: 037, Runtime 0.041968, Loss 0.159359, Train: 1.0000, Val: 0.5589, Test: 0.5361, Best time: 18.2948
Epoch: 038, Runtime 0.052305, Loss 0.127213, Train: 1.0000, Val: 0.5611, Test: 0.5546, Best time: 18.2948
Epoch: 039, Runtime 0.059414, Loss 0.155366, Train: 1.0000, Val: 0.5649, Test: 0.5608, Best time: 18.2948
Epoch: 040, Runtime 0.043597, Loss 0.208251, Train: 1.0000, Val: 0.5660, Test: 0.5546, Best time: 18.2948
Epoch: 041, Runtime 0.048353, Loss 0.122391, Train: 1.0000, Val: 0.5726, Test: 0.5588, Best time: 18.2948
Epoch: 042, Runtime 0.037758, Loss 0.136088, Train: 1.0000, Val: 0.5715, Test: 0.5526, Best time: 18.2948
Epoch: 043, Runtime 0.041348, Loss 0.140041, Train: 1.0000, Val: 0.5715, Test: 0.5505, Best time: 18.2948
Epoch: 044, Runtime 0.044341, Loss 0.162871, Train: 1.0000, Val: 0.5704, Test: 0.5546, Best time: 18.2948
Epoch: 045, Runtime 0.042533, Loss 0.153587, Train: 1.0000, Val: 0.5611, Test: 0.5546, Best time: 18.2948
Epoch: 046, Runtime 0.041648, Loss 0.132023, Train: 1.0000, Val: 0.5567, Test: 0.5546, Best time: 18.2948
Epoch: 047, Runtime 0.040836, Loss 0.193520, Train: 1.0000, Val: 0.5589, Test: 0.5546, Best time: 18.2948
Epoch: 048, Runtime 0.040706, Loss 0.134552, Train: 1.0000, Val: 0.5589, Test: 0.5526, Best time: 18.2948
Epoch: 049, Runtime 0.041732, Loss 0.135463, Train: 1.0000, Val: 0.5589, Test: 0.5464, Best time: 18.2948
Epoch: 050, Runtime 0.044774, Loss 0.138730, Train: 1.0000, Val: 0.5605, Test: 0.5464, Best time: 18.2948
Epoch: 051, Runtime 0.052815, Loss 0.168039, Train: 1.0000, Val: 0.5616, Test: 0.5443, Best time: 18.2948
Epoch: 052, Runtime 0.051690, Loss 0.168353, Train: 1.0000, Val: 0.5578, Test: 0.5464, Best time: 18.2948
Epoch: 053, Runtime 0.040623, Loss 0.136011, Train: 1.0000, Val: 0.5485, Test: 0.5567, Best time: 18.2948
Epoch: 054, Runtime 0.028604, Loss 0.111186, Train: 1.0000, Val: 0.5441, Test: 0.5670, Best time: 18.2948
Epoch: 055, Runtime 0.046579, Loss 0.104028, Train: 1.0000, Val: 0.5463, Test: 0.5691, Best time: 18.2948
Epoch: 056, Runtime 0.043050, Loss 0.123562, Train: 1.0000, Val: 0.5436, Test: 0.5629, Best time: 18.2948
Epoch: 057, Runtime 0.042224, Loss 0.152607, Train: 1.0000, Val: 0.5468, Test: 0.5546, Best time: 18.2948
Epoch: 058, Runtime 0.041102, Loss 0.135379, Train: 1.0000, Val: 0.5430, Test: 0.5649, Best time: 18.2948
Epoch: 059, Runtime 0.041640, Loss 0.118663, Train: 1.0000, Val: 0.5479, Test: 0.5691, Best time: 18.2948
Epoch: 060, Runtime 0.037160, Loss 0.157067, Train: 1.0000, Val: 0.5518, Test: 0.5670, Best time: 18.2948
Epoch: 061, Runtime 0.039906, Loss 0.166907, Train: 1.0000, Val: 0.5534, Test: 0.5485, Best time: 18.2948
Epoch: 062, Runtime 0.041964, Loss 0.137709, Train: 1.0000, Val: 0.5518, Test: 0.5505, Best time: 18.2948
Epoch: 063, Runtime 0.041318, Loss 0.176703, Train: 1.0000, Val: 0.5545, Test: 0.5464, Best time: 18.2948
Epoch: 064, Runtime 0.043020, Loss 0.128368, Train: 1.0000, Val: 0.5567, Test: 0.5485, Best time: 18.2948
Epoch: 065, Runtime 0.040511, Loss 0.159334, Train: 1.0000, Val: 0.5655, Test: 0.5505, Best time: 18.2948

100%|████████████████████████████| 100/100 [00:06<00:00, 16.59it/s]
Epoch: 067, Runtime 0.068290, Loss 0.145189, Train: 1.0000, Val: 0.5534, Test: 0.5423, Best time: 18.2948
Epoch: 068, Runtime 0.039736, Loss 0.134165, Train: 1.0000, Val: 0.5529, Test: 0.5381, Best time: 18.2948
Epoch: 069, Runtime 0.040872, Loss 0.128163, Train: 1.0000, Val: 0.5562, Test: 0.5402, Best time: 18.2948
Epoch: 070, Runtime 0.042629, Loss 0.135966, Train: 1.0000, Val: 0.5567, Test: 0.5464, Best time: 18.2948
Epoch: 071, Runtime 0.041481, Loss 0.135062, Train: 1.0000, Val: 0.5578, Test: 0.5443, Best time: 18.2948
Epoch: 072, Runtime 0.045296, Loss 0.130899, Train: 1.0000, Val: 0.5611, Test: 0.5402, Best time: 18.2948
Epoch: 073, Runtime 0.041699, Loss 0.126475, Train: 1.0000, Val: 0.5633, Test: 0.5340, Best time: 18.2948
Epoch: 074, Runtime 0.040576, Loss 0.137227, Train: 1.0000, Val: 0.5595, Test: 0.5361, Best time: 18.2948
Epoch: 075, Runtime 0.038123, Loss 0.137975, Train: 1.0000, Val: 0.5622, Test: 0.5485, Best time: 18.2948
Epoch: 076, Runtime 0.046967, Loss 0.145671, Train: 1.0000, Val: 0.5633, Test: 0.5505, Best time: 18.2948
Epoch: 077, Runtime 0.072613, Loss 0.199309, Train: 1.0000, Val: 0.5649, Test: 0.5588, Best time: 18.2948
Epoch: 078, Runtime 0.063918, Loss 0.130093, Train: 1.0000, Val: 0.5616, Test: 0.5546, Best time: 18.2948
Epoch: 079, Runtime 0.052501, Loss 0.130546, Train: 1.0000, Val: 0.5589, Test: 0.5485, Best time: 18.2948
Epoch: 080, Runtime 0.042149, Loss 0.126993, Train: 1.0000, Val: 0.5496, Test: 0.5381, Best time: 18.2948
Epoch: 081, Runtime 0.043073, Loss 0.140231, Train: 1.0000, Val: 0.5447, Test: 0.5381, Best time: 18.2948
Epoch: 082, Runtime 0.043514, Loss 0.137469, Train: 1.0000, Val: 0.5479, Test: 0.5464, Best time: 18.2948
Epoch: 083, Runtime 0.041371, Loss 0.151746, Train: 1.0000, Val: 0.5468, Test: 0.5423, Best time: 18.2948
Epoch: 084, Runtime 0.040261, Loss 0.128033, Train: 1.0000, Val: 0.5485, Test: 0.5505, Best time: 18.2948
Epoch: 085, Runtime 0.044719, Loss 0.116328, Train: 1.0000, Val: 0.5468, Test: 0.5546, Best time: 18.2948
Epoch: 086, Runtime 0.042453, Loss 0.159002, Train: 1.0000, Val: 0.5441, Test: 0.5485, Best time: 18.2948
Epoch: 087, Runtime 0.048990, Loss 0.161919, Train: 1.0000, Val: 0.5436, Test: 0.5526, Best time: 18.2948
Epoch: 088, Runtime 0.043760, Loss 0.111672, Train: 1.0000, Val: 0.5479, Test: 0.5567, Best time: 18.2948
Epoch: 089, Runtime 0.042300, Loss 0.133407, Train: 1.0000, Val: 0.5529, Test: 0.5546, Best time: 18.2948
Epoch: 090, Runtime 0.041584, Loss 0.143920, Train: 1.0000, Val: 0.5578, Test: 0.5608, Best time: 18.2948
Epoch: 091, Runtime 0.041579, Loss 0.155039, Train: 1.0000, Val: 0.5677, Test: 0.5608, Best time: 18.2948
Epoch: 092, Runtime 0.041639, Loss 0.144255, Train: 1.0000, Val: 0.5638, Test: 0.5567, Best time: 18.2948
Epoch: 093, Runtime 0.042490, Loss 0.158294, Train: 1.0000, Val: 0.5704, Test: 0.5753, Best time: 18.2948
Epoch: 094, Runtime 0.043225, Loss 0.136318, Train: 1.0000, Val: 0.5721, Test: 0.5773, Best time: 18.2948
Epoch: 095, Runtime 0.043462, Loss 0.152198, Train: 1.0000, Val: 0.5770, Test: 0.5814, Best time: 18.2948
Epoch: 096, Runtime 0.041993, Loss 0.151325, Train: 1.0000, Val: 0.5786, Test: 0.5876, Best time: 18.2948
Epoch: 097, Runtime 0.042422, Loss 0.140995, Train: 1.0000, Val: 0.5792, Test: 0.5814, Best time: 18.2948
Epoch: 098, Runtime 0.051193, Loss 0.139697, Train: 1.0000, Val: 0.5792, Test: 0.5753, Best time: 18.2948
Epoch: 099, Runtime 0.041637, Loss 0.157273, Train: 1.0000, Val: 0.5666, Test: 0.5629, Best time: 18.2948
Epoch: 100, Runtime 0.132303, Loss 0.163621, Train: 1.0000, Val: 0.5660, Test: 0.5505, Best time: 18.2948
best val accuracy 0.566027 with test accuracy 0.550515 at epoch 12 and best time 18.294754