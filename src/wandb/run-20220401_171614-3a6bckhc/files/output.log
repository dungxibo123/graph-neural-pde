GrandExtendDiscritizedNet
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
mol_list.0.alpha_train
torch.Size([])
mol_list.0.beta_train
torch.Size([])
mol_list.0.alpha_sc
torch.Size([1])
mol_list.0.beta_sc
torch.Size([1])
mol_list.0.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.0.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.V.bias
torch.Size([128])
mol_list.0.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.K.bias
torch.Size([128])
mol_list.0.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.0.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.1.alpha_train
torch.Size([])
mol_list.1.beta_train
torch.Size([])
mol_list.1.alpha_sc
torch.Size([1])
mol_list.1.beta_sc
torch.Size([1])
mol_list.1.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.1.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.V.bias
torch.Size([128])
mol_list.1.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.K.bias
torch.Size([128])
mol_list.1.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.1.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.2.alpha_train
torch.Size([])
mol_list.2.beta_train
torch.Size([])
mol_list.2.alpha_sc
torch.Size([1])
mol_list.2.beta_sc
torch.Size([1])
mol_list.2.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.2.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.V.bias
torch.Size([128])
mol_list.2.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.K.bias
torch.Size([128])
mol_list.2.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.2.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.3.alpha_train
torch.Size([])
mol_list.3.beta_train
torch.Size([])
mol_list.3.alpha_sc
torch.Size([1])
mol_list.3.beta_sc
torch.Size([1])
mol_list.3.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.3.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.V.bias
torch.Size([128])
mol_list.3.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.K.bias
torch.Size([128])
mol_list.3.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.3.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.4.alpha_train
torch.Size([])
mol_list.4.beta_train
torch.Size([])
mol_list.4.alpha_sc
torch.Size([1])
mol_list.4.beta_sc
torch.Size([1])
mol_list.4.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.4.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.V.bias
torch.Size([128])
mol_list.4.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.K.bias
torch.Size([128])
mol_list.4.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.4.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.5.alpha_train
torch.Size([])
mol_list.5.beta_train
torch.Size([])
mol_list.5.alpha_sc
torch.Size([1])
mol_list.5.beta_sc
torch.Size([1])
mol_list.5.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.5.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.5.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.5.multihead_att_layer.V.bias
torch.Size([128])
mol_list.5.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.5.multihead_att_layer.K.bias
torch.Size([128])
mol_list.5.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.5.multihead_att_layer.Wout.bias
torch.Size([80])

 28%|████████                     | 28/100 [00:02<00:04, 17.49it/s]
Epoch: 001, Runtime 1.573778, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 002, Runtime 0.049422, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 003, Runtime 0.043793, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 004, Runtime 0.044912, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 005, Runtime 0.042538, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 006, Runtime 0.045295, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 007, Runtime 0.043130, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 008, Runtime 0.048166, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 009, Runtime 0.053301, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 010, Runtime 0.055096, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 011, Runtime 0.050776, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 012, Runtime 0.043846, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 013, Runtime 0.042530, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 014, Runtime 0.043020, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 015, Runtime 0.042354, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 016, Runtime 0.049926, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 017, Runtime 0.044231, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 018, Runtime 0.049524, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 019, Runtime 0.054022, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 020, Runtime 0.047590, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 021, Runtime 0.052469, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 022, Runtime 0.056472, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 023, Runtime 0.064873, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 024, Runtime 0.050249, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 025, Runtime 0.048462, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 026, Runtime 0.064300, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 027, Runtime 0.048141, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948

 65%|██████████████████▊          | 65/100 [00:04<00:01, 20.15it/s]
Epoch: 029, Runtime 0.061858, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 030, Runtime 0.051654, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 031, Runtime 0.050774, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 032, Runtime 0.046788, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 033, Runtime 0.047143, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 034, Runtime 0.046376, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 035, Runtime 0.046669, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 036, Runtime 0.055701, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 037, Runtime 0.044765, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 038, Runtime 0.051693, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 039, Runtime 0.066357, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 040, Runtime 0.049121, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 041, Runtime 0.058931, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 042, Runtime 0.048161, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 043, Runtime 0.066409, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 044, Runtime 0.063252, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 045, Runtime 0.045760, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 046, Runtime 0.044907, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 047, Runtime 0.050548, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 048, Runtime 0.053339, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 049, Runtime 0.051502, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 050, Runtime 0.050508, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 051, Runtime 0.047570, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 052, Runtime 0.047553, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 053, Runtime 0.052425, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 054, Runtime 0.047971, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 055, Runtime 0.057501, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 056, Runtime 0.050818, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 057, Runtime 0.058980, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 058, Runtime 0.044375, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 059, Runtime 0.046499, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 060, Runtime 0.055310, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 061, Runtime 0.045152, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 062, Runtime 0.056050, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 063, Runtime 0.046374, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 064, Runtime 0.047443, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 065, Runtime 0.040478, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948

100%|████████████████████████████| 100/100 [00:06<00:00, 15.02it/s]
Epoch: 067, Runtime 0.058947, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 068, Runtime 0.053686, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 069, Runtime 0.054003, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 070, Runtime 0.049987, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 071, Runtime 0.045090, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 072, Runtime 0.042807, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 073, Runtime 0.057363, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 074, Runtime 0.048396, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 075, Runtime 0.047967, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 076, Runtime 0.052539, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 077, Runtime 0.070733, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 078, Runtime 0.048724, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 079, Runtime 0.060586, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 080, Runtime 0.060157, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 081, Runtime 0.042603, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 082, Runtime 0.046045, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 083, Runtime 0.040966, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 084, Runtime 0.039068, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 085, Runtime 0.040059, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 086, Runtime 0.040313, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 087, Runtime 0.050697, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 088, Runtime 0.160491, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 089, Runtime 0.040433, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 090, Runtime 0.044041, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 091, Runtime 0.040238, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 092, Runtime 0.044281, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 093, Runtime 0.041660, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 094, Runtime 0.041001, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 095, Runtime 0.040436, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 096, Runtime 0.047103, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 097, Runtime 0.042235, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 098, Runtime 0.038064, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 099, Runtime 0.039552, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 100, Runtime 0.040319, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
best val accuracy 0.140822 with test accuracy 0.127835 at epoch 1 and best time 18.294754