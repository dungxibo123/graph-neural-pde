GrandExtendDiscritizedNet
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
mol_list.0.alpha_train
torch.Size([])
mol_list.0.beta_train
torch.Size([])
mol_list.0.alpha_sc
torch.Size([1])
mol_list.0.beta_sc
torch.Size([1])
mol_list.0.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.0.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.V.bias
torch.Size([128])
mol_list.0.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.K.bias
torch.Size([128])
mol_list.0.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.0.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.1.alpha_train
torch.Size([])
mol_list.1.beta_train
torch.Size([])
mol_list.1.alpha_sc
torch.Size([1])
mol_list.1.beta_sc
torch.Size([1])
mol_list.1.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.1.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.V.bias
torch.Size([128])
mol_list.1.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.K.bias
torch.Size([128])
mol_list.1.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.1.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.2.alpha_train
torch.Size([])
mol_list.2.beta_train
torch.Size([])
mol_list.2.alpha_sc
torch.Size([1])
mol_list.2.beta_sc
torch.Size([1])
mol_list.2.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.2.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.V.bias
torch.Size([128])
mol_list.2.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.K.bias
torch.Size([128])
mol_list.2.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.2.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.3.alpha_train
torch.Size([])
mol_list.3.beta_train
torch.Size([])
mol_list.3.alpha_sc
torch.Size([1])
mol_list.3.beta_sc
torch.Size([1])
mol_list.3.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.3.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.V.bias
torch.Size([128])
mol_list.3.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.K.bias
torch.Size([128])
mol_list.3.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.3.multihead_att_layer.Wout.bias
torch.Size([80])

 35%|██████████▏                  | 35/100 [00:03<00:03, 19.17it/s]
Epoch: 001, Runtime 2.090250, Loss 433617795937927692288.000000, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 002, Runtime 0.052149, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 003, Runtime 0.042988, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 004, Runtime 0.065343, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 005, Runtime 0.053568, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 006, Runtime 0.049957, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 007, Runtime 0.050560, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 008, Runtime 0.051020, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 009, Runtime 0.052813, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 010, Runtime 0.050983, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 011, Runtime 0.051417, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 012, Runtime 0.052499, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 013, Runtime 0.051794, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 014, Runtime 0.055706, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 015, Runtime 0.052912, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 016, Runtime 0.054084, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 017, Runtime 0.053116, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 018, Runtime 0.069321, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 019, Runtime 0.052838, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 020, Runtime 0.071406, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 021, Runtime 0.065400, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 022, Runtime 0.053750, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 023, Runtime 0.054650, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 024, Runtime 0.054457, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 025, Runtime 0.052537, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948

 64%|██████████████████▌          | 64/100 [00:05<00:01, 20.53it/s]
Epoch: 027, Runtime 0.050437, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 028, Runtime 0.051101, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 029, Runtime 0.052333, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 030, Runtime 0.051616, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 031, Runtime 0.051780, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 032, Runtime 0.043376, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 033, Runtime 0.041118, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 034, Runtime 0.049773, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 035, Runtime 0.051408, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 036, Runtime 0.089664, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 037, Runtime 0.051215, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 038, Runtime 0.050642, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 039, Runtime 0.050486, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 040, Runtime 0.049021, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 041, Runtime 0.050635, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 042, Runtime 0.050102, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 043, Runtime 0.050355, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 044, Runtime 0.051561, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 045, Runtime 0.051492, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 046, Runtime 0.051610, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 047, Runtime 0.052541, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 048, Runtime 0.051513, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 049, Runtime 0.044959, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 050, Runtime 0.050263, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 051, Runtime 0.052315, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 052, Runtime 0.053760, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 053, Runtime 0.051590, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 054, Runtime 0.051954, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 055, Runtime 0.051204, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 056, Runtime 0.054591, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 057, Runtime 0.049265, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 058, Runtime 0.051400, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 059, Runtime 0.044559, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 060, Runtime 0.043727, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 061, Runtime 0.044013, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 062, Runtime 0.046352, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 063, Runtime 0.047571, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 064, Runtime 0.045399, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948

100%|████████████████████████████| 100/100 [00:07<00:00, 13.97it/s]
Epoch: 066, Runtime 0.043874, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 067, Runtime 0.044177, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 068, Runtime 0.045063, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 069, Runtime 0.044814, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 070, Runtime 0.045431, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 071, Runtime 0.043884, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 072, Runtime 0.044468, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 073, Runtime 0.050796, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 074, Runtime 0.043885, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 075, Runtime 0.044115, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 076, Runtime 0.038764, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 077, Runtime 0.050477, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 078, Runtime 0.058626, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 079, Runtime 0.045913, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 080, Runtime 0.045286, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 081, Runtime 0.051145, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 082, Runtime 0.040844, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 083, Runtime 0.031855, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 084, Runtime 0.044292, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 085, Runtime 0.046884, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 086, Runtime 0.046471, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 087, Runtime 0.046098, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 088, Runtime 0.046811, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 089, Runtime 0.043976, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 090, Runtime 0.043920, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 091, Runtime 0.055203, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 092, Runtime 0.061645, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 093, Runtime 0.048718, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 094, Runtime 0.045866, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 095, Runtime 0.048832, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 096, Runtime 0.050343, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 097, Runtime 0.046272, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 098, Runtime 0.044983, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 099, Runtime 0.045940, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 100, Runtime 0.044544, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
best val accuracy 0.135342 with test accuracy 0.148454 at epoch 1 and best time 18.294754