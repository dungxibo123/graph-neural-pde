GrandExtendDiscritizedNet
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
mol_list.0.alpha_train
torch.Size([])
mol_list.0.beta_train
torch.Size([])
mol_list.0.alpha_sc
torch.Size([1])
mol_list.0.beta_sc
torch.Size([1])
mol_list.0.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.0.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.V.bias
torch.Size([128])
mol_list.0.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.K.bias
torch.Size([128])
mol_list.0.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.0.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.1.alpha_train
torch.Size([])
mol_list.1.beta_train
torch.Size([])
mol_list.1.alpha_sc
torch.Size([1])
mol_list.1.beta_sc
torch.Size([1])
mol_list.1.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.1.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.V.bias
torch.Size([128])
mol_list.1.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.K.bias
torch.Size([128])
mol_list.1.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.1.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.2.alpha_train
torch.Size([])
mol_list.2.beta_train
torch.Size([])
mol_list.2.alpha_sc
torch.Size([1])
mol_list.2.beta_sc
torch.Size([1])
mol_list.2.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.2.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.V.bias
torch.Size([128])
mol_list.2.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.K.bias
torch.Size([128])
mol_list.2.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.2.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.3.alpha_train
torch.Size([])
mol_list.3.beta_train
torch.Size([])
mol_list.3.alpha_sc
torch.Size([1])
mol_list.3.beta_sc
torch.Size([1])
mol_list.3.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.3.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.V.bias
torch.Size([128])
mol_list.3.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.K.bias
torch.Size([128])
mol_list.3.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.3.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.4.alpha_train
torch.Size([])
mol_list.4.beta_train
torch.Size([])
mol_list.4.alpha_sc
torch.Size([1])
mol_list.4.beta_sc
torch.Size([1])
mol_list.4.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.4.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.V.bias
torch.Size([128])
mol_list.4.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.K.bias
torch.Size([128])
mol_list.4.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.4.multihead_att_layer.Wout.bias
torch.Size([80])
  0%|                                      | 0/100 [00:00<?, ?it/s]
Epoch: 001, Runtime 1.900776, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 002, Runtime 0.058468, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 003, Runtime 0.064634, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 004, Runtime 0.053367, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 005, Runtime 0.047279, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 006, Runtime 0.046643, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 007, Runtime 0.055435, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948


 45%|█████████████                | 45/100 [00:04<00:02, 19.76it/s]
Epoch: 009, Runtime 0.055727, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 010, Runtime 0.045101, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 011, Runtime 0.047132, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 012, Runtime 0.046683, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 013, Runtime 0.055577, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 014, Runtime 0.064295, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 015, Runtime 0.055938, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 016, Runtime 0.048834, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 017, Runtime 0.047618, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 018, Runtime 0.057531, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 019, Runtime 0.071974, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 020, Runtime 0.047811, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 021, Runtime 0.050750, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 022, Runtime 0.047513, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 023, Runtime 0.046971, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 024, Runtime 0.047102, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 025, Runtime 0.050151, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 026, Runtime 0.048911, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 027, Runtime 0.047993, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 028, Runtime 0.056201, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 029, Runtime 0.064887, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 030, Runtime 0.050911, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 031, Runtime 0.052720, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 032, Runtime 0.045491, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 033, Runtime 0.056046, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 034, Runtime 0.050972, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 035, Runtime 0.049402, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 036, Runtime 0.049554, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 037, Runtime 0.056312, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 038, Runtime 0.070892, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 039, Runtime 0.048111, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 040, Runtime 0.046732, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 041, Runtime 0.046050, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 042, Runtime 0.046024, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 043, Runtime 0.046361, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 044, Runtime 0.046433, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 045, Runtime 0.047877, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948

 84%|████████████████████████▎    | 84/100 [00:06<00:00, 19.40it/s]
Epoch: 047, Runtime 0.056399, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 048, Runtime 0.039206, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 049, Runtime 0.046433, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 050, Runtime 0.045630, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 051, Runtime 0.045646, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 052, Runtime 0.049299, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 053, Runtime 0.047924, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 054, Runtime 0.057398, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 055, Runtime 0.047025, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 056, Runtime 0.052452, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 057, Runtime 0.078998, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 058, Runtime 0.048733, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 059, Runtime 0.047216, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 060, Runtime 0.050698, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 061, Runtime 0.049165, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 062, Runtime 0.072389, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 063, Runtime 0.049441, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 064, Runtime 0.058848, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 065, Runtime 0.045815, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 066, Runtime 0.058788, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 067, Runtime 0.070650, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 068, Runtime 0.056434, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 069, Runtime 0.051563, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 070, Runtime 0.045524, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 071, Runtime 0.046102, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 072, Runtime 0.054203, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 073, Runtime 0.055469, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 074, Runtime 0.048183, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 075, Runtime 0.048138, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 076, Runtime 0.056394, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 077, Runtime 0.063274, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 078, Runtime 0.055070, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 079, Runtime 0.048163, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 080, Runtime 0.047878, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 081, Runtime 0.048136, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 082, Runtime 0.047587, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 083, Runtime 0.048114, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 084, Runtime 0.047552, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 085, Runtime 0.049589, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 086, Runtime 0.050990, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 087, Runtime 0.048690, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 088, Runtime 0.049323, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 089, Runtime 0.047272, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 090, Runtime 0.048159, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 091, Runtime 0.049078, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 092, Runtime 0.048007, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 093, Runtime 0.046742, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 094, Runtime 0.050983, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 095, Runtime 0.219151, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 096, Runtime 0.064355, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 097, Runtime 0.065723, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 098, Runtime 0.064225, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 099, Runtime 0.064240, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948
Epoch: 100, Runtime 0.064874, Loss nan, Train: 0.1429, Val: 0.1408, Test: 0.1278, Best time: 18.2948

100%|████████████████████████████| 100/100 [00:07<00:00, 13.59it/s]