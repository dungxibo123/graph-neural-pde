
  0%|                                                                            | 0/100 [00:00<?, ?it/s]
GrandExtendDiscritizedNet
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
mol_list.0.alpha_train
torch.Size([])
mol_list.0.beta_train
torch.Size([])
mol_list.0.alpha_sc
torch.Size([1])
mol_list.0.beta_sc
torch.Size([1])
mol_list.0.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.0.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.V.bias
torch.Size([128])
mol_list.0.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.K.bias
torch.Size([128])
mol_list.0.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.0.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.1.alpha_train
torch.Size([])
mol_list.1.beta_train
torch.Size([])
mol_list.1.alpha_sc
torch.Size([1])
mol_list.1.beta_sc
torch.Size([1])
mol_list.1.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.1.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.V.bias
torch.Size([128])
mol_list.1.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.K.bias
torch.Size([128])
mol_list.1.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.1.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.2.alpha_train
torch.Size([])
mol_list.2.beta_train
torch.Size([])
mol_list.2.alpha_sc
torch.Size([1])
mol_list.2.beta_sc
torch.Size([1])
mol_list.2.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.2.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.V.bias
torch.Size([128])
mol_list.2.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.K.bias
torch.Size([128])
mol_list.2.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.2.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.3.alpha_train
torch.Size([])
mol_list.3.beta_train
torch.Size([])
mol_list.3.alpha_sc
torch.Size([1])
mol_list.3.beta_sc
torch.Size([1])
mol_list.3.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.3.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.V.bias
torch.Size([128])
mol_list.3.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.K.bias
torch.Size([128])
mol_list.3.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.3.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.4.alpha_train
torch.Size([])
mol_list.4.beta_train
torch.Size([])
mol_list.4.alpha_sc
torch.Size([1])
mol_list.4.beta_sc
torch.Size([1])
mol_list.4.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.4.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.V.bias
torch.Size([128])
mol_list.4.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.K.bias
torch.Size([128])
mol_list.4.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.4.multihead_att_layer.Wout.bias
torch.Size([80])
Epoch: 001, Runtime 1.034039, Loss 1.949337, Train: 0.8686, Val: 0.4488, Test: 0.4309, Best time: 18.2948
Epoch: 002, Runtime 0.030621, Loss 1.721755, Train: 0.9371, Val: 0.5616, Test: 0.5464, Best time: 18.2948
Epoch: 003, Runtime 0.026841, Loss 1.414377, Train: 0.9600, Val: 0.5803, Test: 0.5711, Best time: 18.2948
Epoch: 004, Runtime 0.034248, Loss 1.059839, Train: 0.9714, Val: 0.5940, Test: 0.5918, Best time: 18.2948
Epoch: 005, Runtime 0.027842, Loss 0.767686, Train: 0.9943, Val: 0.6175, Test: 0.6124, Best time: 18.2948
Epoch: 006, Runtime 0.030769, Loss 0.546830, Train: 0.9943, Val: 0.6318, Test: 0.6289, Best time: 18.2948
Epoch: 007, Runtime 0.046890, Loss 0.427253, Train: 0.9943, Val: 0.6373, Test: 0.6351, Best time: 18.2948
Epoch: 008, Runtime 0.030292, Loss 0.295481, Train: 1.0000, Val: 0.6373, Test: 0.6371, Best time: 18.2948
Epoch: 009, Runtime 0.040061, Loss 0.184548, Train: 1.0000, Val: 0.6362, Test: 0.6454, Best time: 18.2948
Epoch: 010, Runtime 0.038092, Loss 0.221093, Train: 1.0000, Val: 0.6411, Test: 0.6392, Best time: 18.2948
Epoch: 011, Runtime 0.031564, Loss 0.195725, Train: 1.0000, Val: 0.6384, Test: 0.6330, Best time: 18.2948
Epoch: 012, Runtime 0.034178, Loss 0.162853, Train: 1.0000, Val: 0.6345, Test: 0.6206, Best time: 18.2948
Epoch: 013, Runtime 0.033863, Loss 0.111789, Train: 1.0000, Val: 0.6236, Test: 0.6227, Best time: 18.2948
Epoch: 014, Runtime 0.032892, Loss 0.100569, Train: 1.0000, Val: 0.6175, Test: 0.6144, Best time: 18.2948
Epoch: 015, Runtime 0.040769, Loss 0.119588, Train: 1.0000, Val: 0.6159, Test: 0.6062, Best time: 18.2948
Epoch: 016, Runtime 0.043991, Loss 0.136019, Train: 1.0000, Val: 0.6110, Test: 0.5979, Best time: 18.2948
Epoch: 017, Runtime 0.041666, Loss 0.086924, Train: 1.0000, Val: 0.6055, Test: 0.5897, Best time: 18.2948
Epoch: 018, Runtime 0.049375, Loss 0.133950, Train: 1.0000, Val: 0.6077, Test: 0.5979, Best time: 18.2948
Epoch: 019, Runtime 0.045183, Loss 0.151188, Train: 1.0000, Val: 0.6055, Test: 0.6041, Best time: 18.2948
Epoch: 020, Runtime 0.048356, Loss 0.098574, Train: 1.0000, Val: 0.6049, Test: 0.6041, Best time: 18.2948
Epoch: 021, Runtime 0.031080, Loss 0.138886, Train: 1.0000, Val: 0.6011, Test: 0.5897, Best time: 18.2948
Epoch: 022, Runtime 0.033631, Loss 0.113451, Train: 1.0000, Val: 0.5995, Test: 0.6041, Best time: 18.2948
Epoch: 023, Runtime 0.031628, Loss 0.151914, Train: 1.0000, Val: 0.5967, Test: 0.5835, Best time: 18.2948
Epoch: 024, Runtime 0.032848, Loss 0.101325, Train: 1.0000, Val: 0.6022, Test: 0.5959, Best time: 18.2948
Epoch: 025, Runtime 0.033134, Loss 0.142838, Train: 1.0000, Val: 0.6038, Test: 0.5876, Best time: 18.2948
Epoch: 026, Runtime 0.038151, Loss 0.166398, Train: 1.0000, Val: 0.6104, Test: 0.5918, Best time: 18.2948
Epoch: 027, Runtime 0.035829, Loss 0.176215, Train: 1.0000, Val: 0.6099, Test: 0.5856, Best time: 18.2948
Epoch: 028, Runtime 0.039131, Loss 0.136591, Train: 1.0000, Val: 0.6088, Test: 0.5814, Best time: 18.2948
Epoch: 029, Runtime 0.045418, Loss 0.176191, Train: 1.0000, Val: 0.6082, Test: 0.5732, Best time: 18.2948
Epoch: 030, Runtime 0.036956, Loss 0.137379, Train: 1.0000, Val: 0.6137, Test: 0.5794, Best time: 18.2948
Epoch: 031, Runtime 0.035367, Loss 0.170682, Train: 1.0000, Val: 0.6088, Test: 0.5897, Best time: 18.2948
Epoch: 032, Runtime 0.030805, Loss 0.191519, Train: 1.0000, Val: 0.5912, Test: 0.5897, Best time: 18.2948
Epoch: 033, Runtime 0.052562, Loss 0.167413, Train: 1.0000, Val: 0.5868, Test: 0.5794, Best time: 18.2948
Epoch: 034, Runtime 0.034660, Loss 0.187944, Train: 1.0000, Val: 0.5841, Test: 0.5753, Best time: 18.2948
Epoch: 035, Runtime 0.036254, Loss 0.253218, Train: 1.0000, Val: 0.5825, Test: 0.5814, Best time: 18.2948
Epoch: 036, Runtime 0.037722, Loss 0.154670, Train: 1.0000, Val: 0.5753, Test: 0.5691, Best time: 18.2948
Epoch: 037, Runtime 0.036522, Loss 0.158604, Train: 1.0000, Val: 0.5737, Test: 0.5670, Best time: 18.2948
Epoch: 038, Runtime 0.036702, Loss 0.126914, Train: 1.0000, Val: 0.5775, Test: 0.5670, Best time: 18.2948
Epoch: 039, Runtime 0.033917, Loss 0.170537, Train: 1.0000, Val: 0.5808, Test: 0.5691, Best time: 18.2948
Epoch: 040, Runtime 0.035633, Loss 0.123153, Train: 1.0000, Val: 0.5879, Test: 0.5835, Best time: 18.2948
Epoch: 041, Runtime 0.033619, Loss 0.139426, Train: 1.0000, Val: 0.5863, Test: 0.5794, Best time: 18.2948
Epoch: 042, Runtime 0.044604, Loss 0.180972, Train: 1.0000, Val: 0.5918, Test: 0.5753, Best time: 18.2948
Epoch: 043, Runtime 0.031532, Loss 0.157482, Train: 1.0000, Val: 0.5912, Test: 0.5649, Best time: 18.2948
Epoch: 044, Runtime 0.031112, Loss 0.141467, Train: 1.0000, Val: 0.5775, Test: 0.5691, Best time: 18.2948
Epoch: 045, Runtime 0.030308, Loss 0.123717, Train: 1.0000, Val: 0.5770, Test: 0.5670, Best time: 18.2948

 44%|█████████████████████████████▍                                     | 44/100 [00:02<00:02, 26.37it/s]
Epoch: 047, Runtime 0.040623, Loss 0.116612, Train: 1.0000, Val: 0.5742, Test: 0.5670, Best time: 18.2948
Epoch: 048, Runtime 0.042545, Loss 0.118761, Train: 1.0000, Val: 0.5622, Test: 0.5608, Best time: 18.2948
Epoch: 049, Runtime 0.037396, Loss 0.112057, Train: 1.0000, Val: 0.5573, Test: 0.5608, Best time: 18.2948
Epoch: 050, Runtime 0.030478, Loss 0.110097, Train: 1.0000, Val: 0.5496, Test: 0.5567, Best time: 18.2948
Epoch: 051, Runtime 0.037431, Loss 0.115018, Train: 1.0000, Val: 0.5567, Test: 0.5670, Best time: 18.2948
Epoch: 052, Runtime 0.032998, Loss 0.140296, Train: 1.0000, Val: 0.5627, Test: 0.5794, Best time: 18.2948
Epoch: 053, Runtime 0.038136, Loss 0.145419, Train: 1.0000, Val: 0.5732, Test: 0.5876, Best time: 18.2948
Epoch: 054, Runtime 0.033823, Loss 0.132040, Train: 1.0000, Val: 0.5863, Test: 0.5835, Best time: 18.2948
Epoch: 055, Runtime 0.038763, Loss 0.130792, Train: 1.0000, Val: 0.5934, Test: 0.5856, Best time: 18.2948
Epoch: 056, Runtime 0.044893, Loss 0.134572, Train: 1.0000, Val: 0.6033, Test: 0.5856, Best time: 18.2948
Epoch: 057, Runtime 0.034731, Loss 0.147247, Train: 1.0000, Val: 0.6005, Test: 0.5856, Best time: 18.2948
Epoch: 058, Runtime 0.032896, Loss 0.122683, Train: 1.0000, Val: 0.5967, Test: 0.5794, Best time: 18.2948
Epoch: 059, Runtime 0.060696, Loss 0.122369, Train: 1.0000, Val: 0.5929, Test: 0.5856, Best time: 18.2948
Epoch: 060, Runtime 0.029775, Loss 0.119856, Train: 1.0000, Val: 0.5847, Test: 0.5794, Best time: 18.2948
Epoch: 061, Runtime 0.026629, Loss 0.113351, Train: 1.0000, Val: 0.5841, Test: 0.5732, Best time: 18.2948
Epoch: 062, Runtime 0.029112, Loss 0.135775, Train: 1.0000, Val: 0.5759, Test: 0.5711, Best time: 18.2948
Epoch: 063, Runtime 0.027170, Loss 0.117577, Train: 1.0000, Val: 0.5671, Test: 0.5526, Best time: 18.2948
Epoch: 064, Runtime 0.032621, Loss 0.122194, Train: 1.0000, Val: 0.5644, Test: 0.5546, Best time: 18.2948
Epoch: 065, Runtime 0.034225, Loss 0.135319, Train: 1.0000, Val: 0.5589, Test: 0.5485, Best time: 18.2948
Epoch: 066, Runtime 0.033838, Loss 0.141284, Train: 1.0000, Val: 0.5605, Test: 0.5464, Best time: 18.2948
Epoch: 067, Runtime 0.034099, Loss 0.157959, Train: 1.0000, Val: 0.5622, Test: 0.5567, Best time: 18.2948
Epoch: 068, Runtime 0.030587, Loss 0.152627, Train: 1.0000, Val: 0.5759, Test: 0.5567, Best time: 18.2948
Epoch: 069, Runtime 0.035064, Loss 0.148914, Train: 1.0000, Val: 0.5759, Test: 0.5732, Best time: 18.2948
Epoch: 070, Runtime 0.033911, Loss 0.162630, Train: 1.0000, Val: 0.5830, Test: 0.5856, Best time: 18.2948
Epoch: 071, Runtime 0.034539, Loss 0.102573, Train: 1.0000, Val: 0.5885, Test: 0.5856, Best time: 18.2948
Epoch: 072, Runtime 0.040726, Loss 0.136521, Train: 1.0000, Val: 0.5962, Test: 0.5897, Best time: 18.2948
Epoch: 073, Runtime 0.041376, Loss 0.126923, Train: 1.0000, Val: 0.5951, Test: 0.5814, Best time: 18.2948
Epoch: 074, Runtime 0.052457, Loss 0.144349, Train: 1.0000, Val: 0.5973, Test: 0.5876, Best time: 18.2948
Epoch: 075, Runtime 0.038199, Loss 0.134170, Train: 1.0000, Val: 0.6033, Test: 0.5897, Best time: 18.2948
Epoch: 076, Runtime 0.037897, Loss 0.096143, Train: 1.0000, Val: 0.5945, Test: 0.5897, Best time: 18.2948
Epoch: 077, Runtime 0.058512, Loss 0.137469, Train: 1.0000, Val: 0.5885, Test: 0.5979, Best time: 18.2948
Epoch: 078, Runtime 0.064399, Loss 0.124396, Train: 1.0000, Val: 0.5879, Test: 0.5856, Best time: 18.2948
Epoch: 079, Runtime 0.037643, Loss 0.133517, Train: 1.0000, Val: 0.5841, Test: 0.5753, Best time: 18.2948
Epoch: 080, Runtime 0.053020, Loss 0.129409, Train: 1.0000, Val: 0.5836, Test: 0.5753, Best time: 18.2948
Epoch: 081, Runtime 0.028111, Loss 0.163096, Train: 1.0000, Val: 0.5808, Test: 0.5732, Best time: 18.2948
Epoch: 082, Runtime 0.052366, Loss 0.117374, Train: 1.0000, Val: 0.5764, Test: 0.5608, Best time: 18.2948
Epoch: 083, Runtime 0.028305, Loss 0.119865, Train: 1.0000, Val: 0.5748, Test: 0.5546, Best time: 18.2948
Epoch: 084, Runtime 0.034481, Loss 0.074854, Train: 1.0000, Val: 0.5742, Test: 0.5649, Best time: 18.2948
Epoch: 085, Runtime 0.031554, Loss 0.137736, Train: 1.0000, Val: 0.5688, Test: 0.5629, Best time: 18.2948
Epoch: 086, Runtime 0.031687, Loss 0.127343, Train: 1.0000, Val: 0.5704, Test: 0.5526, Best time: 18.2948
Epoch: 087, Runtime 0.033827, Loss 0.135213, Train: 1.0000, Val: 0.5781, Test: 0.5588, Best time: 18.2948
Epoch: 088, Runtime 0.032480, Loss 0.119893, Train: 1.0000, Val: 0.5890, Test: 0.5814, Best time: 18.2948
Epoch: 089, Runtime 0.040155, Loss 0.103761, Train: 1.0000, Val: 0.5951, Test: 0.5773, Best time: 18.2948
Epoch: 090, Runtime 0.025826, Loss 0.118011, Train: 1.0000, Val: 0.5978, Test: 0.5856, Best time: 18.2948
Epoch: 091, Runtime 0.030068, Loss 0.120760, Train: 1.0000, Val: 0.5962, Test: 0.5897, Best time: 18.2948
Epoch: 092, Runtime 0.037345, Loss 0.146800, Train: 1.0000, Val: 0.5984, Test: 0.5856, Best time: 18.2948
Epoch: 093, Runtime 0.034804, Loss 0.119317, Train: 1.0000, Val: 0.5995, Test: 0.5856, Best time: 18.2948
Epoch: 094, Runtime 0.033220, Loss 0.161275, Train: 1.0000, Val: 0.5967, Test: 0.5959, Best time: 18.2948
Epoch: 095, Runtime 0.034300, Loss 0.139343, Train: 1.0000, Val: 0.5984, Test: 0.5835, Best time: 18.2948
Epoch: 096, Runtime 0.030502, Loss 0.150456, Train: 1.0000, Val: 0.5918, Test: 0.5711, Best time: 18.2948

100%|██████████████████████████████████████████████████████████████████| 100/100 [00:04<00:00, 20.14it/s]
Epoch: 098, Runtime 0.160548, Loss 0.105139, Train: 1.0000, Val: 0.5852, Test: 0.5649, Best time: 18.2948
Epoch: 099, Runtime 0.038204, Loss 0.110609, Train: 1.0000, Val: 0.5841, Test: 0.5711, Best time: 18.2948
Epoch: 100, Runtime 0.033879, Loss 0.090956, Train: 1.0000, Val: 0.5885, Test: 0.5670, Best time: 18.2948
best val accuracy 0.588493 with test accuracy 0.567010 at epoch 10 and best time 18.294754