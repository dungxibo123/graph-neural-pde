GrandExtendDiscritizedNet
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
mol_list.0.alpha_train
torch.Size([])
mol_list.0.beta_train
torch.Size([])
mol_list.0.alpha_sc
torch.Size([1])
mol_list.0.beta_sc
torch.Size([1])
mol_list.0.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.0.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.V.bias
torch.Size([128])
mol_list.0.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.K.bias
torch.Size([128])
mol_list.0.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.0.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.1.alpha_train
torch.Size([])
mol_list.1.beta_train
torch.Size([])
mol_list.1.alpha_sc
torch.Size([1])
mol_list.1.beta_sc
torch.Size([1])
mol_list.1.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.1.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.V.bias
torch.Size([128])
mol_list.1.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.K.bias
torch.Size([128])
mol_list.1.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.1.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.2.alpha_train
torch.Size([])
mol_list.2.beta_train
torch.Size([])
mol_list.2.alpha_sc
torch.Size([1])
mol_list.2.beta_sc
torch.Size([1])
mol_list.2.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.2.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.V.bias
torch.Size([128])
mol_list.2.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.K.bias
torch.Size([128])
mol_list.2.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.2.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.3.alpha_train
torch.Size([])
mol_list.3.beta_train
torch.Size([])
mol_list.3.alpha_sc
torch.Size([1])
mol_list.3.beta_sc
torch.Size([1])
mol_list.3.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.3.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.V.bias
torch.Size([128])
mol_list.3.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.K.bias
torch.Size([128])
mol_list.3.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.3.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.4.alpha_train
torch.Size([])
mol_list.4.beta_train
torch.Size([])
mol_list.4.alpha_sc
torch.Size([1])
mol_list.4.beta_sc
torch.Size([1])
mol_list.4.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.4.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.V.bias
torch.Size([128])
mol_list.4.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.K.bias
torch.Size([128])
mol_list.4.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.4.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.5.alpha_train
torch.Size([])
mol_list.5.beta_train
torch.Size([])
mol_list.5.alpha_sc
torch.Size([1])
mol_list.5.beta_sc
torch.Size([1])
mol_list.5.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.5.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.5.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.5.multihead_att_layer.V.bias
torch.Size([128])
mol_list.5.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.5.multihead_att_layer.K.bias
torch.Size([128])
mol_list.5.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.5.multihead_att_layer.Wout.bias
torch.Size([80])
  0%|                                                                            | 0/100 [00:00<?, ?it/s]
Epoch: 001, Runtime 1.916289, Loss 1.947919, Train: 0.9029, Val: 0.4553, Test: 0.4495, Best time: 18.2948
Epoch: 002, Runtime 0.062982, Loss 1.760517, Train: 0.9314, Val: 0.5353, Test: 0.5175, Best time: 18.2948
Epoch: 003, Runtime 0.055263, Loss 1.514539, Train: 0.9486, Val: 0.5781, Test: 0.5567, Best time: 18.2948
Epoch: 004, Runtime 0.061829, Loss 1.266727, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 005, Runtime 0.058387, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 006, Runtime 0.061156, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 007, Runtime 0.057839, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 008, Runtime 0.057219, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948


 41%|███████████████████████████▍                                       | 41/100 [00:04<00:03, 16.86it/s]
Epoch: 010, Runtime 0.058597, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 011, Runtime 0.056978, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 012, Runtime 0.054847, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 013, Runtime 0.046150, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 014, Runtime 0.057356, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 015, Runtime 0.078825, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 016, Runtime 0.071088, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 017, Runtime 0.059807, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 018, Runtime 0.067125, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 019, Runtime 0.063535, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 020, Runtime 0.078758, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 021, Runtime 0.064628, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 022, Runtime 0.065122, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 023, Runtime 0.058305, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 024, Runtime 0.059543, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 025, Runtime 0.060575, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 026, Runtime 0.063613, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 027, Runtime 0.060894, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 028, Runtime 0.065053, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 029, Runtime 0.061403, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 030, Runtime 0.059429, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 031, Runtime 0.059529, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 032, Runtime 0.059012, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 033, Runtime 0.056670, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 034, Runtime 0.058453, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 035, Runtime 0.058665, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 036, Runtime 0.056246, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 037, Runtime 0.059319, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 038, Runtime 0.056971, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 039, Runtime 0.057464, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 040, Runtime 0.056892, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 041, Runtime 0.058265, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948

 73%|████████████████████████████████████████████████▉                  | 73/100 [00:06<00:01, 16.52it/s]
Epoch: 043, Runtime 0.059002, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 044, Runtime 0.058137, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 045, Runtime 0.057939, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 046, Runtime 0.061920, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 047, Runtime 0.063131, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 048, Runtime 0.057043, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 049, Runtime 0.057027, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 050, Runtime 0.059869, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 051, Runtime 0.076657, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 052, Runtime 0.056758, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 053, Runtime 0.077357, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 054, Runtime 0.066975, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 055, Runtime 0.060256, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 056, Runtime 0.059211, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 057, Runtime 0.066862, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 058, Runtime 0.059441, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 059, Runtime 0.067401, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 060, Runtime 0.066903, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 061, Runtime 0.066935, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 062, Runtime 0.065311, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 063, Runtime 0.057333, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 064, Runtime 0.056714, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 065, Runtime 0.057948, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 066, Runtime 0.057763, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 067, Runtime 0.060234, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 068, Runtime 0.055998, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 069, Runtime 0.055800, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 070, Runtime 0.067251, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 071, Runtime 0.059103, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 072, Runtime 0.058702, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 073, Runtime 0.057348, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948

100%|██████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 12.16it/s]
Epoch: 075, Runtime 0.078780, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 076, Runtime 0.058958, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 077, Runtime 0.051402, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 078, Runtime 0.068653, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 079, Runtime 0.056198, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 080, Runtime 0.064523, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 081, Runtime 0.052773, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 082, Runtime 0.054039, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 083, Runtime 0.211422, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 084, Runtime 0.070862, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 085, Runtime 0.066163, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 086, Runtime 0.060221, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 087, Runtime 0.066199, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 088, Runtime 0.079334, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 089, Runtime 0.065205, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 090, Runtime 0.070876, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 091, Runtime 0.072373, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 092, Runtime 0.069988, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 093, Runtime 0.072489, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 094, Runtime 0.052381, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 095, Runtime 0.063970, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 096, Runtime 0.039470, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 097, Runtime 0.037121, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 098, Runtime 0.037111, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 099, Runtime 0.077229, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 100, Runtime 0.060203, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
best val accuracy 0.132055 with test accuracy 0.160825 at epoch 3 and best time 18.294754