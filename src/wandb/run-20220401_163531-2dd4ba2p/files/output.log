GrandExtendDiscritizedNet
m1.weight
torch.Size([80, 3703])
m1.bias
torch.Size([80])
m2.weight
torch.Size([6, 80])
m2.bias
torch.Size([6])
mol_list.0.alpha_train
torch.Size([])
mol_list.0.beta_train
torch.Size([])
mol_list.0.alpha_sc
torch.Size([1])
mol_list.0.beta_sc
torch.Size([1])
mol_list.0.multihead_att_layer.Q.weight
torch.Size([32, 80])
mol_list.0.multihead_att_layer.Q.bias
torch.Size([32])
mol_list.0.multihead_att_layer.V.weight
torch.Size([32, 80])
mol_list.0.multihead_att_layer.V.bias
torch.Size([32])
mol_list.0.multihead_att_layer.K.weight
torch.Size([32, 80])
mol_list.0.multihead_att_layer.K.bias
torch.Size([32])
mol_list.0.multihead_att_layer.Wout.weight
torch.Size([80, 4])
mol_list.0.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.1.alpha_train
torch.Size([])
mol_list.1.beta_train
torch.Size([])
mol_list.1.alpha_sc
torch.Size([1])
mol_list.1.beta_sc
torch.Size([1])
mol_list.1.multihead_att_layer.Q.weight
torch.Size([32, 80])
mol_list.1.multihead_att_layer.Q.bias
torch.Size([32])
mol_list.1.multihead_att_layer.V.weight
torch.Size([32, 80])
mol_list.1.multihead_att_layer.V.bias
torch.Size([32])
mol_list.1.multihead_att_layer.K.weight
torch.Size([32, 80])
mol_list.1.multihead_att_layer.K.bias
torch.Size([32])
mol_list.1.multihead_att_layer.Wout.weight
torch.Size([80, 4])
mol_list.1.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.2.alpha_train
torch.Size([])
mol_list.2.beta_train
torch.Size([])
mol_list.2.alpha_sc
torch.Size([1])
mol_list.2.beta_sc
torch.Size([1])
mol_list.2.multihead_att_layer.Q.weight
torch.Size([32, 80])
mol_list.2.multihead_att_layer.Q.bias
torch.Size([32])
mol_list.2.multihead_att_layer.V.weight
torch.Size([32, 80])
mol_list.2.multihead_att_layer.V.bias
torch.Size([32])
mol_list.2.multihead_att_layer.K.weight
torch.Size([32, 80])
mol_list.2.multihead_att_layer.K.bias
torch.Size([32])
mol_list.2.multihead_att_layer.Wout.weight
torch.Size([80, 4])
mol_list.2.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.3.alpha_train
torch.Size([])
mol_list.3.beta_train
torch.Size([])
mol_list.3.alpha_sc
torch.Size([1])
mol_list.3.beta_sc
torch.Size([1])
mol_list.3.multihead_att_layer.Q.weight
torch.Size([32, 80])
mol_list.3.multihead_att_layer.Q.bias
torch.Size([32])
mol_list.3.multihead_att_layer.V.weight
torch.Size([32, 80])
mol_list.3.multihead_att_layer.V.bias
torch.Size([32])
mol_list.3.multihead_att_layer.K.weight
torch.Size([32, 80])
mol_list.3.multihead_att_layer.K.bias
torch.Size([32])
mol_list.3.multihead_att_layer.Wout.weight
torch.Size([80, 4])
mol_list.3.multihead_att_layer.Wout.bias
torch.Size([80])

  9%|██▌                          | 22/250 [00:02<00:12, 18.08it/s]
Epoch: 001, Runtime 1.583437, Loss 322439687585136640.000000, Train: 0.1667, Val: 0.1438, Test: 0.1583, Best time: 7.8741
Epoch: 002, Runtime 0.029598, Loss 117855294171643904.000000, Train: 0.1667, Val: 0.1422, Test: 0.1333, Best time: 7.8741
Epoch: 003, Runtime 0.032949, Loss 194755326396858368.000000, Train: 0.1400, Val: 0.1141, Test: 0.1000, Best time: 7.8741
Epoch: 004, Runtime 0.032608, Loss 173377556177747968.000000, Train: 0.1333, Val: 0.1168, Test: 0.1250, Best time: 7.8741
Epoch: 005, Runtime 0.033966, Loss 89196188586213376.000000, Train: 0.1600, Val: 0.1395, Test: 0.1500, Best time: 7.8741
Epoch: 006, Runtime 0.034987, Loss 100786982468190208.000000, Train: 0.1600, Val: 0.1524, Test: 0.1750, Best time: 7.8741
Epoch: 007, Runtime 0.031559, Loss 54454090754686976.000000, Train: 0.1533, Val: 0.1562, Test: 0.1583, Best time: 7.8741
Epoch: 008, Runtime 0.033948, Loss 78265660026650624.000000, Train: 0.1600, Val: 0.1643, Test: 0.1583, Best time: 7.8741
Epoch: 009, Runtime 0.030131, Loss 54536094565269504.000000, Train: 0.1600, Val: 0.1627, Test: 0.1583, Best time: 7.8741
Epoch: 010, Runtime 0.030429, Loss 86491853838352384.000000, Train: 0.1733, Val: 0.1595, Test: 0.1583, Best time: 7.8741
Epoch: 011, Runtime 0.051772, Loss 38119784667152384.000000, Train: 0.1533, Val: 0.1530, Test: 0.1500, Best time: 7.8741
Epoch: 012, Runtime 0.026400, Loss 46289607033094144.000000, Train: 0.1600, Val: 0.1508, Test: 0.1500, Best time: 7.8741
Epoch: 013, Runtime 0.031417, Loss 92711705217335296.000000, Train: 0.1600, Val: 0.1449, Test: 0.1500, Best time: 7.8741
Epoch: 014, Runtime 0.034243, Loss 49728209389879296.000000, Train: 0.1400, Val: 0.1465, Test: 0.0917, Best time: 7.8741
Epoch: 015, Runtime 0.037503, Loss 37238100895727616.000000, Train: 0.1667, Val: 0.1443, Test: 0.1417, Best time: 7.8741
Epoch: 016, Runtime 0.032294, Loss 35085622200762368.000000, Train: 0.1667, Val: 0.1422, Test: 0.1583, Best time: 7.8741
Epoch: 017, Runtime 0.029495, Loss 23826528643055616.000000, Train: 0.1667, Val: 0.1438, Test: 0.1583, Best time: 7.8741
Epoch: 018, Runtime 0.034787, Loss 43025977348980736.000000, Train: 0.1667, Val: 0.1438, Test: 0.1583, Best time: 7.8741
Epoch: 019, Runtime 0.041735, Loss 23819564353585152.000000, Train: 0.1667, Val: 0.1438, Test: 0.1583, Best time: 7.8741
Epoch: 020, Runtime 0.054037, Loss 29163242404184064.000000, Train: 0.1667, Val: 0.1449, Test: 0.1500, Best time: 7.8741
Epoch: 021, Runtime 0.029438, Loss 24843516769206272.000000, Train: 0.1533, Val: 0.1535, Test: 0.1333, Best time: 7.8741
Epoch: 022, Runtime 0.040170, Loss 32429249352695808.000000, Train: 0.1400, Val: 0.1308, Test: 0.1417, Best time: 7.8741

 29%|████████▍                    | 73/250 [00:04<00:06, 25.93it/s]
Epoch: 024, Runtime 0.040866, Loss 21294241695137792.000000, Train: 0.1533, Val: 0.1605, Test: 0.1167, Best time: 7.8741
Epoch: 025, Runtime 0.034687, Loss 19348153358614528.000000, Train: 0.2133, Val: 0.2259, Test: 0.1917, Best time: 7.8741
Epoch: 026, Runtime 0.042706, Loss 18102838328557568.000000, Train: 0.2200, Val: 0.2470, Test: 0.2333, Best time: 7.8741
Epoch: 027, Runtime 0.035838, Loss 25581205319581696.000000, Train: 0.2133, Val: 0.2492, Test: 0.2500, Best time: 7.8741
Epoch: 028, Runtime 0.034010, Loss 13351670343794688.000000, Train: 0.2133, Val: 0.2524, Test: 0.2500, Best time: 7.8741
Epoch: 029, Runtime 0.036935, Loss 25874482866421760.000000, Train: 0.2200, Val: 0.2573, Test: 0.2667, Best time: 7.8741
Epoch: 030, Runtime 0.037548, Loss 12118921314304000.000000, Train: 0.2133, Val: 0.2697, Test: 0.2667, Best time: 7.8741
Epoch: 031, Runtime 0.037242, Loss 10248095837192192.000000, Train: 0.2267, Val: 0.2838, Test: 0.2583, Best time: 7.8741
Epoch: 032, Runtime 0.037466, Loss 27291594440835072.000000, Train: 0.2267, Val: 0.2849, Test: 0.2583, Best time: 7.8741
Epoch: 033, Runtime 0.035669, Loss 13761593833684992.000000, Train: 0.2400, Val: 0.2924, Test: 0.2917, Best time: 7.8741
Epoch: 034, Runtime 0.040609, Loss 19520372957249536.000000, Train: 0.2400, Val: 0.2876, Test: 0.3000, Best time: 7.8741
Epoch: 035, Runtime 0.047113, Loss 13252648799043584.000000, Train: 0.1867, Val: 0.2362, Test: 0.2583, Best time: 7.8741
Epoch: 036, Runtime 0.055639, Loss 11790634415292416.000000, Train: 0.1667, Val: 0.2243, Test: 0.2333, Best time: 7.8741
Epoch: 037, Runtime 0.037048, Loss 13424253143613440.000000, Train: 0.1667, Val: 0.2227, Test: 0.2333, Best time: 7.8741
Epoch: 038, Runtime 0.036732, Loss 31435930791313408.000000, Train: 0.1667, Val: 0.2222, Test: 0.2333, Best time: 7.8741
Epoch: 039, Runtime 0.037786, Loss 6515867504345088.000000, Train: 0.1667, Val: 0.2222, Test: 0.2333, Best time: 7.8741
Epoch: 040, Runtime 0.036439, Loss 11507481180110848.000000, Train: 0.1667, Val: 0.2254, Test: 0.2333, Best time: 7.8741
Epoch: 041, Runtime 0.035592, Loss 16713227429740544.000000, Train: 0.2200, Val: 0.2762, Test: 0.2917, Best time: 7.8741
Epoch: 042, Runtime 0.036009, Loss 6226161222811648.000000, Train: 0.1867, Val: 0.2119, Test: 0.2167, Best time: 7.8741
Epoch: 043, Runtime 0.035941, Loss 13010018580299776.000000, Train: 0.1667, Val: 0.1881, Test: 0.1833, Best time: 7.8741
Epoch: 044, Runtime 0.036660, Loss 11665444708548608.000000, Train: 0.1667, Val: 0.1843, Test: 0.1917, Best time: 7.8741
Epoch: 045, Runtime 0.033067, Loss 4977541752291328.000000, Train: 0.1667, Val: 0.1843, Test: 0.1917, Best time: 7.8741
Epoch: 046, Runtime 0.037184, Loss 10644737140719616.000000, Train: 0.1667, Val: 0.1843, Test: 0.1917, Best time: 7.8741
Epoch: 047, Runtime 0.032632, Loss 8312436218134528.000000, Train: 0.1667, Val: 0.1843, Test: 0.1917, Best time: 7.8741
Epoch: 048, Runtime 0.035968, Loss 12741682982289408.000000, Train: 0.1667, Val: 0.1843, Test: 0.1917, Best time: 7.8741
Epoch: 049, Runtime 0.037091, Loss 6874519822139392.000000, Train: 0.1667, Val: 0.1843, Test: 0.1917, Best time: 7.8741
Epoch: 050, Runtime 0.070215, Loss 15506010907082752.000000, Train: 0.1667, Val: 0.1843, Test: 0.1917, Best time: 7.8741
Epoch: 051, Runtime 0.039101, Loss 4438602545102848.000000, Train: 0.1667, Val: 0.1843, Test: 0.1917, Best time: 7.8741
Epoch: 052, Runtime 0.036608, Loss 6564428015206400.000000, Train: 0.1667, Val: 0.1843, Test: 0.1917, Best time: 7.8741
Epoch: 053, Runtime 0.035933, Loss 9887407704899584.000000, Train: 0.1667, Val: 0.1843, Test: 0.1917, Best time: 7.8741
Epoch: 054, Runtime 0.055164, Loss 6159822768570368.000000, Train: 0.1600, Val: 0.1805, Test: 0.1917, Best time: 7.8741
Epoch: 055, Runtime 0.045924, Loss 6162696101691392.000000, Train: 0.1600, Val: 0.1724, Test: 0.1833, Best time: 7.8741
Epoch: 056, Runtime 0.039551, Loss 8768409810501632.000000, Train: 0.1467, Val: 0.1286, Test: 0.1500, Best time: 7.8741
Epoch: 057, Runtime 0.037163, Loss 7931087145664512.000000, Train: 0.1400, Val: 0.1292, Test: 0.1417, Best time: 7.8741
Epoch: 058, Runtime 0.034191, Loss 6199894276571136.000000, Train: 0.1667, Val: 0.1395, Test: 0.1833, Best time: 7.8741
Epoch: 059, Runtime 0.032358, Loss 4273540509466624.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 060, Runtime 0.034304, Loss 3599494784483328.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 061, Runtime 0.034033, Loss 5594870823518208.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 062, Runtime 0.050290, Loss 4237126166118400.000000, Train: 0.1667, Val: 0.1395, Test: 0.1833, Best time: 7.8741
Epoch: 063, Runtime 0.032690, Loss 5253747877871616.000000, Train: 0.1667, Val: 0.1395, Test: 0.1833, Best time: 7.8741
Epoch: 064, Runtime 0.031119, Loss 4108066425405440.000000, Train: 0.1667, Val: 0.1395, Test: 0.1833, Best time: 7.8741
Epoch: 065, Runtime 0.034256, Loss 4233299887128576.000000, Train: 0.1667, Val: 0.1395, Test: 0.1833, Best time: 7.8741
Epoch: 066, Runtime 0.034023, Loss 5279823698067456.000000, Train: 0.1667, Val: 0.1395, Test: 0.1833, Best time: 7.8741
Epoch: 067, Runtime 0.036164, Loss 3223401946677248.000000, Train: 0.1667, Val: 0.1389, Test: 0.1750, Best time: 7.8741
Epoch: 068, Runtime 0.034763, Loss 4227270021480448.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 069, Runtime 0.035855, Loss 3216726493757440.000000, Train: 0.1667, Val: 0.1400, Test: 0.1750, Best time: 7.8741
Epoch: 070, Runtime 0.040509, Loss 4548200715255808.000000, Train: 0.1600, Val: 0.1389, Test: 0.1750, Best time: 7.8741
Epoch: 071, Runtime 0.038265, Loss 3254241959346176.000000, Train: 0.1400, Val: 0.1649, Test: 0.1833, Best time: 7.8741
Epoch: 072, Runtime 0.038401, Loss 1837288761851904.000000, Train: 0.1600, Val: 0.1838, Test: 0.1917, Best time: 7.8741
Epoch: 073, Runtime 0.040621, Loss 6968240303505408.000000, Train: 0.1667, Val: 0.1843, Test: 0.1917, Best time: 7.8741

 46%|████████████▉               | 116/250 [00:06<00:06, 21.95it/s]
Epoch: 075, Runtime 0.043570, Loss 3399349576925184.000000, Train: 0.1667, Val: 0.1843, Test: 0.1917, Best time: 7.8741
Epoch: 076, Runtime 0.039759, Loss 2995651373694976.000000, Train: 0.1667, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 077, Runtime 0.042955, Loss 2985356337086464.000000, Train: 0.1667, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 078, Runtime 0.045894, Loss 3411832094064640.000000, Train: 0.1667, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 079, Runtime 0.046219, Loss 2321513038479360.000000, Train: 0.1667, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 080, Runtime 0.053969, Loss 1470008391630848.000000, Train: 0.1667, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 081, Runtime 0.049315, Loss 1780675724181504.000000, Train: 0.1667, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 082, Runtime 0.041853, Loss 1776313245368320.000000, Train: 0.1667, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 083, Runtime 0.037610, Loss 1545877512519680.000000, Train: 0.1667, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 084, Runtime 0.039223, Loss 2459141775818752.000000, Train: 0.1667, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 085, Runtime 0.075284, Loss 1659515233632256.000000, Train: 0.1667, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 086, Runtime 0.048389, Loss 1627125140422656.000000, Train: 0.1667, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 087, Runtime 0.042322, Loss 2514651275329536.000000, Train: 0.1667, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 088, Runtime 0.033628, Loss 1433184281559040.000000, Train: 0.1667, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 089, Runtime 0.043561, Loss 1719245478035456.000000, Train: 0.1667, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 090, Runtime 0.042945, Loss 907193394135040.000000, Train: 0.1667, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 091, Runtime 0.033703, Loss 4835864202969088.000000, Train: 0.1667, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 092, Runtime 0.046045, Loss 2216107561713664.000000, Train: 0.1667, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 093, Runtime 0.040086, Loss 2680355140141056.000000, Train: 0.1667, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 094, Runtime 0.051789, Loss 1822210071199744.000000, Train: 0.1667, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 095, Runtime 0.042431, Loss 1194748501032960.000000, Train: 0.1667, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 096, Runtime 0.048639, Loss 1286418135515136.000000, Train: 0.1667, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 097, Runtime 0.062825, Loss 3660491910021120.000000, Train: 0.1667, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 098, Runtime 0.044737, Loss 926181109006336.000000, Train: 0.1667, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 099, Runtime 0.047987, Loss 3195180790317056.000000, Train: 0.1667, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 100, Runtime 0.046423, Loss 1373679254503424.000000, Train: 0.1667, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 101, Runtime 0.040588, Loss 1751641342607360.000000, Train: 0.1667, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 102, Runtime 0.036772, Loss 986922751098880.000000, Train: 0.1667, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 103, Runtime 0.043390, Loss 673233640620032.000000, Train: 0.1667, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 104, Runtime 0.041672, Loss 2282851353493504.000000, Train: 0.1667, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 105, Runtime 0.033414, Loss 1602483973521408.000000, Train: 0.1667, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 106, Runtime 0.040179, Loss 1387096195465216.000000, Train: 0.1667, Val: 0.1849, Test: 0.1833, Best time: 7.8741
Epoch: 107, Runtime 0.042756, Loss 1942060999376896.000000, Train: 0.1667, Val: 0.1849, Test: 0.1917, Best time: 7.8741
Epoch: 108, Runtime 0.046141, Loss 1916349043441664.000000, Train: 0.1667, Val: 0.1849, Test: 0.1917, Best time: 7.8741
Epoch: 109, Runtime 0.178787, Loss 1177029747671040.000000, Train: 0.1667, Val: 0.1843, Test: 0.1917, Best time: 7.8741
Epoch: 110, Runtime 0.047877, Loss 2672032030392320.000000, Train: 0.1667, Val: 0.1843, Test: 0.1917, Best time: 7.8741
Epoch: 111, Runtime 0.045399, Loss 1261265867505664.000000, Train: 0.1667, Val: 0.1843, Test: 0.1917, Best time: 7.8741
Epoch: 112, Runtime 0.030411, Loss 2788231565279232.000000, Train: 0.1667, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 113, Runtime 0.030163, Loss 769004096454656.000000, Train: 0.1667, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 114, Runtime 0.027223, Loss 1750324398260224.000000, Train: 0.1667, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 115, Runtime 0.039452, Loss 806554055999488.000000, Train: 0.1667, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 116, Runtime 0.032889, Loss 1538947314352128.000000, Train: 0.1667, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 117, Runtime 0.029422, Loss 2890655797870592.000000, Train: 0.1667, Val: 0.1843, Test: 0.1917, Best time: 7.8741
Epoch: 118, Runtime 0.029045, Loss 581098874601472.000000, Train: 0.1600, Val: 0.1838, Test: 0.1917, Best time: 7.8741
Epoch: 119, Runtime 0.029550, Loss 1831722752671744.000000, Train: 0.1467, Val: 0.1757, Test: 0.1833, Best time: 7.8741
Epoch: 120, Runtime 0.034950, Loss 661484824690688.000000, Train: 0.1200, Val: 0.1686, Test: 0.1583, Best time: 7.8741
Epoch: 121, Runtime 0.033271, Loss 1104592506978304.000000, Train: 0.1467, Val: 0.1735, Test: 0.1583, Best time: 7.8741

 71%|███████████████████▊        | 177/250 [00:08<00:02, 29.55it/s]
Epoch: 123, Runtime 0.033855, Loss 3216432825368576.000000, Train: 0.1667, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 124, Runtime 0.029460, Loss 373442339667968.000000, Train: 0.1667, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 125, Runtime 0.030161, Loss 601698074624000.000000, Train: 0.1667, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 126, Runtime 0.027659, Loss 408187618459648.000000, Train: 0.1667, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 127, Runtime 0.028498, Loss 390234017628160.000000, Train: 0.1667, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 128, Runtime 0.029700, Loss 451586316828672.000000, Train: 0.1667, Val: 0.1843, Test: 0.1833, Best time: 7.8741
Epoch: 129, Runtime 0.033026, Loss 1700365070237696.000000, Train: 0.1667, Val: 0.2622, Test: 0.1667, Best time: 7.8741
Epoch: 130, Runtime 0.030856, Loss 259687731691520.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 131, Runtime 0.028226, Loss 381998988263424.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 132, Runtime 0.031375, Loss 205859980312576.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 133, Runtime 0.050118, Loss 1744830329782272.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 134, Runtime 0.032248, Loss 261449121267712.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 135, Runtime 0.029564, Loss 2273003798790144.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 136, Runtime 0.029297, Loss 1706545259741184.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 137, Runtime 0.030737, Loss 1448111440396288.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 138, Runtime 0.037971, Loss 10790763495424.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 139, Runtime 0.031109, Loss 738156701810688.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 140, Runtime 0.028100, Loss 1748167653588992.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 141, Runtime 0.028085, Loss 82549640527872.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 142, Runtime 0.030610, Loss 2005931860688896.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 143, Runtime 0.028519, Loss 960799082283008.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 144, Runtime 0.030194, Loss 1089398657515520.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 145, Runtime 0.037590, Loss 293954943713280.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 146, Runtime 0.042094, Loss 158263052075008.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 147, Runtime 0.027351, Loss 1006717852712960.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 148, Runtime 0.029523, Loss 2345032547827712.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 149, Runtime 0.028420, Loss 1307564004343808.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 150, Runtime 0.030194, Loss 104601319636992.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 151, Runtime 0.028832, Loss 283380230914048.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 152, Runtime 0.029073, Loss 911293007527936.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 153, Runtime 0.033664, Loss 117817714147328.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 154, Runtime 0.035904, Loss 361279797592064.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 155, Runtime 0.032700, Loss 243543805263872.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 156, Runtime 0.033392, Loss 1567132097708032.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 157, Runtime 0.035435, Loss 1335189233991680.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 158, Runtime 0.030123, Loss 227560990441472.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 159, Runtime 0.028494, Loss 696007503380480.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 160, Runtime 0.031795, Loss 1289811696549888.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 161, Runtime 0.033221, Loss 1219446442033152.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 162, Runtime 0.030789, Loss 211766986407936.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 163, Runtime 0.032558, Loss 108642288271360.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 164, Runtime 0.035644, Loss 86915558670336.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 165, Runtime 0.033742, Loss 1048387759636480.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 166, Runtime 0.028665, Loss 99444213153792.000000, Train: 0.1667, Val: 0.2649, Test: 0.1750, Best time: 7.8741
Epoch: 167, Runtime 0.031857, Loss 212900505452544.000000, Train: 0.1600, Val: 0.1438, Test: 0.1667, Best time: 7.8741
Epoch: 168, Runtime 0.030969, Loss 1263001839599616.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 169, Runtime 0.036036, Loss 516699161886720.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 170, Runtime 0.034613, Loss 144794370179072.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 171, Runtime 0.030728, Loss 1058001775493120.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 172, Runtime 0.031102, Loss 86355828801536.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 173, Runtime 0.037745, Loss 115818138435584.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 174, Runtime 0.037162, Loss 1444671708463104.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 175, Runtime 0.040642, Loss 723497374449664.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 176, Runtime 0.029027, Loss 41691964768256.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 177, Runtime 0.028800, Loss 25966829109248.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 178, Runtime 0.024259, Loss 969005355499520.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 179, Runtime 0.030041, Loss 14321383899136.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 180, Runtime 0.025948, Loss 14054413303808.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 181, Runtime 0.026040, Loss 28722059018240.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 182, Runtime 0.029736, Loss 25395275497472.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 183, Runtime 0.027378, Loss 2076073374253056.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741

 98%|███████████████████████████▍| 245/250 [00:10<00:00, 34.08it/s]
Epoch: 185, Runtime 0.034081, Loss 780139470258176.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 186, Runtime 0.032854, Loss 1975482958479360.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 187, Runtime 0.028955, Loss 15633374773248.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 188, Runtime 0.030841, Loss 1368689307811840.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 189, Runtime 0.029164, Loss 649332550270976.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 190, Runtime 0.029782, Loss 259028353548288.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 191, Runtime 0.030534, Loss 1290814034542592.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 192, Runtime 0.029889, Loss 36742614745088.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 193, Runtime 0.026045, Loss 1104358968131584.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 194, Runtime 0.028132, Loss 44994387771392.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 195, Runtime 0.033194, Loss 2042557731176448.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 196, Runtime 0.046534, Loss 35490581446656.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 197, Runtime 0.034930, Loss 23171608608768.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 198, Runtime 0.029041, Loss 13892582375424.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 199, Runtime 0.034193, Loss 1613721889669120.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 200, Runtime 0.024659, Loss 37967640920064.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 201, Runtime 0.033150, Loss 1705729887043584.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 202, Runtime 0.024757, Loss 1860734719885312.000000, Train: 0.1667, Val: 0.1395, Test: 0.1833, Best time: 7.8741
Epoch: 203, Runtime 0.028415, Loss 1313825127137280.000000, Train: 0.1667, Val: 0.1395, Test: 0.1833, Best time: 7.8741
Epoch: 204, Runtime 0.025995, Loss 1514537807249408.000000, Train: 0.1667, Val: 0.1395, Test: 0.1833, Best time: 7.8741
Epoch: 205, Runtime 0.026174, Loss 1971889413029888.000000, Train: 0.1667, Val: 0.1395, Test: 0.1833, Best time: 7.8741
Epoch: 206, Runtime 0.025509, Loss 1778243698950144.000000, Train: 0.1667, Val: 0.1395, Test: 0.1833, Best time: 7.8741
Epoch: 207, Runtime 0.025451, Loss 39987173130240.000000, Train: 0.1667, Val: 0.1395, Test: 0.1833, Best time: 7.8741
Epoch: 208, Runtime 0.028648, Loss 795834690043904.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 209, Runtime 0.028656, Loss 34430712283136.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 210, Runtime 0.024508, Loss 1409733894340608.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 211, Runtime 0.028282, Loss 1772484282023936.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 212, Runtime 0.025935, Loss 19611200258048.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 213, Runtime 0.028823, Loss 2947861004156928.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 214, Runtime 0.027011, Loss 55312627269632.000000, Train: 0.1667, Val: 0.1395, Test: 0.1833, Best time: 7.8741
Epoch: 215, Runtime 0.026403, Loss 757966500265984.000000, Train: 0.1600, Val: 0.1427, Test: 0.1667, Best time: 7.8741
Epoch: 216, Runtime 0.026514, Loss 45962332471296.000000, Train: 0.1467, Val: 0.2297, Test: 0.1500, Best time: 7.8741
Epoch: 217, Runtime 0.024920, Loss 144806147784704.000000, Train: 0.1667, Val: 0.2524, Test: 0.1833, Best time: 7.8741
Epoch: 218, Runtime 0.030527, Loss 3618620810723328.000000, Train: 0.1667, Val: 0.1422, Test: 0.1833, Best time: 7.8741
Epoch: 219, Runtime 0.026942, Loss 1232773054464000.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 220, Runtime 0.040883, Loss 43770598916096.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 221, Runtime 0.026100, Loss 28969017540608.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 222, Runtime 0.032779, Loss 35214839513088.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 223, Runtime 0.029945, Loss 11362421964800.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 224, Runtime 0.030175, Loss 13908090814464.000000, Train: 0.1667, Val: 0.1395, Test: 0.1750, Best time: 7.8741
Epoch: 225, Runtime 0.027821, Loss 3113181811572736.000000, Train: 0.1533, Val: 0.1497, Test: 0.1667, Best time: 7.8741
Epoch: 226, Runtime 0.026058, Loss 68379788443648.000000, Train: 0.1667, Val: 0.2589, Test: 0.1667, Best time: 7.8741
Epoch: 227, Runtime 0.032439, Loss 2404616360689664.000000, Train: 0.1667, Val: 0.2627, Test: 0.1667, Best time: 7.8741
Epoch: 228, Runtime 0.032202, Loss 3008627812073472.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 229, Runtime 0.025934, Loss 1278504658272256.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 230, Runtime 0.030901, Loss 27413297758208.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 231, Runtime 0.025497, Loss 2099997818486784.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 232, Runtime 0.028046, Loss 1988469060534272.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 233, Runtime 0.025759, Loss 1859818952327168.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 234, Runtime 0.030040, Loss 86139302051840.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 235, Runtime 0.026793, Loss 221954296512512.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 236, Runtime 0.027890, Loss 127304760033280.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 237, Runtime 0.042083, Loss 3371375112749056.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 238, Runtime 0.027732, Loss 1984946516262912.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 239, Runtime 0.029127, Loss 1691786275717120.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 240, Runtime 0.030037, Loss 86011023458304.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 241, Runtime 0.026982, Loss 116147944947712.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 242, Runtime 0.030466, Loss 1806251717558272.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 243, Runtime 0.027962, Loss 1931360625229824.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 244, Runtime 0.026163, Loss 123553491976192.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 245, Runtime 0.025770, Loss 98814279024640.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 246, Runtime 0.023861, Loss 1327972346757120.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 247, Runtime 0.027180, Loss 1329636512366592.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 248, Runtime 0.025641, Loss 1413735730118656.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 249, Runtime 0.024080, Loss 1506222750564352.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741
Epoch: 250, Runtime 0.024598, Loss 2280688032153600.000000, Train: 0.1667, Val: 0.2627, Test: 0.1750, Best time: 7.8741

100%|████████████████████████████| 250/250 [00:10<00:00, 23.72it/s]