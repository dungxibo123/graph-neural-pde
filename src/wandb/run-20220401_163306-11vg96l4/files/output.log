GrandExtendDiscritizedNet
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
mol_list.0.alpha_train
torch.Size([])
mol_list.0.beta_train
torch.Size([])
mol_list.0.alpha_sc
torch.Size([1])
mol_list.0.beta_sc
torch.Size([1])
mol_list.0.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.0.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.V.bias
torch.Size([128])
mol_list.0.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.K.bias
torch.Size([128])
mol_list.0.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.0.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.1.alpha_train
torch.Size([])
mol_list.1.beta_train
torch.Size([])
mol_list.1.alpha_sc
torch.Size([1])
mol_list.1.beta_sc
torch.Size([1])
mol_list.1.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.1.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.V.bias
torch.Size([128])
mol_list.1.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.K.bias
torch.Size([128])
mol_list.1.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.1.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.2.alpha_train
torch.Size([])
mol_list.2.beta_train
torch.Size([])
mol_list.2.alpha_sc
torch.Size([1])
mol_list.2.beta_sc
torch.Size([1])
mol_list.2.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.2.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.V.bias
torch.Size([128])
mol_list.2.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.K.bias
torch.Size([128])
mol_list.2.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.2.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.3.alpha_train
torch.Size([])
mol_list.3.beta_train
torch.Size([])
mol_list.3.alpha_sc
torch.Size([1])
mol_list.3.beta_sc
torch.Size([1])
mol_list.3.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.3.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.V.bias
torch.Size([128])
mol_list.3.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.K.bias
torch.Size([128])
mol_list.3.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.3.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.4.alpha_train
torch.Size([])
mol_list.4.beta_train
torch.Size([])
mol_list.4.alpha_sc
torch.Size([1])
mol_list.4.beta_sc
torch.Size([1])
mol_list.4.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.4.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.V.bias
torch.Size([128])
mol_list.4.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.K.bias
torch.Size([128])
mol_list.4.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.4.multihead_att_layer.Wout.bias
torch.Size([80])

 28%|████████                     | 28/100 [00:01<00:02, 24.53it/s]
Epoch: 001, Runtime 1.091254, Loss 1.945083, Train: 0.8400, Val: 0.3868, Test: 0.3773, Best time: 18.2948
Epoch: 002, Runtime 0.025562, Loss 1.752618, Train: 0.9086, Val: 0.4559, Test: 0.4392, Best time: 18.2948
Epoch: 003, Runtime 0.027753, Loss 1.468266, Train: 0.9429, Val: 0.4871, Test: 0.4742, Best time: 18.2948
Epoch: 004, Runtime 0.026754, Loss 1.143332, Train: 0.9600, Val: 0.5096, Test: 0.4907, Best time: 18.2948
Epoch: 005, Runtime 0.024945, Loss 0.843767, Train: 0.9771, Val: 0.5507, Test: 0.5299, Best time: 18.2948
Epoch: 006, Runtime 0.026124, Loss 0.597624, Train: 0.9886, Val: 0.5836, Test: 0.5485, Best time: 18.2948
Epoch: 007, Runtime 0.024398, Loss 0.421679, Train: 0.9886, Val: 0.5852, Test: 0.5567, Best time: 18.2948
Epoch: 008, Runtime 0.024404, Loss 0.344573, Train: 0.9886, Val: 0.5819, Test: 0.5505, Best time: 18.2948
Epoch: 009, Runtime 0.024888, Loss 0.210978, Train: 0.9886, Val: 0.5819, Test: 0.5546, Best time: 18.2948
Epoch: 010, Runtime 0.036906, Loss 0.201782, Train: 0.9886, Val: 0.5748, Test: 0.5464, Best time: 18.2948
Epoch: 011, Runtime 0.024008, Loss 0.168760, Train: 0.9943, Val: 0.5655, Test: 0.5423, Best time: 18.2948
Epoch: 012, Runtime 0.027232, Loss 0.142208, Train: 0.9943, Val: 0.5704, Test: 0.5485, Best time: 18.2948
Epoch: 013, Runtime 0.038135, Loss 0.151363, Train: 0.9943, Val: 0.5819, Test: 0.5526, Best time: 18.2948
Epoch: 014, Runtime 0.022612, Loss 0.111869, Train: 0.9943, Val: 0.5863, Test: 0.5505, Best time: 18.2948
Epoch: 015, Runtime 0.028352, Loss 0.128563, Train: 0.9943, Val: 0.5896, Test: 0.5608, Best time: 18.2948
Epoch: 016, Runtime 0.036224, Loss 0.127178, Train: 0.9943, Val: 0.5803, Test: 0.5546, Best time: 18.2948
Epoch: 017, Runtime 0.041605, Loss 0.109792, Train: 1.0000, Val: 0.5874, Test: 0.5546, Best time: 18.2948
Epoch: 018, Runtime 0.027342, Loss 0.121144, Train: 1.0000, Val: 0.5945, Test: 0.5546, Best time: 18.2948
Epoch: 019, Runtime 0.035189, Loss 0.141342, Train: 1.0000, Val: 0.6016, Test: 0.5505, Best time: 18.2948
Epoch: 020, Runtime 0.037964, Loss 0.092077, Train: 1.0000, Val: 0.5984, Test: 0.5485, Best time: 18.2948
Epoch: 021, Runtime 0.024542, Loss 0.128470, Train: 1.0000, Val: 0.5978, Test: 0.5340, Best time: 18.2948
Epoch: 022, Runtime 0.028838, Loss 0.154299, Train: 1.0000, Val: 0.5973, Test: 0.5485, Best time: 18.2948
Epoch: 023, Runtime 0.024923, Loss 0.158549, Train: 1.0000, Val: 0.5934, Test: 0.5443, Best time: 18.2948
Epoch: 024, Runtime 0.024583, Loss 0.114534, Train: 1.0000, Val: 0.5825, Test: 0.5505, Best time: 18.2948
Epoch: 025, Runtime 0.026476, Loss 0.206793, Train: 1.0000, Val: 0.5710, Test: 0.5464, Best time: 18.2948
Epoch: 026, Runtime 0.049922, Loss 0.175735, Train: 1.0000, Val: 0.5693, Test: 0.5485, Best time: 18.2948
Epoch: 027, Runtime 0.035850, Loss 0.169763, Train: 1.0000, Val: 0.5578, Test: 0.5381, Best time: 18.2948
Epoch: 028, Runtime 0.034654, Loss 0.161428, Train: 1.0000, Val: 0.5523, Test: 0.5320, Best time: 18.2948
Epoch: 029, Runtime 0.032923, Loss 0.160406, Train: 1.0000, Val: 0.5496, Test: 0.5258, Best time: 18.2948
Epoch: 030, Runtime 0.034038, Loss 0.169922, Train: 1.0000, Val: 0.5512, Test: 0.5258, Best time: 18.2948

 75%|█████████████████████▊       | 75/100 [00:04<00:01, 20.37it/s]
Epoch: 032, Runtime 0.040009, Loss 0.165392, Train: 1.0000, Val: 0.5721, Test: 0.5443, Best time: 18.2948
Epoch: 033, Runtime 0.035213, Loss 0.150438, Train: 1.0000, Val: 0.5836, Test: 0.5381, Best time: 18.2948
Epoch: 034, Runtime 0.023820, Loss 0.131554, Train: 1.0000, Val: 0.5852, Test: 0.5567, Best time: 18.2948
Epoch: 035, Runtime 0.023856, Loss 0.200637, Train: 1.0000, Val: 0.5890, Test: 0.5588, Best time: 18.2948
Epoch: 036, Runtime 0.044894, Loss 0.225563, Train: 1.0000, Val: 0.5852, Test: 0.5546, Best time: 18.2948
Epoch: 037, Runtime 0.026704, Loss 0.171704, Train: 1.0000, Val: 0.5836, Test: 0.5505, Best time: 18.2948
Epoch: 038, Runtime 0.052039, Loss 0.142913, Train: 1.0000, Val: 0.5737, Test: 0.5505, Best time: 18.2948
Epoch: 039, Runtime 0.037190, Loss 0.132982, Train: 1.0000, Val: 0.5682, Test: 0.5505, Best time: 18.2948
Epoch: 040, Runtime 0.027022, Loss 0.182995, Train: 1.0000, Val: 0.5627, Test: 0.5505, Best time: 18.2948
Epoch: 041, Runtime 0.026774, Loss 0.167090, Train: 1.0000, Val: 0.5655, Test: 0.5505, Best time: 18.2948
Epoch: 042, Runtime 0.024453, Loss 0.128904, Train: 1.0000, Val: 0.5710, Test: 0.5588, Best time: 18.2948
Epoch: 043, Runtime 0.026251, Loss 0.138272, Train: 1.0000, Val: 0.5693, Test: 0.5546, Best time: 18.2948
Epoch: 044, Runtime 0.024257, Loss 0.126260, Train: 1.0000, Val: 0.5732, Test: 0.5608, Best time: 18.2948
Epoch: 045, Runtime 0.024441, Loss 0.142665, Train: 1.0000, Val: 0.5737, Test: 0.5691, Best time: 18.2948
Epoch: 046, Runtime 0.038086, Loss 0.136337, Train: 1.0000, Val: 0.5748, Test: 0.5711, Best time: 18.2948
Epoch: 047, Runtime 0.031012, Loss 0.134731, Train: 1.0000, Val: 0.5737, Test: 0.5753, Best time: 18.2948
Epoch: 048, Runtime 0.037452, Loss 0.149921, Train: 1.0000, Val: 0.5688, Test: 0.5711, Best time: 18.2948
Epoch: 049, Runtime 0.053286, Loss 0.154611, Train: 1.0000, Val: 0.5605, Test: 0.5588, Best time: 18.2948
Epoch: 050, Runtime 0.048384, Loss 0.128738, Train: 1.0000, Val: 0.5595, Test: 0.5505, Best time: 18.2948
Epoch: 051, Runtime 0.052496, Loss 0.127137, Train: 1.0000, Val: 0.5540, Test: 0.5567, Best time: 18.2948
Epoch: 052, Runtime 0.045055, Loss 0.126965, Train: 1.0000, Val: 0.5518, Test: 0.5546, Best time: 18.2948
Epoch: 053, Runtime 0.047975, Loss 0.133320, Train: 1.0000, Val: 0.5507, Test: 0.5485, Best time: 18.2948
Epoch: 054, Runtime 0.055029, Loss 0.121099, Train: 1.0000, Val: 0.5501, Test: 0.5443, Best time: 18.2948
Epoch: 055, Runtime 0.064497, Loss 0.140062, Train: 1.0000, Val: 0.5479, Test: 0.5423, Best time: 18.2948
Epoch: 056, Runtime 0.047707, Loss 0.142569, Train: 1.0000, Val: 0.5463, Test: 0.5443, Best time: 18.2948
Epoch: 057, Runtime 0.061896, Loss 0.124023, Train: 1.0000, Val: 0.5501, Test: 0.5443, Best time: 18.2948
Epoch: 058, Runtime 0.046518, Loss 0.119182, Train: 1.0000, Val: 0.5512, Test: 0.5485, Best time: 18.2948
Epoch: 059, Runtime 0.046846, Loss 0.127151, Train: 1.0000, Val: 0.5551, Test: 0.5464, Best time: 18.2948
Epoch: 060, Runtime 0.055092, Loss 0.103496, Train: 1.0000, Val: 0.5578, Test: 0.5381, Best time: 18.2948
Epoch: 061, Runtime 0.063855, Loss 0.151214, Train: 1.0000, Val: 0.5605, Test: 0.5485, Best time: 18.2948
Epoch: 062, Runtime 0.050153, Loss 0.122302, Train: 1.0000, Val: 0.5627, Test: 0.5546, Best time: 18.2948
Epoch: 063, Runtime 0.050039, Loss 0.160993, Train: 1.0000, Val: 0.5627, Test: 0.5608, Best time: 18.2948
Epoch: 064, Runtime 0.046489, Loss 0.138848, Train: 1.0000, Val: 0.5688, Test: 0.5691, Best time: 18.2948
Epoch: 065, Runtime 0.049205, Loss 0.136176, Train: 1.0000, Val: 0.5715, Test: 0.5732, Best time: 18.2948
Epoch: 066, Runtime 0.047832, Loss 0.112479, Train: 1.0000, Val: 0.5721, Test: 0.5732, Best time: 18.2948
Epoch: 067, Runtime 0.053491, Loss 0.122233, Train: 1.0000, Val: 0.5721, Test: 0.5670, Best time: 18.2948
Epoch: 068, Runtime 0.051654, Loss 0.118897, Train: 1.0000, Val: 0.5732, Test: 0.5608, Best time: 18.2948
Epoch: 069, Runtime 0.047453, Loss 0.130310, Train: 1.0000, Val: 0.5759, Test: 0.5588, Best time: 18.2948
Epoch: 070, Runtime 0.047262, Loss 0.106979, Train: 1.0000, Val: 0.5759, Test: 0.5485, Best time: 18.2948
Epoch: 071, Runtime 0.048074, Loss 0.114354, Train: 1.0000, Val: 0.5742, Test: 0.5505, Best time: 18.2948
Epoch: 072, Runtime 0.048211, Loss 0.137676, Train: 1.0000, Val: 0.5737, Test: 0.5485, Best time: 18.2948
Epoch: 073, Runtime 0.046471, Loss 0.155552, Train: 1.0000, Val: 0.5759, Test: 0.5381, Best time: 18.2948
Epoch: 074, Runtime 0.049025, Loss 0.122862, Train: 1.0000, Val: 0.5721, Test: 0.5340, Best time: 18.2948
Epoch: 075, Runtime 0.047173, Loss 0.123538, Train: 1.0000, Val: 0.5715, Test: 0.5423, Best time: 18.2948

100%|████████████████████████████| 100/100 [00:05<00:00, 18.26it/s]
Epoch: 077, Runtime 0.060258, Loss 0.143439, Train: 1.0000, Val: 0.5759, Test: 0.5320, Best time: 18.2948
Epoch: 078, Runtime 0.051388, Loss 0.145327, Train: 1.0000, Val: 0.5775, Test: 0.5423, Best time: 18.2948
Epoch: 079, Runtime 0.049085, Loss 0.124306, Train: 1.0000, Val: 0.5797, Test: 0.5402, Best time: 18.2948
Epoch: 080, Runtime 0.046990, Loss 0.147197, Train: 1.0000, Val: 0.5825, Test: 0.5423, Best time: 18.2948
Epoch: 081, Runtime 0.046075, Loss 0.158331, Train: 1.0000, Val: 0.5797, Test: 0.5443, Best time: 18.2948
Epoch: 082, Runtime 0.046748, Loss 0.143414, Train: 1.0000, Val: 0.5753, Test: 0.5505, Best time: 18.2948
Epoch: 083, Runtime 0.048528, Loss 0.153797, Train: 1.0000, Val: 0.5737, Test: 0.5546, Best time: 18.2948
Epoch: 084, Runtime 0.046584, Loss 0.107426, Train: 1.0000, Val: 0.5688, Test: 0.5402, Best time: 18.2948
Epoch: 085, Runtime 0.048331, Loss 0.119727, Train: 1.0000, Val: 0.5682, Test: 0.5361, Best time: 18.2948
Epoch: 086, Runtime 0.162045, Loss 0.116882, Train: 1.0000, Val: 0.5638, Test: 0.5485, Best time: 18.2948
Epoch: 087, Runtime 0.052734, Loss 0.146360, Train: 1.0000, Val: 0.5595, Test: 0.5464, Best time: 18.2948
Epoch: 088, Runtime 0.048973, Loss 0.115236, Train: 1.0000, Val: 0.5622, Test: 0.5485, Best time: 18.2948
Epoch: 089, Runtime 0.062942, Loss 0.158826, Train: 1.0000, Val: 0.5622, Test: 0.5505, Best time: 18.2948
Epoch: 090, Runtime 0.053019, Loss 0.096592, Train: 1.0000, Val: 0.5556, Test: 0.5423, Best time: 18.2948
Epoch: 091, Runtime 0.049328, Loss 0.098426, Train: 1.0000, Val: 0.5523, Test: 0.5423, Best time: 18.2948
Epoch: 092, Runtime 0.048731, Loss 0.146297, Train: 1.0000, Val: 0.5501, Test: 0.5443, Best time: 18.2948
Epoch: 093, Runtime 0.048952, Loss 0.137518, Train: 1.0000, Val: 0.5512, Test: 0.5546, Best time: 18.2948
Epoch: 094, Runtime 0.044562, Loss 0.114118, Train: 1.0000, Val: 0.5518, Test: 0.5608, Best time: 18.2948
Epoch: 095, Runtime 0.062605, Loss 0.135147, Train: 1.0000, Val: 0.5534, Test: 0.5567, Best time: 18.2948
Epoch: 096, Runtime 0.069971, Loss 0.102167, Train: 1.0000, Val: 0.5512, Test: 0.5649, Best time: 18.2948
Epoch: 097, Runtime 0.056171, Loss 0.148258, Train: 1.0000, Val: 0.5567, Test: 0.5649, Best time: 18.2948
Epoch: 098, Runtime 0.050944, Loss 0.116520, Train: 1.0000, Val: 0.5660, Test: 0.5732, Best time: 18.2948
Epoch: 099, Runtime 0.065892, Loss 0.171455, Train: 1.0000, Val: 0.5715, Test: 0.5876, Best time: 18.2948
Epoch: 100, Runtime 0.066984, Loss 0.133427, Train: 1.0000, Val: 0.5803, Test: 0.5897, Best time: 18.2948
best val accuracy 0.580274 with test accuracy 0.589691 at epoch 19 and best time 18.294754