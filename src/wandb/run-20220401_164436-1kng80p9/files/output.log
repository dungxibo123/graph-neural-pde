GrandExtendDiscritizedNet
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
mol_list.0.alpha_train
torch.Size([])
mol_list.0.beta_train
torch.Size([])
mol_list.0.alpha_sc
torch.Size([1])
mol_list.0.beta_sc
torch.Size([1])
mol_list.0.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.0.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.V.bias
torch.Size([128])
mol_list.0.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.K.bias
torch.Size([128])
mol_list.0.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.0.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.1.alpha_train
torch.Size([])
mol_list.1.beta_train
torch.Size([])
mol_list.1.alpha_sc
torch.Size([1])
mol_list.1.beta_sc
torch.Size([1])
mol_list.1.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.1.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.V.bias
torch.Size([128])
mol_list.1.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.K.bias
torch.Size([128])
mol_list.1.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.1.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.2.alpha_train
torch.Size([])
mol_list.2.beta_train
torch.Size([])
mol_list.2.alpha_sc
torch.Size([1])
mol_list.2.beta_sc
torch.Size([1])
mol_list.2.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.2.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.V.bias
torch.Size([128])
mol_list.2.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.K.bias
torch.Size([128])
mol_list.2.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.2.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.3.alpha_train
torch.Size([])
mol_list.3.beta_train
torch.Size([])
mol_list.3.alpha_sc
torch.Size([1])
mol_list.3.beta_sc
torch.Size([1])
mol_list.3.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.3.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.V.bias
torch.Size([128])
mol_list.3.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.K.bias
torch.Size([128])
mol_list.3.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.3.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.4.alpha_train
torch.Size([])
mol_list.4.beta_train
torch.Size([])
mol_list.4.alpha_sc
torch.Size([1])
mol_list.4.beta_sc
torch.Size([1])
mol_list.4.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.4.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.V.bias
torch.Size([128])
mol_list.4.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.K.bias
torch.Size([128])
mol_list.4.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.4.multihead_att_layer.Wout.bias
torch.Size([80])

 33%|█████████▌                   | 33/100 [00:03<00:03, 20.79it/s]
Epoch: 001, Runtime 1.564216, Loss 1.945071, Train: 0.8057, Val: 0.4164, Test: 0.4062, Best time: 18.2948
Epoch: 002, Runtime 0.063159, Loss 1.747143, Train: 0.9143, Val: 0.5578, Test: 0.5629, Best time: 18.2948
Epoch: 003, Runtime 0.046573, Loss 1.460714, Train: 0.9600, Val: 0.7112, Test: 0.7216, Best time: 18.2948
Epoch: 004, Runtime 0.035634, Loss 1.186929, Train: 0.9600, Val: 0.7825, Test: 0.7711, Best time: 18.2948
Epoch: 005, Runtime 0.038541, Loss 0.866247, Train: 0.9314, Val: 0.8016, Test: 0.8124, Best time: 18.2948
Epoch: 006, Runtime 0.041963, Loss 0.578593, Train: 0.9143, Val: 0.8121, Test: 0.8351, Best time: 18.2948
Epoch: 007, Runtime 0.046821, Loss 0.325882, Train: 0.1086, Val: 0.0658, Test: 0.0536, Best time: 18.2948
Epoch: 008, Runtime 0.042614, Loss 2.319008, Train: 0.0914, Val: 0.2663, Test: 0.2536, Best time: 18.2948
Epoch: 009, Runtime 0.041110, Loss 12.826923, Train: 0.8686, Val: 0.7671, Test: 0.7814, Best time: 18.2948
Epoch: 010, Runtime 0.044539, Loss 13171.011719, Train: 0.6686, Val: 0.6071, Test: 0.6515, Best time: 18.2948
Epoch: 011, Runtime 0.048120, Loss 4798707.500000, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 012, Runtime 0.034240, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 013, Runtime 0.045192, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 014, Runtime 0.049757, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 015, Runtime 0.038112, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 016, Runtime 0.047112, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 017, Runtime 0.045306, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 018, Runtime 0.043133, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 019, Runtime 0.050942, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 020, Runtime 0.041531, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 021, Runtime 0.045212, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 022, Runtime 0.048291, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 023, Runtime 0.043840, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 024, Runtime 0.046722, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 025, Runtime 0.051459, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 026, Runtime 0.043137, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 027, Runtime 0.043719, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 028, Runtime 0.045560, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 029, Runtime 0.049671, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 030, Runtime 0.032815, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 031, Runtime 0.044437, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 032, Runtime 0.040435, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 033, Runtime 0.046880, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 034, Runtime 0.049195, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948

 78%|██████████████████████▌      | 78/100 [00:05<00:01, 21.87it/s]
Epoch: 036, Runtime 0.060222, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 037, Runtime 0.050369, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 038, Runtime 0.042127, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 039, Runtime 0.041004, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 040, Runtime 0.044845, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 041, Runtime 0.040899, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 042, Runtime 0.045294, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 043, Runtime 0.041568, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 044, Runtime 0.046486, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 045, Runtime 0.038800, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 046, Runtime 0.042519, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 047, Runtime 0.061176, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 048, Runtime 0.045558, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 049, Runtime 0.043858, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 050, Runtime 0.038977, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 051, Runtime 0.043166, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 052, Runtime 0.039845, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 053, Runtime 0.041724, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 054, Runtime 0.048126, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 055, Runtime 0.038130, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 056, Runtime 0.037028, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 057, Runtime 0.039237, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 058, Runtime 0.044445, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 059, Runtime 0.051911, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 060, Runtime 0.042019, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 061, Runtime 0.043697, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 062, Runtime 0.046103, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 063, Runtime 0.047485, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 064, Runtime 0.045789, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 065, Runtime 0.048383, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 066, Runtime 0.043461, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 067, Runtime 0.041518, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 068, Runtime 0.047100, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 069, Runtime 0.051176, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 070, Runtime 0.050194, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 071, Runtime 0.050048, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 072, Runtime 0.041255, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 073, Runtime 0.043096, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 074, Runtime 0.042309, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 075, Runtime 0.046998, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 076, Runtime 0.037544, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 077, Runtime 0.048144, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 078, Runtime 0.046456, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 079, Runtime 0.042290, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 080, Runtime 0.046539, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 081, Runtime 0.051294, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 082, Runtime 0.045393, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 083, Runtime 0.047143, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 084, Runtime 0.042409, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 085, Runtime 0.049233, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 086, Runtime 0.042215, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 087, Runtime 0.036574, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 088, Runtime 0.037832, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 089, Runtime 0.036461, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 090, Runtime 0.042007, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 091, Runtime 0.078928, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 092, Runtime 0.048125, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 093, Runtime 0.038823, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 094, Runtime 0.041961, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 095, Runtime 0.044609, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 096, Runtime 0.057388, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 097, Runtime 0.040470, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 098, Runtime 0.045696, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 099, Runtime 0.046304, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948
Epoch: 100, Runtime 0.054272, Loss nan, Train: 0.1429, Val: 0.1321, Test: 0.1608, Best time: 18.2948

100%|████████████████████████████| 100/100 [00:06<00:00, 16.40it/s]