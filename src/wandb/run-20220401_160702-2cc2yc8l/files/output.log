GrandExtendDiscritizedNet
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
mol_list.0.alpha_train
torch.Size([])
mol_list.0.beta_train
torch.Size([])
mol_list.0.alpha_sc
torch.Size([1])
mol_list.0.beta_sc
torch.Size([1])
mol_list.0.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.0.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.V.bias
torch.Size([128])
mol_list.0.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.K.bias
torch.Size([128])
mol_list.0.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.0.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.1.alpha_train
torch.Size([])
mol_list.1.beta_train
torch.Size([])
mol_list.1.alpha_sc
torch.Size([1])
mol_list.1.beta_sc
torch.Size([1])
mol_list.1.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.1.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.V.bias
torch.Size([128])
mol_list.1.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.K.bias
torch.Size([128])
mol_list.1.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.1.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.2.alpha_train
torch.Size([])
mol_list.2.beta_train
torch.Size([])
mol_list.2.alpha_sc
torch.Size([1])
mol_list.2.beta_sc
torch.Size([1])
mol_list.2.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.2.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.V.bias
torch.Size([128])
mol_list.2.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.K.bias
torch.Size([128])
mol_list.2.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.2.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.3.alpha_train
torch.Size([])
mol_list.3.beta_train
torch.Size([])
mol_list.3.alpha_sc
torch.Size([1])
mol_list.3.beta_sc
torch.Size([1])
mol_list.3.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.3.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.V.bias
torch.Size([128])
mol_list.3.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.K.bias
torch.Size([128])
mol_list.3.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.3.multihead_att_layer.Wout.bias
torch.Size([80])
  0%|                                      | 0/100 [00:00<?, ?it/s]
Epoch: 001, Runtime 1.596734, Loss 1.948932, Train: 0.9086, Val: 0.4521, Test: 0.4742, Best time: 18.2948
Epoch: 002, Runtime 0.030211, Loss 1.754478, Train: 0.9429, Val: 0.4811, Test: 0.4825, Best time: 18.2948
Epoch: 003, Runtime 0.031873, Loss 1.466142, Train: 0.9543, Val: 0.5036, Test: 0.4948, Best time: 18.2948
Epoch: 004, Runtime 0.030892, Loss 1.151112, Train: 0.9657, Val: 0.5244, Test: 0.5299, Best time: 18.2948
Epoch: 005, Runtime 0.031384, Loss 0.834065, Train: 0.9771, Val: 0.5715, Test: 0.5711, Best time: 18.2948
Epoch: 006, Runtime 0.033161, Loss 0.660979, Train: 0.9829, Val: 0.5940, Test: 0.5959, Best time: 18.2948
Epoch: 007, Runtime 0.029591, Loss 0.427134, Train: 0.9886, Val: 0.6038, Test: 0.6103, Best time: 18.2948
Epoch: 008, Runtime 0.028852, Loss 0.367695, Train: 0.9886, Val: 0.6088, Test: 0.6082, Best time: 18.2948
Epoch: 009, Runtime 0.027404, Loss 0.277233, Train: 0.9886, Val: 0.6066, Test: 0.6165, Best time: 18.2948
Epoch: 010, Runtime 0.026680, Loss 0.243544, Train: 0.9886, Val: 0.6027, Test: 0.6124, Best time: 18.2948
Epoch: 011, Runtime 0.030254, Loss 0.181083, Train: 0.9943, Val: 0.5984, Test: 0.6103, Best time: 18.2948
Epoch: 012, Runtime 0.031928, Loss 0.201335, Train: 0.9943, Val: 0.6000, Test: 0.6082, Best time: 18.2948
Epoch: 013, Runtime 0.030467, Loss 0.190513, Train: 0.9943, Val: 0.5995, Test: 0.6021, Best time: 18.2948
Epoch: 014, Runtime 0.034080, Loss 0.195526, Train: 0.9943, Val: 0.6011, Test: 0.6021, Best time: 18.2948
Epoch: 015, Runtime 0.037979, Loss 0.161011, Train: 0.9943, Val: 0.5978, Test: 0.6041, Best time: 18.2948
Epoch: 016, Runtime 0.038252, Loss 0.144615, Train: 0.9943, Val: 0.5973, Test: 0.6021, Best time: 18.2948
Epoch: 017, Runtime 0.029269, Loss 0.234471, Train: 0.9943, Val: 0.5918, Test: 0.6000, Best time: 18.2948
Epoch: 018, Runtime 0.028630, Loss 0.129485, Train: 0.9943, Val: 0.5929, Test: 0.5897, Best time: 18.2948
Epoch: 019, Runtime 0.034205, Loss 0.112175, Train: 1.0000, Val: 0.5934, Test: 0.5691, Best time: 18.2948
Epoch: 020, Runtime 0.034624, Loss 0.168624, Train: 0.9943, Val: 0.6000, Test: 0.5691, Best time: 18.2948
Epoch: 021, Runtime 0.031106, Loss 0.160057, Train: 0.9943, Val: 0.6011, Test: 0.5711, Best time: 18.2948
Epoch: 022, Runtime 0.031360, Loss 0.221538, Train: 0.9943, Val: 0.6088, Test: 0.5753, Best time: 18.2948
Epoch: 023, Runtime 0.032897, Loss 0.222725, Train: 1.0000, Val: 0.6082, Test: 0.5835, Best time: 18.2948
Epoch: 024, Runtime 0.028644, Loss 0.179943, Train: 1.0000, Val: 0.5973, Test: 0.5835, Best time: 18.2948
Epoch: 025, Runtime 0.032302, Loss 0.166143, Train: 0.9943, Val: 0.5852, Test: 0.5670, Best time: 18.2948
Epoch: 026, Runtime 0.031026, Loss 0.165582, Train: 0.9943, Val: 0.5753, Test: 0.5505, Best time: 18.2948
Epoch: 027, Runtime 0.029706, Loss 0.183042, Train: 0.9943, Val: 0.5633, Test: 0.5381, Best time: 18.2948
Epoch: 028, Runtime 0.027833, Loss 0.205178, Train: 0.9943, Val: 0.5644, Test: 0.5361, Best time: 18.2948
Epoch: 029, Runtime 0.029596, Loss 0.206037, Train: 1.0000, Val: 0.5721, Test: 0.5402, Best time: 18.2948


 97%|████████████████████████████▏| 97/100 [00:04<00:00, 32.00it/s]
Epoch: 031, Runtime 0.035988, Loss 0.221685, Train: 0.9943, Val: 0.5775, Test: 0.5856, Best time: 18.2948
Epoch: 032, Runtime 0.029517, Loss 0.235877, Train: 0.9943, Val: 0.5814, Test: 0.5835, Best time: 18.2948
Epoch: 033, Runtime 0.030342, Loss 0.193996, Train: 0.9943, Val: 0.5814, Test: 0.5856, Best time: 18.2948
Epoch: 034, Runtime 0.032158, Loss 0.170763, Train: 0.9943, Val: 0.5803, Test: 0.5732, Best time: 18.2948
Epoch: 035, Runtime 0.031507, Loss 0.219275, Train: 0.9943, Val: 0.5792, Test: 0.5691, Best time: 18.2948
Epoch: 036, Runtime 0.031512, Loss 0.177815, Train: 0.9943, Val: 0.5704, Test: 0.5546, Best time: 18.2948
Epoch: 037, Runtime 0.028501, Loss 0.177568, Train: 0.9943, Val: 0.5671, Test: 0.5485, Best time: 18.2948
Epoch: 038, Runtime 0.031237, Loss 0.177818, Train: 1.0000, Val: 0.5573, Test: 0.5402, Best time: 18.2948
Epoch: 039, Runtime 0.029500, Loss 0.150318, Train: 1.0000, Val: 0.5534, Test: 0.5402, Best time: 18.2948
Epoch: 040, Runtime 0.029533, Loss 0.202711, Train: 1.0000, Val: 0.5518, Test: 0.5423, Best time: 18.2948
Epoch: 041, Runtime 0.029811, Loss 0.190807, Train: 0.9943, Val: 0.5485, Test: 0.5361, Best time: 18.2948
Epoch: 042, Runtime 0.031872, Loss 0.153250, Train: 0.9943, Val: 0.5595, Test: 0.5381, Best time: 18.2948
Epoch: 043, Runtime 0.031146, Loss 0.174939, Train: 0.9943, Val: 0.5660, Test: 0.5423, Best time: 18.2948
Epoch: 044, Runtime 0.029743, Loss 0.194220, Train: 0.9943, Val: 0.5655, Test: 0.5464, Best time: 18.2948
Epoch: 045, Runtime 0.033030, Loss 0.139707, Train: 0.9943, Val: 0.5699, Test: 0.5443, Best time: 18.2948
Epoch: 046, Runtime 0.030652, Loss 0.153755, Train: 0.9943, Val: 0.5721, Test: 0.5423, Best time: 18.2948
Epoch: 047, Runtime 0.049443, Loss 0.179091, Train: 0.9943, Val: 0.5693, Test: 0.5505, Best time: 18.2948
Epoch: 048, Runtime 0.028010, Loss 0.174191, Train: 0.9943, Val: 0.5688, Test: 0.5443, Best time: 18.2948
Epoch: 049, Runtime 0.026682, Loss 0.140175, Train: 0.9943, Val: 0.5671, Test: 0.5526, Best time: 18.2948
Epoch: 050, Runtime 0.032390, Loss 0.171487, Train: 0.9943, Val: 0.5616, Test: 0.5546, Best time: 18.2948
Epoch: 051, Runtime 0.025493, Loss 0.159684, Train: 0.9943, Val: 0.5633, Test: 0.5505, Best time: 18.2948
Epoch: 052, Runtime 0.032297, Loss 0.173461, Train: 0.9943, Val: 0.5616, Test: 0.5588, Best time: 18.2948
Epoch: 053, Runtime 0.028231, Loss 0.156922, Train: 0.9943, Val: 0.5649, Test: 0.5526, Best time: 18.2948
Epoch: 054, Runtime 0.024779, Loss 0.148677, Train: 0.9943, Val: 0.5649, Test: 0.5505, Best time: 18.2948
Epoch: 055, Runtime 0.029472, Loss 0.148382, Train: 0.9943, Val: 0.5660, Test: 0.5485, Best time: 18.2948
Epoch: 056, Runtime 0.023334, Loss 0.149665, Train: 0.9943, Val: 0.5622, Test: 0.5464, Best time: 18.2948
Epoch: 057, Runtime 0.022053, Loss 0.184238, Train: 0.9943, Val: 0.5616, Test: 0.5588, Best time: 18.2948
Epoch: 058, Runtime 0.022482, Loss 0.152684, Train: 1.0000, Val: 0.5688, Test: 0.5608, Best time: 18.2948
Epoch: 059, Runtime 0.021434, Loss 0.152821, Train: 0.9943, Val: 0.5715, Test: 0.5649, Best time: 18.2948
Epoch: 060, Runtime 0.023334, Loss 0.231754, Train: 0.9943, Val: 0.5819, Test: 0.5773, Best time: 18.2948
Epoch: 061, Runtime 0.025835, Loss 0.225626, Train: 0.9943, Val: 0.5836, Test: 0.5711, Best time: 18.2948
Epoch: 062, Runtime 0.026353, Loss 0.161727, Train: 0.9943, Val: 0.5896, Test: 0.5588, Best time: 18.2948
Epoch: 063, Runtime 0.024052, Loss 0.138068, Train: 0.9886, Val: 0.5907, Test: 0.5691, Best time: 18.2948
Epoch: 064, Runtime 0.029393, Loss 0.185123, Train: 0.9943, Val: 0.5863, Test: 0.5670, Best time: 18.2948
Epoch: 065, Runtime 0.026803, Loss 0.143445, Train: 0.9943, Val: 0.5852, Test: 0.5629, Best time: 18.2948
Epoch: 066, Runtime 0.035353, Loss 0.139798, Train: 0.9943, Val: 0.5803, Test: 0.5629, Best time: 18.2948
Epoch: 067, Runtime 0.026769, Loss 0.162518, Train: 0.9943, Val: 0.5764, Test: 0.5773, Best time: 18.2948
Epoch: 068, Runtime 0.026647, Loss 0.126162, Train: 0.9943, Val: 0.5682, Test: 0.5794, Best time: 18.2948
Epoch: 069, Runtime 0.024005, Loss 0.175137, Train: 0.9943, Val: 0.5600, Test: 0.5794, Best time: 18.2948
Epoch: 070, Runtime 0.024592, Loss 0.131460, Train: 0.9943, Val: 0.5573, Test: 0.5670, Best time: 18.2948
Epoch: 071, Runtime 0.023502, Loss 0.144302, Train: 0.9943, Val: 0.5556, Test: 0.5670, Best time: 18.2948
Epoch: 072, Runtime 0.024807, Loss 0.163367, Train: 0.9943, Val: 0.5523, Test: 0.5691, Best time: 18.2948
Epoch: 073, Runtime 0.027360, Loss 0.159242, Train: 0.9943, Val: 0.5600, Test: 0.5732, Best time: 18.2948
Epoch: 074, Runtime 0.026472, Loss 0.179990, Train: 0.9943, Val: 0.5627, Test: 0.5732, Best time: 18.2948
Epoch: 075, Runtime 0.024223, Loss 0.166484, Train: 1.0000, Val: 0.5633, Test: 0.5670, Best time: 18.2948
Epoch: 076, Runtime 0.042209, Loss 0.151715, Train: 1.0000, Val: 0.5671, Test: 0.5670, Best time: 18.2948
Epoch: 077, Runtime 0.025122, Loss 0.160869, Train: 1.0000, Val: 0.5726, Test: 0.5670, Best time: 18.2948
Epoch: 078, Runtime 0.027760, Loss 0.157204, Train: 0.9943, Val: 0.5748, Test: 0.5691, Best time: 18.2948
Epoch: 079, Runtime 0.034692, Loss 0.131449, Train: 0.9943, Val: 0.5808, Test: 0.5588, Best time: 18.2948
Epoch: 080, Runtime 0.028600, Loss 0.142255, Train: 0.9943, Val: 0.5836, Test: 0.5649, Best time: 18.2948
Epoch: 081, Runtime 0.025224, Loss 0.156026, Train: 0.9943, Val: 0.5836, Test: 0.5691, Best time: 18.2948
Epoch: 082, Runtime 0.029395, Loss 0.144284, Train: 0.9943, Val: 0.5858, Test: 0.5753, Best time: 18.2948
Epoch: 083, Runtime 0.028924, Loss 0.162080, Train: 0.9943, Val: 0.5830, Test: 0.5691, Best time: 18.2948
Epoch: 084, Runtime 0.039379, Loss 0.191903, Train: 0.9943, Val: 0.5847, Test: 0.5588, Best time: 18.2948
Epoch: 085, Runtime 0.029972, Loss 0.171490, Train: 0.9943, Val: 0.5841, Test: 0.5608, Best time: 18.2948
Epoch: 086, Runtime 0.028132, Loss 0.151170, Train: 0.9943, Val: 0.5852, Test: 0.5649, Best time: 18.2948
Epoch: 087, Runtime 0.031400, Loss 0.170722, Train: 0.9943, Val: 0.5852, Test: 0.5691, Best time: 18.2948
Epoch: 088, Runtime 0.031811, Loss 0.126353, Train: 0.9943, Val: 0.5797, Test: 0.5629, Best time: 18.2948
Epoch: 089, Runtime 0.033601, Loss 0.156884, Train: 0.9943, Val: 0.5803, Test: 0.5546, Best time: 18.2948
Epoch: 090, Runtime 0.030818, Loss 0.154206, Train: 0.9943, Val: 0.5836, Test: 0.5567, Best time: 18.2948
Epoch: 091, Runtime 0.035291, Loss 0.188897, Train: 0.9943, Val: 0.5797, Test: 0.5567, Best time: 18.2948
Epoch: 092, Runtime 0.029963, Loss 0.159152, Train: 0.9943, Val: 0.5786, Test: 0.5526, Best time: 18.2948
Epoch: 093, Runtime 0.028231, Loss 0.127443, Train: 0.9886, Val: 0.5792, Test: 0.5567, Best time: 18.2948
Epoch: 094, Runtime 0.036957, Loss 0.197543, Train: 0.9943, Val: 0.5781, Test: 0.5588, Best time: 18.2948
Epoch: 095, Runtime 0.028640, Loss 0.152614, Train: 0.9943, Val: 0.5792, Test: 0.5629, Best time: 18.2948
Epoch: 096, Runtime 0.032643, Loss 0.162296, Train: 0.9943, Val: 0.5781, Test: 0.5649, Best time: 18.2948
Epoch: 097, Runtime 0.028358, Loss 0.169716, Train: 0.9943, Val: 0.5814, Test: 0.5629, Best time: 18.2948
Epoch: 098, Runtime 0.030447, Loss 0.168474, Train: 0.9943, Val: 0.5803, Test: 0.5670, Best time: 18.2948
Epoch: 099, Runtime 0.156383, Loss 0.133328, Train: 0.9886, Val: 0.5814, Test: 0.5711, Best time: 18.2948
Epoch: 100, Runtime 0.032912, Loss 0.170459, Train: 0.9943, Val: 0.5819, Test: 0.5814, Best time: 18.2948

100%|████████████████████████████| 100/100 [00:04<00:00, 21.05it/s]