GrandExtendDiscritizedNet
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
mol_list.0.alpha_train
torch.Size([])
mol_list.0.beta_train
torch.Size([])
mol_list.0.alpha_sc
torch.Size([1])
mol_list.0.beta_sc
torch.Size([1])
mol_list.0.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.0.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.V.bias
torch.Size([128])
mol_list.0.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.K.bias
torch.Size([128])
mol_list.0.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.0.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.1.alpha_train
torch.Size([])
mol_list.1.beta_train
torch.Size([])
mol_list.1.alpha_sc
torch.Size([1])
mol_list.1.beta_sc
torch.Size([1])
mol_list.1.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.1.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.V.bias
torch.Size([128])
mol_list.1.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.K.bias
torch.Size([128])
mol_list.1.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.1.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.2.alpha_train
torch.Size([])
mol_list.2.beta_train
torch.Size([])
mol_list.2.alpha_sc
torch.Size([1])
mol_list.2.beta_sc
torch.Size([1])
mol_list.2.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.2.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.V.bias
torch.Size([128])
mol_list.2.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.K.bias
torch.Size([128])
mol_list.2.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.2.multihead_att_layer.Wout.bias
torch.Size([80])
  0%|                                      | 0/100 [00:00<?, ?it/s]
Epoch: 001, Runtime 1.099170, Loss 1.948705, Train: 0.2171, Val: 0.1310, Test: 0.1216, Best time: 18.2948
Epoch: 002, Runtime 0.018052, Loss 335575.562500, Train: 0.2286, Val: 0.1430, Test: 0.1340, Best time: 18.2948
Epoch: 003, Runtime 0.018541, Loss 5803656.000000, Train: 0.5371, Val: 0.3332, Test: 0.3320, Best time: 18.2948
Epoch: 004, Runtime 0.018836, Loss 228.828278, Train: 0.2000, Val: 0.1458, Test: 0.1526, Best time: 18.2948
Epoch: 005, Runtime 0.017330, Loss 4559329.000000, Train: 0.1543, Val: 0.1545, Test: 0.1505, Best time: 18.2948
Epoch: 006, Runtime 0.018648, Loss 8337652224.000000, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 007, Runtime 0.017388, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 008, Runtime 0.016284, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 009, Runtime 0.018746, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 010, Runtime 0.018064, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 011, Runtime 0.017448, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 012, Runtime 0.016885, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 013, Runtime 0.018020, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 014, Runtime 0.016201, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 015, Runtime 0.017151, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 016, Runtime 0.016476, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 017, Runtime 0.019681, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 018, Runtime 0.018884, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 019, Runtime 0.020399, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 020, Runtime 0.019077, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 021, Runtime 0.018458, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 022, Runtime 0.020797, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 023, Runtime 0.021558, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 024, Runtime 0.022848, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 025, Runtime 0.020340, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 026, Runtime 0.019119, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 027, Runtime 0.044204, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 028, Runtime 0.020795, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 029, Runtime 0.017435, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 030, Runtime 0.018260, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 031, Runtime 0.018420, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 032, Runtime 0.018096, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 033, Runtime 0.025132, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 034, Runtime 0.018092, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 035, Runtime 0.018583, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 036, Runtime 0.018713, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 037, Runtime 0.017893, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 038, Runtime 0.017880, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 039, Runtime 0.017768, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 040, Runtime 0.018300, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 041, Runtime 0.019173, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 042, Runtime 0.022717, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 043, Runtime 0.018771, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 044, Runtime 0.018167, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 045, Runtime 0.018293, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 046, Runtime 0.017803, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 047, Runtime 0.018000, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 048, Runtime 0.018558, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 049, Runtime 0.020596, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 050, Runtime 0.021518, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 051, Runtime 0.029230, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 052, Runtime 0.034174, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 053, Runtime 0.018764, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 054, Runtime 0.023783, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 055, Runtime 0.022832, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 056, Runtime 0.022307, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 057, Runtime 0.022545, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 058, Runtime 0.021622, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 059, Runtime 0.019914, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 060, Runtime 0.026343, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 061, Runtime 0.021881, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 062, Runtime 0.022455, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 063, Runtime 0.021838, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 064, Runtime 0.022102, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 065, Runtime 0.029532, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 066, Runtime 0.026436, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 067, Runtime 0.021813, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 068, Runtime 0.020910, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 069, Runtime 0.023302, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 070, Runtime 0.026876, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 071, Runtime 0.025973, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 072, Runtime 0.025914, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 073, Runtime 0.035041, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 074, Runtime 0.022141, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 075, Runtime 0.021488, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 076, Runtime 0.021409, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 077, Runtime 0.022074, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 078, Runtime 0.019611, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 079, Runtime 0.023522, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 080, Runtime 0.015550, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 081, Runtime 0.024368, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 082, Runtime 0.021458, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 083, Runtime 0.026791, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 084, Runtime 0.020759, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 085, Runtime 0.026796, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 086, Runtime 0.022549, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 087, Runtime 0.019945, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 088, Runtime 0.020967, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 089, Runtime 0.021423, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 090, Runtime 0.019445, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 091, Runtime 0.018980, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 092, Runtime 0.019317, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 093, Runtime 0.019223, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948

 92%|██████████████████████████▋  | 92/100 [00:03<00:00, 44.06it/s]
Epoch: 095, Runtime 0.040102, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 096, Runtime 0.020366, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 097, Runtime 0.020915, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 098, Runtime 0.020489, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 099, Runtime 0.020947, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948
Epoch: 100, Runtime 0.024922, Loss nan, Train: 0.1429, Val: 0.1348, Test: 0.1505, Best time: 18.2948

100%|████████████████████████████| 100/100 [00:03<00:00, 30.64it/s]