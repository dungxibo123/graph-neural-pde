GrandExtendDiscritizedNet
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
mol_list.0.alpha_train
torch.Size([])
mol_list.0.beta_train
torch.Size([])
mol_list.0.alpha_sc
torch.Size([1])
mol_list.0.beta_sc
torch.Size([1])
mol_list.0.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.0.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.V.bias
torch.Size([128])
mol_list.0.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.K.bias
torch.Size([128])
mol_list.0.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.0.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.1.alpha_train
torch.Size([])
mol_list.1.beta_train
torch.Size([])
mol_list.1.alpha_sc
torch.Size([1])
mol_list.1.beta_sc
torch.Size([1])
mol_list.1.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.1.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.V.bias
torch.Size([128])
mol_list.1.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.K.bias
torch.Size([128])
mol_list.1.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.1.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.2.alpha_train
torch.Size([])
mol_list.2.beta_train
torch.Size([])
mol_list.2.alpha_sc
torch.Size([1])
mol_list.2.beta_sc
torch.Size([1])
mol_list.2.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.2.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.V.bias
torch.Size([128])
mol_list.2.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.K.bias
torch.Size([128])
mol_list.2.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.2.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.3.alpha_train
torch.Size([])
mol_list.3.beta_train
torch.Size([])
mol_list.3.alpha_sc
torch.Size([1])
mol_list.3.beta_sc
torch.Size([1])
mol_list.3.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.3.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.V.bias
torch.Size([128])
mol_list.3.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.K.bias
torch.Size([128])
mol_list.3.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.3.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.4.alpha_train
torch.Size([])
mol_list.4.beta_train
torch.Size([])
mol_list.4.alpha_sc
torch.Size([1])
mol_list.4.beta_sc
torch.Size([1])
mol_list.4.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.4.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.V.bias
torch.Size([128])
mol_list.4.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.K.bias
torch.Size([128])
mol_list.4.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.4.multihead_att_layer.Wout.bias
torch.Size([80])
  0%|                                      | 0/100 [00:00<?, ?it/s]
Epoch: 001, Runtime 1.399029, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 002, Runtime 0.040882, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 003, Runtime 0.037374, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 004, Runtime 0.035294, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 005, Runtime 0.036238, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 006, Runtime 0.038319, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 007, Runtime 0.036695, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 008, Runtime 0.046055, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 009, Runtime 0.034691, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 010, Runtime 0.032180, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 011, Runtime 0.038890, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 012, Runtime 0.038659, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 013, Runtime 0.048035, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 014, Runtime 0.041220, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 015, Runtime 0.041178, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 016, Runtime 0.044188, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 017, Runtime 0.034400, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 018, Runtime 0.035551, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 019, Runtime 0.038787, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 020, Runtime 0.042110, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 021, Runtime 0.045482, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 022, Runtime 0.035160, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 023, Runtime 0.037976, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 024, Runtime 0.033880, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 025, Runtime 0.035256, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 026, Runtime 0.033026, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 027, Runtime 0.036331, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 028, Runtime 0.038240, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 029, Runtime 0.035707, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 030, Runtime 0.034634, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 031, Runtime 0.036409, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 032, Runtime 0.033563, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948


 86%|████████████████████████▉    | 86/100 [00:04<00:00, 27.73it/s]
Epoch: 034, Runtime 0.049015, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 035, Runtime 0.036141, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 036, Runtime 0.034692, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 037, Runtime 0.035744, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 038, Runtime 0.038628, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 039, Runtime 0.039782, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 040, Runtime 0.037218, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 041, Runtime 0.039454, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 042, Runtime 0.040648, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 043, Runtime 0.039834, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 044, Runtime 0.038851, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 045, Runtime 0.043665, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 046, Runtime 0.057376, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 047, Runtime 0.038304, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 048, Runtime 0.036188, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 049, Runtime 0.036767, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 050, Runtime 0.043474, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 051, Runtime 0.040054, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 052, Runtime 0.033654, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 053, Runtime 0.029443, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 054, Runtime 0.035117, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 055, Runtime 0.034394, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 056, Runtime 0.028410, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 057, Runtime 0.032694, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 058, Runtime 0.032897, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 059, Runtime 0.029937, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 060, Runtime 0.033552, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 061, Runtime 0.036750, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 062, Runtime 0.033205, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 063, Runtime 0.037159, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 064, Runtime 0.036860, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 065, Runtime 0.032816, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 066, Runtime 0.035263, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 067, Runtime 0.033423, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 068, Runtime 0.039712, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 069, Runtime 0.040507, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 070, Runtime 0.039889, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 071, Runtime 0.037108, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 072, Runtime 0.031887, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 073, Runtime 0.034722, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 074, Runtime 0.040125, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 075, Runtime 0.035235, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 076, Runtime 0.032680, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 077, Runtime 0.034282, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 078, Runtime 0.032574, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 079, Runtime 0.040510, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 080, Runtime 0.035385, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 081, Runtime 0.037212, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 082, Runtime 0.035802, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 083, Runtime 0.037758, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 084, Runtime 0.033931, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 085, Runtime 0.033271, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 086, Runtime 0.033601, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 087, Runtime 0.032379, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 088, Runtime 0.183289, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 089, Runtime 0.037603, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 090, Runtime 0.030818, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 091, Runtime 0.030714, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 092, Runtime 0.030915, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 093, Runtime 0.029844, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 094, Runtime 0.032335, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 095, Runtime 0.034149, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 096, Runtime 0.055117, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 097, Runtime 0.035037, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 098, Runtime 0.033202, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 099, Runtime 0.034181, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948
Epoch: 100, Runtime 0.032033, Loss nan, Train: 0.1429, Val: 0.1353, Test: 0.1485, Best time: 18.2948

100%|████████████████████████████| 100/100 [00:05<00:00, 18.52it/s]