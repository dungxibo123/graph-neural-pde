
  0%|                                      | 0/600 [00:00<?, ?it/s]
GrandExtendDiscritizedNet
m1.weight
torch.Size([128, 500])
m1.bias
torch.Size([128])
m2.weight
torch.Size([3, 128])
m2.bias
torch.Size([3])
mol_list.0.alpha_train
torch.Size([])
mol_list.0.beta_train
torch.Size([])
mol_list.0.alpha_sc
torch.Size([1])
mol_list.0.beta_sc
torch.Size([1])
mol_list.0.multihead_att_layer.Q.weight
torch.Size([16, 128])
mol_list.0.multihead_att_layer.Q.bias
torch.Size([16])
mol_list.0.multihead_att_layer.V.weight
torch.Size([16, 128])
mol_list.0.multihead_att_layer.V.bias
torch.Size([16])
mol_list.0.multihead_att_layer.K.weight
torch.Size([16, 128])
mol_list.0.multihead_att_layer.K.bias
torch.Size([16])
mol_list.0.multihead_att_layer.Wout.weight
torch.Size([128, 16])
mol_list.0.multihead_att_layer.Wout.bias
torch.Size([128])
mol_list.1.alpha_train
torch.Size([])
mol_list.1.beta_train
torch.Size([])
mol_list.1.alpha_sc
torch.Size([1])
mol_list.1.beta_sc
torch.Size([1])
mol_list.1.multihead_att_layer.Q.weight
torch.Size([16, 128])
mol_list.1.multihead_att_layer.Q.bias
torch.Size([16])
mol_list.1.multihead_att_layer.V.weight
torch.Size([16, 128])
mol_list.1.multihead_att_layer.V.bias
torch.Size([16])
mol_list.1.multihead_att_layer.K.weight
torch.Size([16, 128])
mol_list.1.multihead_att_layer.K.bias
torch.Size([16])
mol_list.1.multihead_att_layer.Wout.weight
torch.Size([128, 16])
mol_list.1.multihead_att_layer.Wout.bias
torch.Size([128])
mol_list.2.alpha_train
torch.Size([])
mol_list.2.beta_train
torch.Size([])
mol_list.2.alpha_sc
torch.Size([1])
mol_list.2.beta_sc
torch.Size([1])
mol_list.2.multihead_att_layer.Q.weight
torch.Size([16, 128])
mol_list.2.multihead_att_layer.Q.bias
torch.Size([16])
mol_list.2.multihead_att_layer.V.weight
torch.Size([16, 128])
mol_list.2.multihead_att_layer.V.bias
torch.Size([16])
mol_list.2.multihead_att_layer.K.weight
torch.Size([16, 128])
mol_list.2.multihead_att_layer.K.bias
torch.Size([16])
mol_list.2.multihead_att_layer.Wout.weight
torch.Size([128, 16])
mol_list.2.multihead_att_layer.Wout.bias
torch.Size([128])
mol_list.3.alpha_train
torch.Size([])
mol_list.3.beta_train
torch.Size([])
mol_list.3.alpha_sc
torch.Size([1])
mol_list.3.beta_sc
torch.Size([1])
mol_list.3.multihead_att_layer.Q.weight
torch.Size([16, 128])
mol_list.3.multihead_att_layer.Q.bias
torch.Size([16])
mol_list.3.multihead_att_layer.V.weight
torch.Size([16, 128])
mol_list.3.multihead_att_layer.V.bias
torch.Size([16])
mol_list.3.multihead_att_layer.K.weight
torch.Size([16, 128])
mol_list.3.multihead_att_layer.K.bias
torch.Size([16])
mol_list.3.multihead_att_layer.Wout.weight
torch.Size([128, 16])
mol_list.3.multihead_att_layer.Wout.bias
torch.Size([128])
mol_list.4.alpha_train
torch.Size([])
mol_list.4.beta_train
torch.Size([])
mol_list.4.alpha_sc
torch.Size([1])
mol_list.4.beta_sc
torch.Size([1])
mol_list.4.multihead_att_layer.Q.weight
torch.Size([16, 128])
mol_list.4.multihead_att_layer.Q.bias
torch.Size([16])
mol_list.4.multihead_att_layer.V.weight
torch.Size([16, 128])
mol_list.4.multihead_att_layer.V.bias
torch.Size([16])
mol_list.4.multihead_att_layer.K.weight
torch.Size([16, 128])
mol_list.4.multihead_att_layer.K.bias
torch.Size([16])
mol_list.4.multihead_att_layer.Wout.weight
torch.Size([128, 16])
mol_list.4.multihead_att_layer.Wout.bias
torch.Size([128])
mol_list.5.alpha_train
torch.Size([])
mol_list.5.beta_train
torch.Size([])
mol_list.5.alpha_sc
torch.Size([1])
mol_list.5.beta_sc
torch.Size([1])
mol_list.5.multihead_att_layer.Q.weight
torch.Size([16, 128])
mol_list.5.multihead_att_layer.Q.bias
torch.Size([16])
mol_list.5.multihead_att_layer.V.weight
torch.Size([16, 128])
mol_list.5.multihead_att_layer.V.bias
torch.Size([16])
mol_list.5.multihead_att_layer.K.weight
torch.Size([16, 128])
mol_list.5.multihead_att_layer.K.bias
torch.Size([16])
mol_list.5.multihead_att_layer.Wout.weight
torch.Size([128, 16])
mol_list.5.multihead_att_layer.Wout.bias
  0%|                                      | 0/600 [00:02<?, ?it/s]
Traceback (most recent call last):
  File "/home/cuongnq1/graph-neural-pde/src/run_grand_ex.py", line 427, in <module>
    main(opt)
  File "/home/cuongnq1/graph-neural-pde/src/run_grand_ex.py", line 232, in main
    loss = train(model, optimizer, data, pos_encoding)
  File "/home/cuongnq1/graph-neural-pde/src/run_grand_ex.py", line 91, in train
    loss.backward()
  File "/home/cuongnq1/anaconda3/envs/grand/lib/python3.9/site-packages/torch/_tensor.py", line 307, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/cuongnq1/anaconda3/envs/grand/lib/python3.9/site-packages/torch/autograd/__init__.py", line 154, in backward
    Variable._execution_engine.run_backward(
RuntimeError: CUDA out of memory. Tried to allocate 54.00 MiB (GPU 0; 22.20 GiB total capacity; 6.51 GiB already allocated; 11.06 MiB free; 6.59 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF