GrandExtendDiscritizedNet
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
mol_list.0.alpha_train
torch.Size([])
mol_list.0.beta_train
torch.Size([])
mol_list.0.alpha_sc
torch.Size([1])
mol_list.0.beta_sc
torch.Size([1])
mol_list.0.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.0.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.V.bias
torch.Size([128])
mol_list.0.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.K.bias
torch.Size([128])
mol_list.0.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.0.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.1.alpha_train
torch.Size([])
mol_list.1.beta_train
torch.Size([])
mol_list.1.alpha_sc
torch.Size([1])
mol_list.1.beta_sc
torch.Size([1])
mol_list.1.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.1.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.V.bias
torch.Size([128])
mol_list.1.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.K.bias
torch.Size([128])
mol_list.1.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.1.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.2.alpha_train
torch.Size([])
mol_list.2.beta_train
torch.Size([])
mol_list.2.alpha_sc
torch.Size([1])
mol_list.2.beta_sc
torch.Size([1])
mol_list.2.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.2.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.V.bias
torch.Size([128])
mol_list.2.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.K.bias
torch.Size([128])
mol_list.2.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.2.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.3.alpha_train
torch.Size([])
mol_list.3.beta_train
torch.Size([])
mol_list.3.alpha_sc
torch.Size([1])
mol_list.3.beta_sc
torch.Size([1])
mol_list.3.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.3.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.V.bias
torch.Size([128])
mol_list.3.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.K.bias
torch.Size([128])
mol_list.3.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.3.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.4.alpha_train
torch.Size([])
mol_list.4.beta_train
torch.Size([])
mol_list.4.alpha_sc
torch.Size([1])
mol_list.4.beta_sc
torch.Size([1])
mol_list.4.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.4.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.V.bias
torch.Size([128])
mol_list.4.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.K.bias
torch.Size([128])
mol_list.4.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.4.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.5.alpha_train
torch.Size([])
mol_list.5.beta_train
torch.Size([])
mol_list.5.alpha_sc
torch.Size([1])
mol_list.5.beta_sc
torch.Size([1])
mol_list.5.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.5.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.5.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.5.multihead_att_layer.V.bias
torch.Size([128])
mol_list.5.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.5.multihead_att_layer.K.bias
torch.Size([128])
mol_list.5.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.5.multihead_att_layer.Wout.bias
torch.Size([80])
  0%|                                      | 0/100 [00:00<?, ?it/s]
Epoch: 001, Runtime 1.712543, Loss 1.946509, Train: 0.7943, Val: 0.4521, Test: 0.4186, Best time: 18.2948
Epoch: 002, Runtime 0.064361, Loss 1.761429, Train: 0.9029, Val: 0.5956, Test: 0.5670, Best time: 18.2948
Epoch: 003, Runtime 0.068171, Loss 1.473719, Train: 0.9086, Val: 0.6378, Test: 0.6268, Best time: 18.2948
Epoch: 004, Runtime 0.067590, Loss 1.206760, Train: 0.9371, Val: 0.7162, Test: 0.7072, Best time: 18.2948
Epoch: 005, Runtime 0.065142, Loss 0.938626, Train: 0.9486, Val: 0.7589, Test: 0.7629, Best time: 18.2948
Epoch: 006, Runtime 0.065986, Loss 0.628677, Train: 0.9543, Val: 0.7973, Test: 0.7918, Best time: 18.2948
Epoch: 007, Runtime 0.061512, Loss 0.402478, Train: 0.9600, Val: 0.8115, Test: 0.8000, Best time: 18.2948
Epoch: 008, Runtime 0.061060, Loss 0.298438, Train: 0.9600, Val: 0.8175, Test: 0.7959, Best time: 18.2948
Epoch: 009, Runtime 0.064021, Loss 0.268907, Train: 0.9657, Val: 0.8077, Test: 0.8062, Best time: 18.2948
Epoch: 010, Runtime 0.068332, Loss 0.281152, Train: 0.9657, Val: 0.8071, Test: 0.8041, Best time: 18.2948
Epoch: 011, Runtime 0.063136, Loss 0.274662, Train: 0.9657, Val: 0.8060, Test: 0.8103, Best time: 18.2948
Epoch: 012, Runtime 0.064390, Loss 0.289950, Train: 0.9714, Val: 0.8055, Test: 0.8124, Best time: 18.2948
Epoch: 013, Runtime 0.065706, Loss 0.340312, Train: 0.9657, Val: 0.8071, Test: 0.8062, Best time: 18.2948
Epoch: 014, Runtime 0.057627, Loss 0.342180, Train: 0.9657, Val: 0.8077, Test: 0.8000, Best time: 18.2948
Epoch: 015, Runtime 0.066470, Loss 0.351380, Train: 0.9714, Val: 0.8066, Test: 0.8000, Best time: 18.2948
Epoch: 016, Runtime 0.077361, Loss 0.379289, Train: 0.9714, Val: 0.8049, Test: 0.8062, Best time: 18.2948


 39%|███████████▎                 | 39/100 [00:04<00:05, 11.50it/s]
Epoch: 018, Runtime 0.087436, Loss 0.388030, Train: 0.9714, Val: 0.8027, Test: 0.8021, Best time: 18.2948
Epoch: 019, Runtime 0.084663, Loss 0.401176, Train: 0.9714, Val: 0.8022, Test: 0.8021, Best time: 18.2948
Epoch: 020, Runtime 0.085766, Loss 0.436369, Train: 0.9714, Val: 0.8022, Test: 0.8000, Best time: 18.2948
Epoch: 021, Runtime 0.086396, Loss 0.423212, Train: 0.9657, Val: 0.8033, Test: 0.8000, Best time: 18.2948
Epoch: 022, Runtime 0.085783, Loss 0.451986, Train: 0.9657, Val: 0.8022, Test: 0.7959, Best time: 18.2948
Epoch: 023, Runtime 0.091217, Loss 0.414231, Train: 0.9657, Val: 0.8005, Test: 0.7938, Best time: 18.2948
Epoch: 024, Runtime 0.079650, Loss 0.436730, Train: 0.9657, Val: 0.8000, Test: 0.7876, Best time: 18.2948
Epoch: 025, Runtime 0.085857, Loss 0.419239, Train: 0.9600, Val: 0.8000, Test: 0.7835, Best time: 18.2948
Epoch: 026, Runtime 0.086475, Loss 0.421425, Train: 0.9600, Val: 0.8000, Test: 0.7876, Best time: 18.2948
Epoch: 027, Runtime 0.085799, Loss 0.421220, Train: 0.9600, Val: 0.7989, Test: 0.7835, Best time: 18.2948
Epoch: 028, Runtime 0.081980, Loss 0.442178, Train: 0.9600, Val: 0.7973, Test: 0.7856, Best time: 18.2948
Epoch: 029, Runtime 0.094810, Loss 0.443124, Train: 0.9600, Val: 0.7962, Test: 0.7856, Best time: 18.2948
Epoch: 030, Runtime 0.077188, Loss 0.444176, Train: 0.9600, Val: 0.7967, Test: 0.7835, Best time: 18.2948
Epoch: 031, Runtime 0.091506, Loss 0.419403, Train: 0.9657, Val: 0.7973, Test: 0.7835, Best time: 18.2948
Epoch: 032, Runtime 0.081950, Loss 0.420339, Train: 0.9657, Val: 0.7984, Test: 0.7835, Best time: 18.2948
Epoch: 033, Runtime 0.088485, Loss 0.400781, Train: 0.9600, Val: 0.7984, Test: 0.7835, Best time: 18.2948
Epoch: 034, Runtime 0.084646, Loss 0.390521, Train: 0.9600, Val: 0.7989, Test: 0.7835, Best time: 18.2948
Epoch: 035, Runtime 0.086868, Loss 0.386195, Train: 0.9600, Val: 0.8005, Test: 0.7856, Best time: 18.2948
Epoch: 036, Runtime 0.086220, Loss 0.394612, Train: 0.9600, Val: 0.8011, Test: 0.7876, Best time: 18.2948
Epoch: 037, Runtime 0.086333, Loss 0.406567, Train: 0.9600, Val: 0.8016, Test: 0.7876, Best time: 18.2948
Epoch: 038, Runtime 0.086628, Loss 0.375692, Train: 0.9600, Val: 0.8011, Test: 0.7938, Best time: 18.2948
Epoch: 039, Runtime 0.087282, Loss 0.355749, Train: 0.9600, Val: 0.8011, Test: 0.7918, Best time: 18.2948
Epoch: 040, Runtime 0.085061, Loss 0.348523, Train: 0.9714, Val: 0.8011, Test: 0.7938, Best time: 18.2948
Epoch: 041, Runtime 0.085284, Loss 0.344526, Train: 0.9714, Val: 0.8027, Test: 0.7938, Best time: 18.2948
Epoch: 042, Runtime 0.083550, Loss 0.368374, Train: 0.9714, Val: 0.8033, Test: 0.7959, Best time: 18.2948
Epoch: 043, Runtime 0.086514, Loss 0.347539, Train: 0.9714, Val: 0.8033, Test: 0.7959, Best time: 18.2948
Epoch: 044, Runtime 0.085617, Loss 0.356380, Train: 0.9714, Val: 0.8038, Test: 0.7979, Best time: 18.2948
Epoch: 045, Runtime 0.086683, Loss 0.330376, Train: 0.9714, Val: 0.8027, Test: 0.7979, Best time: 18.2948
Epoch: 046, Runtime 0.091511, Loss 0.349623, Train: 0.9714, Val: 0.8005, Test: 0.8000, Best time: 18.2948
Epoch: 047, Runtime 0.083279, Loss 0.332960, Train: 0.9714, Val: 0.8011, Test: 0.8021, Best time: 18.2948
Epoch: 048, Runtime 0.082785, Loss 0.307269, Train: 0.9714, Val: 0.8022, Test: 0.8062, Best time: 18.2948
Epoch: 049, Runtime 0.086685, Loss 0.309156, Train: 0.9771, Val: 0.8038, Test: 0.8062, Best time: 18.2948
Epoch: 050, Runtime 0.085123, Loss 0.304983, Train: 0.9771, Val: 0.8027, Test: 0.8041, Best time: 18.2948
Epoch: 051, Runtime 0.086891, Loss 0.296009, Train: 0.9771, Val: 0.8027, Test: 0.8041, Best time: 18.2948
Epoch: 052, Runtime 0.087030, Loss 0.308684, Train: 0.9771, Val: 0.8033, Test: 0.7979, Best time: 18.2948
Epoch: 053, Runtime 0.085202, Loss 0.265896, Train: 0.9771, Val: 0.8027, Test: 0.7938, Best time: 18.2948
Epoch: 054, Runtime 0.083668, Loss 0.280514, Train: 0.9771, Val: 0.7995, Test: 0.7938, Best time: 18.2948
Epoch: 055, Runtime 0.086284, Loss 0.321066, Train: 0.9771, Val: 0.7984, Test: 0.7938, Best time: 18.2948
Epoch: 056, Runtime 0.083114, Loss 0.287060, Train: 0.9771, Val: 0.7973, Test: 0.7938, Best time: 18.2948
Epoch: 057, Runtime 0.083328, Loss 0.266472, Train: 0.9771, Val: 0.7973, Test: 0.7959, Best time: 18.2948
Epoch: 058, Runtime 0.083202, Loss 0.256989, Train: 0.9771, Val: 0.7967, Test: 0.7959, Best time: 18.2948
Epoch: 059, Runtime 0.086393, Loss 0.259708, Train: 0.9771, Val: 0.7951, Test: 0.8000, Best time: 18.2948
Epoch: 060, Runtime 0.085815, Loss 0.246275, Train: 0.9771, Val: 0.7956, Test: 0.7979, Best time: 18.2948
Epoch: 061, Runtime 0.085769, Loss 0.261089, Train: 0.9829, Val: 0.7962, Test: 0.7979, Best time: 18.2948
Epoch: 062, Runtime 0.086737, Loss 0.254519, Train: 0.9771, Val: 0.7973, Test: 0.7979, Best time: 18.2948

 63%|██████████████████▎          | 63/100 [00:06<00:03, 11.54it/s]
Epoch: 064, Runtime 0.091058, Loss 0.272374, Train: 0.9771, Val: 0.7951, Test: 0.7938, Best time: 18.2948
Epoch: 065, Runtime 0.081796, Loss 0.241080, Train: 0.9829, Val: 0.7956, Test: 0.7938, Best time: 18.2948
Epoch: 066, Runtime 0.085220, Loss 0.246396, Train: 0.9829, Val: 0.7940, Test: 0.7918, Best time: 18.2948
Epoch: 067, Runtime 0.086211, Loss 0.272605, Train: 0.9829, Val: 0.7940, Test: 0.7938, Best time: 18.2948
Epoch: 068, Runtime 0.086956, Loss 0.249542, Train: 0.9829, Val: 0.7945, Test: 0.7918, Best time: 18.2948
Epoch: 069, Runtime 0.085666, Loss 0.261456, Train: 0.9829, Val: 0.7945, Test: 0.7918, Best time: 18.2948
Epoch: 070, Runtime 0.086524, Loss 0.237834, Train: 0.9829, Val: 0.7951, Test: 0.7918, Best time: 18.2948
Epoch: 071, Runtime 0.082212, Loss 0.238746, Train: 0.9829, Val: 0.7951, Test: 0.7897, Best time: 18.2948
Epoch: 072, Runtime 0.085864, Loss 0.232321, Train: 0.9829, Val: 0.7945, Test: 0.7897, Best time: 18.2948
Epoch: 073, Runtime 0.085538, Loss 0.254386, Train: 0.9829, Val: 0.7951, Test: 0.7876, Best time: 18.2948
Epoch: 074, Runtime 0.086127, Loss 0.223922, Train: 0.9829, Val: 0.7956, Test: 0.7876, Best time: 18.2948
Epoch: 075, Runtime 0.086539, Loss 0.251598, Train: 0.9829, Val: 0.7962, Test: 0.7876, Best time: 18.2948
Epoch: 076, Runtime 0.217228, Loss 0.234381, Train: 0.9829, Val: 0.7951, Test: 0.7897, Best time: 18.2948
Epoch: 077, Runtime 0.099598, Loss 0.229880, Train: 0.9829, Val: 0.7951, Test: 0.7876, Best time: 18.2948
Epoch: 078, Runtime 0.091599, Loss 0.248009, Train: 0.9829, Val: 0.7934, Test: 0.7876, Best time: 18.2948
Epoch: 079, Runtime 0.087046, Loss 0.228588, Train: 0.9829, Val: 0.7934, Test: 0.7918, Best time: 18.2948
Epoch: 080, Runtime 0.085394, Loss 0.236149, Train: 0.9829, Val: 0.7934, Test: 0.7897, Best time: 18.2948
Epoch: 081, Runtime 0.088289, Loss 0.216391, Train: 0.9829, Val: 0.7940, Test: 0.7876, Best time: 18.2948
Epoch: 082, Runtime 0.082285, Loss 0.195100, Train: 0.9829, Val: 0.7940, Test: 0.7897, Best time: 18.2948
Epoch: 083, Runtime 0.079561, Loss 0.236379, Train: 0.9829, Val: 0.7945, Test: 0.7876, Best time: 18.2948
Epoch: 084, Runtime 0.076962, Loss 0.209338, Train: 0.9829, Val: 0.7940, Test: 0.7856, Best time: 18.2948
Epoch: 085, Runtime 0.086370, Loss 0.203499, Train: 0.9829, Val: 0.7940, Test: 0.7856, Best time: 18.2948


100%|████████████████████████████| 100/100 [00:10<00:00,  9.87it/s]
Epoch: 087, Runtime 0.086846, Loss 0.206715, Train: 0.9829, Val: 0.7929, Test: 0.7876, Best time: 18.2948
Epoch: 088, Runtime 0.085868, Loss 0.209683, Train: 0.9829, Val: 0.7940, Test: 0.7876, Best time: 18.2948
Epoch: 089, Runtime 0.086827, Loss 0.209534, Train: 0.9829, Val: 0.7934, Test: 0.7876, Best time: 18.2948
Epoch: 090, Runtime 0.085812, Loss 0.234661, Train: 0.9829, Val: 0.7940, Test: 0.7856, Best time: 18.2948
Epoch: 091, Runtime 0.086441, Loss 0.223180, Train: 0.9829, Val: 0.7940, Test: 0.7856, Best time: 18.2948
Epoch: 092, Runtime 0.085252, Loss 0.230747, Train: 0.9829, Val: 0.7945, Test: 0.7876, Best time: 18.2948
Epoch: 093, Runtime 0.086981, Loss 0.230519, Train: 0.9829, Val: 0.7945, Test: 0.7856, Best time: 18.2948
Epoch: 094, Runtime 0.083064, Loss 0.195787, Train: 0.9829, Val: 0.7940, Test: 0.7876, Best time: 18.2948
Epoch: 095, Runtime 0.086657, Loss 0.203269, Train: 0.9829, Val: 0.7923, Test: 0.7856, Best time: 18.2948
Epoch: 096, Runtime 0.084027, Loss 0.201575, Train: 0.9829, Val: 0.7929, Test: 0.7876, Best time: 18.2948
Epoch: 097, Runtime 0.087956, Loss 0.181920, Train: 0.9829, Val: 0.7934, Test: 0.7897, Best time: 18.2948
Epoch: 098, Runtime 0.084105, Loss 0.230779, Train: 0.9829, Val: 0.7940, Test: 0.7876, Best time: 18.2948
Epoch: 099, Runtime 0.091303, Loss 0.183490, Train: 0.9829, Val: 0.7945, Test: 0.7876, Best time: 18.2948
Epoch: 100, Runtime 0.078943, Loss 0.195407, Train: 0.9829, Val: 0.7951, Test: 0.7876, Best time: 18.2948
best val accuracy 0.795068 with test accuracy 0.787629 at epoch 8 and best time 18.294754