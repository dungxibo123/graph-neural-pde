
  0%|                                      | 0/250 [00:00<?, ?it/s]
GrandExtendDiscritizedNet
m1.weight
torch.Size([16, 6805])
m1.bias
torch.Size([16])
m2.weight
torch.Size([15, 16])
m2.bias
torch.Size([15])
mol_list.0.alpha_train
torch.Size([])
mol_list.0.beta_train
torch.Size([])
mol_list.0.alpha_sc
torch.Size([1])
mol_list.0.beta_sc
torch.Size([1])
mol_list.0.multihead_att_layer.Q.weight
torch.Size([8, 16])
mol_list.0.multihead_att_layer.Q.bias
torch.Size([8])
mol_list.0.multihead_att_layer.V.weight
torch.Size([8, 16])
mol_list.0.multihead_att_layer.V.bias
torch.Size([8])
mol_list.0.multihead_att_layer.K.weight
torch.Size([8, 16])
mol_list.0.multihead_att_layer.K.bias
torch.Size([8])
mol_list.0.multihead_att_layer.Wout.weight
torch.Size([16, 2])
mol_list.0.multihead_att_layer.Wout.bias
torch.Size([16])
mol_list.1.alpha_train
torch.Size([])
mol_list.1.beta_train
torch.Size([])
mol_list.1.alpha_sc
torch.Size([1])
mol_list.1.beta_sc
torch.Size([1])
mol_list.1.multihead_att_layer.Q.weight
torch.Size([8, 16])
mol_list.1.multihead_att_layer.Q.bias
torch.Size([8])
mol_list.1.multihead_att_layer.V.weight
torch.Size([8, 16])
mol_list.1.multihead_att_layer.V.bias
torch.Size([8])
mol_list.1.multihead_att_layer.K.weight
torch.Size([8, 16])
mol_list.1.multihead_att_layer.K.bias
torch.Size([8])
mol_list.1.multihead_att_layer.Wout.weight
torch.Size([16, 2])
mol_list.1.multihead_att_layer.Wout.bias
torch.Size([16])
mol_list.2.alpha_train
torch.Size([])
mol_list.2.beta_train
torch.Size([])
mol_list.2.alpha_sc
torch.Size([1])
mol_list.2.beta_sc
torch.Size([1])
mol_list.2.multihead_att_layer.Q.weight
torch.Size([8, 16])
mol_list.2.multihead_att_layer.Q.bias
torch.Size([8])
mol_list.2.multihead_att_layer.V.weight
torch.Size([8, 16])
mol_list.2.multihead_att_layer.V.bias
torch.Size([8])
mol_list.2.multihead_att_layer.K.weight
torch.Size([8, 16])
mol_list.2.multihead_att_layer.K.bias
torch.Size([8])
mol_list.2.multihead_att_layer.Wout.weight
torch.Size([16, 2])
mol_list.2.multihead_att_layer.Wout.bias
torch.Size([16])
mol_list.3.alpha_train
torch.Size([])
mol_list.3.beta_train
torch.Size([])
mol_list.3.alpha_sc
torch.Size([1])
mol_list.3.beta_sc
torch.Size([1])
mol_list.3.multihead_att_layer.Q.weight
torch.Size([8, 16])
mol_list.3.multihead_att_layer.Q.bias
torch.Size([8])
mol_list.3.multihead_att_layer.V.weight
torch.Size([8, 16])
mol_list.3.multihead_att_layer.V.bias
torch.Size([8])
mol_list.3.multihead_att_layer.K.weight
torch.Size([8, 16])
mol_list.3.multihead_att_layer.K.bias
torch.Size([8])
mol_list.3.multihead_att_layer.Wout.weight
torch.Size([16, 2])
mol_list.3.multihead_att_layer.Wout.bias

 11%|███▏                         | 28/250 [00:02<00:09, 24.39it/s]
Epoch: 001, Runtime 1.487803, Loss 2.715316, Train: 0.1840, Val: 0.1762, Test: 0.1772, Best time: 3.1264
Epoch: 002, Runtime 0.029275, Loss 3458033057267712.000000, Train: 0.1973, Val: 0.1870, Test: 0.1864, Best time: 3.1264
Epoch: 003, Runtime 0.033712, Loss 2689921374486528.000000, Train: 0.1920, Val: 0.1896, Test: 0.1897, Best time: 3.1264
Epoch: 004, Runtime 0.029610, Loss 2984011475451904.000000, Train: 0.2107, Val: 0.1935, Test: 0.1954, Best time: 3.1264
Epoch: 005, Runtime 0.027620, Loss 2401669744689152.000000, Train: 0.2080, Val: 0.1944, Test: 0.1957, Best time: 3.1264
Epoch: 006, Runtime 0.027703, Loss 2704012356878336.000000, Train: 0.2080, Val: 0.1994, Test: 0.1991, Best time: 3.1264
Epoch: 007, Runtime 0.029108, Loss 2987426242887680.000000, Train: 0.2133, Val: 0.1933, Test: 0.1945, Best time: 3.1264
Epoch: 008, Runtime 0.030900, Loss 2767499758141440.000000, Train: 0.2160, Val: 0.1864, Test: 0.1926, Best time: 3.1264
Epoch: 009, Runtime 0.028157, Loss 2173651675774976.000000, Train: 0.2187, Val: 0.1844, Test: 0.1906, Best time: 3.1264
Epoch: 010, Runtime 0.029947, Loss 2143889163026432.000000, Train: 0.2160, Val: 0.1842, Test: 0.1905, Best time: 3.1264
Epoch: 011, Runtime 0.032884, Loss 2118039633920000.000000, Train: 0.2187, Val: 0.1825, Test: 0.1889, Best time: 3.1264
Epoch: 012, Runtime 0.033324, Loss 2005910654287872.000000, Train: 0.2133, Val: 0.1842, Test: 0.1892, Best time: 3.1264
Epoch: 013, Runtime 0.034039, Loss 1989684804714496.000000, Train: 0.2187, Val: 0.1849, Test: 0.1926, Best time: 3.1264
Epoch: 014, Runtime 0.032748, Loss 2069169885413376.000000, Train: 0.2187, Val: 0.1872, Test: 0.1942, Best time: 3.1264
Epoch: 015, Runtime 0.042822, Loss 2257961749577728.000000, Train: 0.2160, Val: 0.1885, Test: 0.1946, Best time: 3.1264
Epoch: 016, Runtime 0.028564, Loss 1807169901035520.000000, Train: 0.2213, Val: 0.1929, Test: 0.1988, Best time: 3.1264
Epoch: 017, Runtime 0.029810, Loss 2190580692025344.000000, Train: 0.2240, Val: 0.1922, Test: 0.2007, Best time: 3.1264
Epoch: 018, Runtime 0.028795, Loss 1712590157774848.000000, Train: 0.2213, Val: 0.1911, Test: 0.1993, Best time: 3.1264
Epoch: 019, Runtime 0.029402, Loss 1892779336663040.000000, Train: 0.2240, Val: 0.1916, Test: 0.1980, Best time: 3.1264
Epoch: 020, Runtime 0.036466, Loss 1897995306008576.000000, Train: 0.2240, Val: 0.1931, Test: 0.2000, Best time: 3.1264
Epoch: 021, Runtime 0.028417, Loss 1760658760663040.000000, Train: 0.2240, Val: 0.1926, Test: 0.1988, Best time: 3.1264
Epoch: 022, Runtime 0.030526, Loss 1865498509705216.000000, Train: 0.2267, Val: 0.1916, Test: 0.1963, Best time: 3.1264
Epoch: 023, Runtime 0.027486, Loss 1743290584006656.000000, Train: 0.2293, Val: 0.1920, Test: 0.1964, Best time: 3.1264
Epoch: 024, Runtime 0.031595, Loss 1522778104659968.000000, Train: 0.2267, Val: 0.1933, Test: 0.1979, Best time: 3.1264
Epoch: 025, Runtime 0.027638, Loss 1758119629684736.000000, Train: 0.2213, Val: 0.1950, Test: 0.2024, Best time: 3.1264
Epoch: 026, Runtime 0.028703, Loss 1739050243325952.000000, Train: 0.2240, Val: 0.1972, Test: 0.2036, Best time: 3.1264
Epoch: 027, Runtime 0.033060, Loss 1831893746057216.000000, Train: 0.2240, Val: 0.1972, Test: 0.2037, Best time: 3.1264
Epoch: 028, Runtime 0.028272, Loss 1497883132035072.000000, Train: 0.2240, Val: 0.1974, Test: 0.2048, Best time: 3.1264
Epoch: 029, Runtime 0.032707, Loss 1612641571176448.000000, Train: 0.2240, Val: 0.1950, Test: 0.2009, Best time: 3.1264

 37%|██████████▋                  | 92/250 [00:04<00:04, 32.52it/s]
Epoch: 031, Runtime 0.039414, Loss 1599366095699968.000000, Train: 0.2240, Val: 0.1957, Test: 0.2005, Best time: 3.1264
Epoch: 032, Runtime 0.031376, Loss 1532808732344320.000000, Train: 0.2267, Val: 0.1972, Test: 0.2041, Best time: 3.1264
Epoch: 033, Runtime 0.028196, Loss 1567893514878976.000000, Train: 0.2267, Val: 0.2000, Test: 0.2049, Best time: 3.1264
Epoch: 034, Runtime 0.027225, Loss 1712873222963200.000000, Train: 0.2240, Val: 0.1991, Test: 0.2053, Best time: 3.1264
Epoch: 035, Runtime 0.029560, Loss 1413749151891456.000000, Train: 0.2240, Val: 0.1974, Test: 0.2022, Best time: 3.1264
Epoch: 036, Runtime 0.031482, Loss 1467347256737792.000000, Train: 0.2293, Val: 0.2000, Test: 0.2030, Best time: 3.1264
Epoch: 037, Runtime 0.033463, Loss 1167435461820416.000000, Train: 0.2240, Val: 0.2043, Test: 0.2057, Best time: 3.1264
Epoch: 038, Runtime 0.032882, Loss 1300662126116864.000000, Train: 0.2213, Val: 0.2030, Test: 0.2015, Best time: 3.1264
Epoch: 039, Runtime 0.032975, Loss 1304330162405376.000000, Train: 0.2293, Val: 0.2061, Test: 0.2057, Best time: 3.1264
Epoch: 040, Runtime 0.028983, Loss 1225689042780160.000000, Train: 0.2293, Val: 0.2035, Test: 0.2072, Best time: 3.1264
Epoch: 041, Runtime 0.028645, Loss 1392629589737472.000000, Train: 0.2267, Val: 0.2022, Test: 0.2050, Best time: 3.1264
Epoch: 042, Runtime 0.027884, Loss 1123840872677376.000000, Train: 0.2240, Val: 0.2028, Test: 0.2064, Best time: 3.1264
Epoch: 043, Runtime 0.029295, Loss 1006262116417536.000000, Train: 0.2187, Val: 0.2052, Test: 0.2099, Best time: 3.1264
Epoch: 044, Runtime 0.031229, Loss 1248649669509120.000000, Train: 0.2240, Val: 0.2119, Test: 0.2141, Best time: 3.1264
Epoch: 045, Runtime 0.046906, Loss 1144152309891072.000000, Train: 0.2187, Val: 0.2058, Test: 0.2064, Best time: 3.1264
Epoch: 046, Runtime 0.060173, Loss 1319327248678912.000000, Train: 0.2187, Val: 0.2037, Test: 0.2066, Best time: 3.1264
Epoch: 047, Runtime 0.029544, Loss 1156516849647616.000000, Train: 0.2267, Val: 0.2080, Test: 0.2131, Best time: 3.1264
Epoch: 048, Runtime 0.026954, Loss 1137629999398912.000000, Train: 0.2187, Val: 0.1972, Test: 0.2033, Best time: 3.1264
Epoch: 049, Runtime 0.027591, Loss 1095503148220416.000000, Train: 0.2080, Val: 0.1976, Test: 0.2015, Best time: 3.1264
Epoch: 050, Runtime 0.030808, Loss 946338665594880.000000, Train: 0.2160, Val: 0.1972, Test: 0.2031, Best time: 3.1264
Epoch: 051, Runtime 0.030616, Loss 1347706647740416.000000, Train: 0.2160, Val: 0.1976, Test: 0.2003, Best time: 3.1264
Epoch: 052, Runtime 0.029061, Loss 975147964039168.000000, Train: 0.2107, Val: 0.1946, Test: 0.1983, Best time: 3.1264
Epoch: 053, Runtime 0.029243, Loss 978342681509888.000000, Train: 0.2160, Val: 0.1985, Test: 0.2031, Best time: 3.1264
Epoch: 054, Runtime 0.035886, Loss 975444853653504.000000, Train: 0.2240, Val: 0.2017, Test: 0.2047, Best time: 3.1264
Epoch: 055, Runtime 0.037521, Loss 1102153502425088.000000, Train: 0.2187, Val: 0.1989, Test: 0.2023, Best time: 3.1264
Epoch: 056, Runtime 0.034431, Loss 1065731307339776.000000, Train: 0.2187, Val: 0.1987, Test: 0.2027, Best time: 3.1264
Epoch: 057, Runtime 0.029573, Loss 875915227693056.000000, Train: 0.2187, Val: 0.2013, Test: 0.2053, Best time: 3.1264
Epoch: 058, Runtime 0.031401, Loss 1117429023375360.000000, Train: 0.2213, Val: 0.1983, Test: 0.2010, Best time: 3.1264
Epoch: 059, Runtime 0.030447, Loss 1002178340716544.000000, Train: 0.2160, Val: 0.2006, Test: 0.2032, Best time: 3.1264
Epoch: 060, Runtime 0.038759, Loss 874247169769472.000000, Train: 0.2240, Val: 0.2024, Test: 0.2069, Best time: 3.1264
Epoch: 061, Runtime 0.033304, Loss 950271312134144.000000, Train: 0.2267, Val: 0.2091, Test: 0.2122, Best time: 3.1264
Epoch: 062, Runtime 0.041006, Loss 669234086543360.000000, Train: 0.2293, Val: 0.2048, Test: 0.2095, Best time: 3.1264
Epoch: 063, Runtime 0.027758, Loss 672393571860480.000000, Train: 0.2293, Val: 0.1950, Test: 0.1991, Best time: 3.1264
Epoch: 064, Runtime 0.028735, Loss 818649690537984.000000, Train: 0.2267, Val: 0.1959, Test: 0.1975, Best time: 3.1264
Epoch: 065, Runtime 0.032133, Loss 900594311102464.000000, Train: 0.2107, Val: 0.2080, Test: 0.2087, Best time: 3.1264
Epoch: 066, Runtime 0.030340, Loss 735194181009408.000000, Train: 0.2187, Val: 0.2214, Test: 0.2231, Best time: 3.1264
Epoch: 067, Runtime 0.028736, Loss 735835875966976.000000, Train: 0.2187, Val: 0.1918, Test: 0.1979, Best time: 3.1264
Epoch: 068, Runtime 0.031848, Loss 767151287828480.000000, Train: 0.2133, Val: 0.1935, Test: 0.1984, Best time: 3.1264
Epoch: 069, Runtime 0.028503, Loss 787828602568704.000000, Train: 0.2107, Val: 0.1996, Test: 0.2008, Best time: 3.1264
Epoch: 070, Runtime 0.030154, Loss 648768701595648.000000, Train: 0.2080, Val: 0.1924, Test: 0.1979, Best time: 3.1264
Epoch: 071, Runtime 0.028546, Loss 755469647872000.000000, Train: 0.2027, Val: 0.1916, Test: 0.1958, Best time: 3.1264
Epoch: 072, Runtime 0.028410, Loss 769055636062208.000000, Train: 0.2000, Val: 0.2052, Test: 0.2065, Best time: 3.1264
Epoch: 073, Runtime 0.029197, Loss 694755453304832.000000, Train: 0.1947, Val: 0.1864, Test: 0.1907, Best time: 3.1264
Epoch: 074, Runtime 0.042691, Loss 695076099457024.000000, Train: 0.1947, Val: 0.1834, Test: 0.1878, Best time: 3.1264
Epoch: 075, Runtime 0.029336, Loss 612347177598976.000000, Train: 0.2107, Val: 0.1950, Test: 0.1973, Best time: 3.1264
Epoch: 076, Runtime 0.030370, Loss 606906527776768.000000, Train: 0.1973, Val: 0.1885, Test: 0.1907, Best time: 3.1264
Epoch: 077, Runtime 0.027412, Loss 639239175798784.000000, Train: 0.1840, Val: 0.1907, Test: 0.1916, Best time: 3.1264
Epoch: 078, Runtime 0.052792, Loss 703495913078784.000000, Train: 0.1733, Val: 0.1756, Test: 0.1799, Best time: 3.1264
Epoch: 079, Runtime 0.029002, Loss 659122794004480.000000, Train: 0.1733, Val: 0.1790, Test: 0.1802, Best time: 3.1264
Epoch: 080, Runtime 0.029406, Loss 605854193680384.000000, Train: 0.1867, Val: 0.1734, Test: 0.1736, Best time: 3.1264
Epoch: 081, Runtime 0.029124, Loss 530858092003328.000000, Train: 0.1760, Val: 0.1764, Test: 0.1774, Best time: 3.1264
Epoch: 082, Runtime 0.028148, Loss 709282978856960.000000, Train: 0.1627, Val: 0.1805, Test: 0.1781, Best time: 3.1264
Epoch: 083, Runtime 0.028728, Loss 634869717663744.000000, Train: 0.1653, Val: 0.1777, Test: 0.1778, Best time: 3.1264
Epoch: 084, Runtime 0.028529, Loss 519147058364416.000000, Train: 0.1573, Val: 0.1730, Test: 0.1748, Best time: 3.1264
Epoch: 085, Runtime 0.027973, Loss 533095568637952.000000, Train: 0.1813, Val: 0.1674, Test: 0.1679, Best time: 3.1264
Epoch: 086, Runtime 0.029453, Loss 514975604932608.000000, Train: 0.1707, Val: 0.1881, Test: 0.1880, Best time: 3.1264
Epoch: 087, Runtime 0.028676, Loss 576641369636864.000000, Train: 0.1707, Val: 0.1741, Test: 0.1766, Best time: 3.1264
Epoch: 088, Runtime 0.028288, Loss 429838783479808.000000, Train: 0.1547, Val: 0.1734, Test: 0.1725, Best time: 3.1264
Epoch: 089, Runtime 0.027704, Loss 457004317409280.000000, Train: 0.1627, Val: 0.1622, Test: 0.1619, Best time: 3.1264
Epoch: 090, Runtime 0.030966, Loss 546609783898112.000000, Train: 0.1627, Val: 0.1695, Test: 0.1703, Best time: 3.1264
Epoch: 091, Runtime 0.028521, Loss 447912207187968.000000, Train: 0.1520, Val: 0.1641, Test: 0.1609, Best time: 3.1264
Epoch: 092, Runtime 0.028235, Loss 501706605461504.000000, Train: 0.1573, Val: 0.1738, Test: 0.1770, Best time: 3.1264

 62%|█████████████████▎          | 155/250 [00:06<00:02, 31.98it/s]
Epoch: 094, Runtime 0.036756, Loss 536932450828288.000000, Train: 0.1467, Val: 0.1343, Test: 0.1335, Best time: 3.1264
Epoch: 095, Runtime 0.027581, Loss 482890152411136.000000, Train: 0.1280, Val: 0.1382, Test: 0.1347, Best time: 3.1264
Epoch: 096, Runtime 0.037577, Loss 464349952999424.000000, Train: 0.1280, Val: 0.1648, Test: 0.1616, Best time: 3.1264
Epoch: 097, Runtime 0.032174, Loss 501108363493376.000000, Train: 0.1173, Val: 0.1194, Test: 0.1159, Best time: 3.1264
Epoch: 098, Runtime 0.028017, Loss 471033727418368.000000, Train: 0.1120, Val: 0.1598, Test: 0.1604, Best time: 3.1264
Epoch: 099, Runtime 0.029768, Loss 480974529888256.000000, Train: 0.1253, Val: 0.1289, Test: 0.1360, Best time: 3.1264
Epoch: 100, Runtime 0.033040, Loss 411946822139904.000000, Train: 0.1120, Val: 0.1531, Test: 0.1539, Best time: 3.1264
Epoch: 101, Runtime 0.029477, Loss 412588953305088.000000, Train: 0.1173, Val: 0.1237, Test: 0.1165, Best time: 3.1264
Epoch: 102, Runtime 0.035661, Loss 368931080503296.000000, Train: 0.1387, Val: 0.1788, Test: 0.1780, Best time: 3.1264
Epoch: 103, Runtime 0.032289, Loss 407183200092160.000000, Train: 0.1147, Val: 0.1699, Test: 0.1712, Best time: 3.1264
Epoch: 104, Runtime 0.028789, Loss 398973873422336.000000, Train: 0.1307, Val: 0.1470, Test: 0.1469, Best time: 3.1264
Epoch: 105, Runtime 0.029572, Loss 307080934195200.000000, Train: 0.1360, Val: 0.1710, Test: 0.1705, Best time: 3.1264
Epoch: 106, Runtime 0.026340, Loss 377961819668480.000000, Train: 0.1227, Val: 0.1516, Test: 0.1438, Best time: 3.1264
Epoch: 107, Runtime 0.069449, Loss 387365013028864.000000, Train: 0.1387, Val: 0.1537, Test: 0.1524, Best time: 3.1264
Epoch: 108, Runtime 0.027822, Loss 322758537904128.000000, Train: 0.1200, Val: 0.1336, Test: 0.1276, Best time: 3.1264
Epoch: 109, Runtime 0.038524, Loss 369686189441024.000000, Train: 0.1360, Val: 0.1185, Test: 0.1220, Best time: 3.1264
Epoch: 110, Runtime 0.034441, Loss 350149960269824.000000, Train: 0.1067, Val: 0.1016, Test: 0.1011, Best time: 3.1264
Epoch: 111, Runtime 0.025850, Loss 365557182365696.000000, Train: 0.1360, Val: 0.1702, Test: 0.1679, Best time: 3.1264
Epoch: 112, Runtime 0.026415, Loss 301702561398784.000000, Train: 0.1413, Val: 0.1116, Test: 0.1130, Best time: 3.1264
Epoch: 113, Runtime 0.024688, Loss 306321463181312.000000, Train: 0.1280, Val: 0.1821, Test: 0.1785, Best time: 3.1264
Epoch: 114, Runtime 0.030548, Loss 316910134624256.000000, Train: 0.1387, Val: 0.0832, Test: 0.0854, Best time: 3.1264
Epoch: 115, Runtime 0.029624, Loss 318670232354816.000000, Train: 0.1360, Val: 0.1624, Test: 0.1650, Best time: 3.1264
Epoch: 116, Runtime 0.026611, Loss 292059923611648.000000, Train: 0.1440, Val: 0.1539, Test: 0.1535, Best time: 3.1264
Epoch: 117, Runtime 0.028068, Loss 336432975577088.000000, Train: 0.1467, Val: 0.1777, Test: 0.1765, Best time: 3.1264
Epoch: 118, Runtime 0.028204, Loss 311618030272512.000000, Train: 0.1227, Val: 0.1211, Test: 0.1190, Best time: 3.1264
Epoch: 119, Runtime 0.030759, Loss 348561459904512.000000, Train: 0.0987, Val: 0.0954, Test: 0.0905, Best time: 3.1264
Epoch: 120, Runtime 0.030622, Loss 286545990909952.000000, Train: 0.1173, Val: 0.1721, Test: 0.1665, Best time: 3.1264
Epoch: 121, Runtime 0.028553, Loss 290517996797952.000000, Train: 0.1093, Val: 0.1343, Test: 0.1409, Best time: 3.1264
Epoch: 122, Runtime 0.031383, Loss 255044821712896.000000, Train: 0.1200, Val: 0.1479, Test: 0.1391, Best time: 3.1264
Epoch: 123, Runtime 0.027260, Loss 240638696095744.000000, Train: 0.1387, Val: 0.0932, Test: 0.1028, Best time: 3.1264
Epoch: 124, Runtime 0.029592, Loss 240676411277312.000000, Train: 0.1120, Val: 0.1183, Test: 0.1157, Best time: 3.1264
Epoch: 125, Runtime 0.045033, Loss 223353113673728.000000, Train: 0.1413, Val: 0.1459, Test: 0.1451, Best time: 3.1264
Epoch: 126, Runtime 0.032494, Loss 299873911963648.000000, Train: 0.1200, Val: 0.1256, Test: 0.1199, Best time: 3.1264
Epoch: 127, Runtime 0.027772, Loss 254339071344640.000000, Train: 0.1680, Val: 0.1317, Test: 0.1288, Best time: 3.1264
Epoch: 128, Runtime 0.026602, Loss 291458460418048.000000, Train: 0.1173, Val: 0.1416, Test: 0.1422, Best time: 3.1264
Epoch: 129, Runtime 0.030047, Loss 191107203858432.000000, Train: 0.1387, Val: 0.1155, Test: 0.1130, Best time: 3.1264
Epoch: 130, Runtime 0.031030, Loss 190151858847744.000000, Train: 0.1173, Val: 0.0960, Test: 0.0932, Best time: 3.1264
Epoch: 131, Runtime 0.026658, Loss 256840671690752.000000, Train: 0.1093, Val: 0.1546, Test: 0.1540, Best time: 3.1264
Epoch: 132, Runtime 0.031480, Loss 205610570219520.000000, Train: 0.1200, Val: 0.0928, Test: 0.0938, Best time: 3.1264
Epoch: 133, Runtime 0.031503, Loss 201820060254208.000000, Train: 0.1333, Val: 0.1479, Test: 0.1540, Best time: 3.1264
Epoch: 134, Runtime 0.029627, Loss 210539414290432.000000, Train: 0.1120, Val: 0.1094, Test: 0.1072, Best time: 3.1264
Epoch: 135, Runtime 0.029616, Loss 194369231519744.000000, Train: 0.1013, Val: 0.0956, Test: 0.1033, Best time: 3.1264
Epoch: 136, Runtime 0.030313, Loss 220691240583168.000000, Train: 0.0933, Val: 0.0692, Test: 0.0702, Best time: 3.1264
Epoch: 137, Runtime 0.028394, Loss 228542843453440.000000, Train: 0.1520, Val: 0.1539, Test: 0.1530, Best time: 3.1264
Epoch: 138, Runtime 0.029197, Loss 239338730291200.000000, Train: 0.1227, Val: 0.1096, Test: 0.1124, Best time: 3.1264
Epoch: 139, Runtime 0.029105, Loss 214504088535040.000000, Train: 0.1147, Val: 0.1392, Test: 0.1454, Best time: 3.1264
Epoch: 140, Runtime 0.028417, Loss 190646384066560.000000, Train: 0.1093, Val: 0.1185, Test: 0.1154, Best time: 3.1264
Epoch: 141, Runtime 0.029093, Loss 174769181818880.000000, Train: 0.1173, Val: 0.0670, Test: 0.0716, Best time: 3.1264
Epoch: 142, Runtime 0.041796, Loss 203982777614336.000000, Train: 0.1013, Val: 0.1120, Test: 0.1134, Best time: 3.1264
Epoch: 143, Runtime 0.031267, Loss 222565071060992.000000, Train: 0.1387, Val: 0.1206, Test: 0.1201, Best time: 3.1264
Epoch: 144, Runtime 0.029169, Loss 207743323471872.000000, Train: 0.1147, Val: 0.1390, Test: 0.1394, Best time: 3.1264
Epoch: 145, Runtime 0.032724, Loss 203801449463808.000000, Train: 0.1173, Val: 0.1072, Test: 0.1083, Best time: 3.1264
Epoch: 146, Runtime 0.030898, Loss 173150549573632.000000, Train: 0.1093, Val: 0.0744, Test: 0.0762, Best time: 3.1264
Epoch: 147, Runtime 0.028474, Loss 174942691786752.000000, Train: 0.1147, Val: 0.1414, Test: 0.1365, Best time: 3.1264
Epoch: 148, Runtime 0.029396, Loss 201013881470976.000000, Train: 0.1067, Val: 0.0973, Test: 0.0970, Best time: 3.1264
Epoch: 149, Runtime 0.030268, Loss 143809044283392.000000, Train: 0.1280, Val: 0.1237, Test: 0.1228, Best time: 3.1264
Epoch: 150, Runtime 0.033617, Loss 183004060188672.000000, Train: 0.0960, Val: 0.0921, Test: 0.0893, Best time: 3.1264
Epoch: 151, Runtime 0.029974, Loss 168582918963200.000000, Train: 0.1307, Val: 0.1325, Test: 0.1448, Best time: 3.1264
Epoch: 152, Runtime 0.031333, Loss 151400281538560.000000, Train: 0.1173, Val: 0.0986, Test: 0.0946, Best time: 3.1264
Epoch: 153, Runtime 0.028371, Loss 150662604128256.000000, Train: 0.1520, Val: 0.1976, Test: 0.1931, Best time: 3.1264
Epoch: 154, Runtime 0.029297, Loss 132495731326976.000000, Train: 0.0933, Val: 0.1075, Test: 0.1199, Best time: 3.1264
Epoch: 155, Runtime 0.030813, Loss 143549416865792.000000, Train: 0.1253, Val: 0.1373, Test: 0.1339, Best time: 3.1264
Epoch: 156, Runtime 0.028394, Loss 169621663514624.000000, Train: 0.1120, Val: 0.1479, Test: 0.1458, Best time: 3.1264

 88%|████████████████████████▌   | 219/250 [00:08<00:00, 32.48it/s]
Epoch: 158, Runtime 0.041393, Loss 141799955890176.000000, Train: 0.1200, Val: 0.1425, Test: 0.1409, Best time: 3.1264
Epoch: 159, Runtime 0.030857, Loss 136533713616896.000000, Train: 0.0880, Val: 0.0636, Test: 0.0669, Best time: 3.1264
Epoch: 160, Runtime 0.030774, Loss 144645489164288.000000, Train: 0.1520, Val: 0.1680, Test: 0.1652, Best time: 3.1264
Epoch: 161, Runtime 0.027125, Loss 147920905043968.000000, Train: 0.1387, Val: 0.1386, Test: 0.1421, Best time: 3.1264
Epoch: 162, Runtime 0.028282, Loss 138145232322560.000000, Train: 0.0933, Val: 0.0508, Test: 0.0591, Best time: 3.1264
Epoch: 163, Runtime 0.026321, Loss 135043510960128.000000, Train: 0.1067, Val: 0.1479, Test: 0.1439, Best time: 3.1264
Epoch: 164, Runtime 0.031178, Loss 142089664856064.000000, Train: 0.1067, Val: 0.1135, Test: 0.1127, Best time: 3.1264
Epoch: 165, Runtime 0.027318, Loss 115692644859904.000000, Train: 0.0960, Val: 0.0863, Test: 0.0917, Best time: 3.1264
Epoch: 166, Runtime 0.027961, Loss 113428291125248.000000, Train: 0.1307, Val: 0.1429, Test: 0.1439, Best time: 3.1264
Epoch: 167, Runtime 0.028644, Loss 133461427879936.000000, Train: 0.1040, Val: 0.0458, Test: 0.0507, Best time: 3.1264
Epoch: 168, Runtime 0.028839, Loss 134117366693888.000000, Train: 0.1227, Val: 0.1896, Test: 0.1767, Best time: 3.1264
Epoch: 169, Runtime 0.028869, Loss 114980795973632.000000, Train: 0.0987, Val: 0.0316, Test: 0.0389, Best time: 3.1264
Epoch: 170, Runtime 0.029987, Loss 110486288859136.000000, Train: 0.0827, Val: 0.1286, Test: 0.1236, Best time: 3.1264
Epoch: 171, Runtime 0.026558, Loss 92362105683968.000000, Train: 0.1067, Val: 0.0960, Test: 0.0908, Best time: 3.1264
Epoch: 172, Runtime 0.058849, Loss 110762576052224.000000, Train: 0.1013, Val: 0.1081, Test: 0.1138, Best time: 3.1264
Epoch: 173, Runtime 0.026394, Loss 97196233981952.000000, Train: 0.1093, Val: 0.1289, Test: 0.1254, Best time: 3.1264
Epoch: 174, Runtime 0.036235, Loss 110747677884416.000000, Train: 0.1067, Val: 0.0690, Test: 0.0693, Best time: 3.1264
Epoch: 175, Runtime 0.028104, Loss 107648842203136.000000, Train: 0.0907, Val: 0.1204, Test: 0.1238, Best time: 3.1264
Epoch: 176, Runtime 0.026499, Loss 114304657391616.000000, Train: 0.1120, Val: 0.1083, Test: 0.1102, Best time: 3.1264
Epoch: 177, Runtime 0.027742, Loss 113755841101824.000000, Train: 0.0853, Val: 0.0826, Test: 0.0832, Best time: 3.1264
Epoch: 178, Runtime 0.028823, Loss 99925962522624.000000, Train: 0.1093, Val: 0.0445, Test: 0.0456, Best time: 3.1264
Epoch: 179, Runtime 0.028155, Loss 98395150614528.000000, Train: 0.0880, Val: 0.1548, Test: 0.1402, Best time: 3.1264
Epoch: 180, Runtime 0.027725, Loss 97603861610496.000000, Train: 0.0960, Val: 0.1003, Test: 0.1000, Best time: 3.1264
Epoch: 181, Runtime 0.029081, Loss 100703838142464.000000, Train: 0.0773, Val: 0.0798, Test: 0.0848, Best time: 3.1264
Epoch: 182, Runtime 0.030360, Loss 101035901190144.000000, Train: 0.0720, Val: 0.0861, Test: 0.0851, Best time: 3.1264
Epoch: 183, Runtime 0.029368, Loss 93390616133632.000000, Train: 0.0800, Val: 0.1003, Test: 0.0959, Best time: 3.1264
Epoch: 184, Runtime 0.027804, Loss 94615881383936.000000, Train: 0.0907, Val: 0.1068, Test: 0.1016, Best time: 3.1264
Epoch: 185, Runtime 0.026946, Loss 81870750482432.000000, Train: 0.1360, Val: 0.1159, Test: 0.1208, Best time: 3.1264
Epoch: 186, Runtime 0.031885, Loss 76113632034816.000000, Train: 0.0720, Val: 0.0629, Test: 0.0686, Best time: 3.1264
Epoch: 187, Runtime 0.028830, Loss 56608390381568.000000, Train: 0.0933, Val: 0.0279, Test: 0.0314, Best time: 3.1264
Epoch: 188, Runtime 0.029240, Loss 85759834980352.000000, Train: 0.0773, Val: 0.1345, Test: 0.1186, Best time: 3.1264
Epoch: 189, Runtime 0.032412, Loss 83054232076288.000000, Train: 0.0907, Val: 0.0748, Test: 0.0719, Best time: 3.1264
Epoch: 190, Runtime 0.028767, Loss 80686178369536.000000, Train: 0.0987, Val: 0.1170, Test: 0.1226, Best time: 3.1264
Epoch: 191, Runtime 0.037211, Loss 67735002284032.000000, Train: 0.0960, Val: 0.0934, Test: 0.0890, Best time: 3.1264
Epoch: 192, Runtime 0.030448, Loss 77253719359488.000000, Train: 0.0907, Val: 0.1269, Test: 0.1192, Best time: 3.1264
Epoch: 193, Runtime 0.028772, Loss 73857725628416.000000, Train: 0.0960, Val: 0.0246, Test: 0.0275, Best time: 3.1264
Epoch: 194, Runtime 0.028216, Loss 69087522717696.000000, Train: 0.1040, Val: 0.1198, Test: 0.1125, Best time: 3.1264
Epoch: 195, Runtime 0.028450, Loss 79823410036736.000000, Train: 0.1200, Val: 0.1539, Test: 0.1484, Best time: 3.1264
Epoch: 196, Runtime 0.028234, Loss 76280347230208.000000, Train: 0.1040, Val: 0.1388, Test: 0.1351, Best time: 3.1264
Epoch: 197, Runtime 0.032137, Loss 68607983747072.000000, Train: 0.1093, Val: 0.0638, Test: 0.0704, Best time: 3.1264
Epoch: 198, Runtime 0.031784, Loss 68127433949184.000000, Train: 0.0987, Val: 0.1429, Test: 0.1382, Best time: 3.1264
Epoch: 199, Runtime 0.029906, Loss 81494303309824.000000, Train: 0.0907, Val: 0.0746, Test: 0.0740, Best time: 3.1264
Epoch: 200, Runtime 0.030266, Loss 82205976035328.000000, Train: 0.0693, Val: 0.0954, Test: 0.0937, Best time: 3.1264
Epoch: 201, Runtime 0.029208, Loss 56607069175808.000000, Train: 0.0533, Val: 0.0316, Test: 0.0338, Best time: 3.1264
Epoch: 202, Runtime 0.027298, Loss 54481123278848.000000, Train: 0.1067, Val: 0.0928, Test: 0.0955, Best time: 3.1264
Epoch: 203, Runtime 0.028200, Loss 65321419407360.000000, Train: 0.1013, Val: 0.1066, Test: 0.1049, Best time: 3.1264
Epoch: 204, Runtime 0.028425, Loss 61293671219200.000000, Train: 0.0987, Val: 0.1587, Test: 0.1506, Best time: 3.1264
Epoch: 205, Runtime 0.035314, Loss 54750171103232.000000, Train: 0.1013, Val: 0.0352, Test: 0.0405, Best time: 3.1264
Epoch: 206, Runtime 0.032345, Loss 43154636013568.000000, Train: 0.1147, Val: 0.1165, Test: 0.1175, Best time: 3.1264
Epoch: 207, Runtime 0.027605, Loss 51669618393088.000000, Train: 0.0693, Val: 0.0411, Test: 0.0425, Best time: 3.1264
Epoch: 208, Runtime 0.044757, Loss 50052592566272.000000, Train: 0.1093, Val: 0.1215, Test: 0.1280, Best time: 3.1264
Epoch: 209, Runtime 0.029721, Loss 45164148031488.000000, Train: 0.0773, Val: 0.1068, Test: 0.1040, Best time: 3.1264
Epoch: 210, Runtime 0.030346, Loss 56075457921024.000000, Train: 0.0907, Val: 0.0316, Test: 0.0317, Best time: 3.1264
Epoch: 211, Runtime 0.027653, Loss 46750425415680.000000, Train: 0.0480, Val: 0.0947, Test: 0.0865, Best time: 3.1264
Epoch: 212, Runtime 0.031771, Loss 55937872166912.000000, Train: 0.0773, Val: 0.0982, Test: 0.1017, Best time: 3.1264
Epoch: 213, Runtime 0.028622, Loss 67801888849920.000000, Train: 0.0720, Val: 0.0865, Test: 0.0863, Best time: 3.1264
Epoch: 214, Runtime 0.028782, Loss 49044973944832.000000, Train: 0.0960, Val: 0.0599, Test: 0.0593, Best time: 3.1264
Epoch: 215, Runtime 0.029465, Loss 51344895377408.000000, Train: 0.0720, Val: 0.1135, Test: 0.1082, Best time: 3.1264
Epoch: 216, Runtime 0.028279, Loss 39009279541248.000000, Train: 0.0773, Val: 0.1031, Test: 0.0933, Best time: 3.1264
Epoch: 217, Runtime 0.028529, Loss 60059413381120.000000, Train: 0.1040, Val: 0.1008, Test: 0.1022, Best time: 3.1264
Epoch: 218, Runtime 0.029693, Loss 53423529525248.000000, Train: 0.1040, Val: 0.1111, Test: 0.1085, Best time: 3.1264
Epoch: 219, Runtime 0.030056, Loss 50180544004096.000000, Train: 0.0880, Val: 0.0670, Test: 0.0728, Best time: 3.1264
Epoch: 220, Runtime 0.028209, Loss 35021440155648.000000, Train: 0.0933, Val: 0.0884, Test: 0.0831, Best time: 3.1264
Epoch: 221, Runtime 0.031084, Loss 37123830841344.000000, Train: 0.0960, Val: 0.0718, Test: 0.0728, Best time: 3.1264
Epoch: 222, Runtime 0.028150, Loss 51486755127296.000000, Train: 0.1360, Val: 0.0791, Test: 0.0725, Best time: 3.1264
Epoch: 223, Runtime 0.027827, Loss 37315619586048.000000, Train: 0.0987, Val: 0.1172, Test: 0.1112, Best time: 3.1264
Epoch: 224, Runtime 0.042180, Loss 38975054020608.000000, Train: 0.1013, Val: 0.1023, Test: 0.1089, Best time: 3.1264
Epoch: 225, Runtime 0.032064, Loss 48747656511488.000000, Train: 0.1093, Val: 0.0971, Test: 0.0938, Best time: 3.1264
Epoch: 226, Runtime 0.030076, Loss 30998377005056.000000, Train: 0.0853, Val: 0.1092, Test: 0.1022, Best time: 3.1264
Epoch: 227, Runtime 0.027351, Loss 43095689265152.000000, Train: 0.0800, Val: 0.0478, Test: 0.0535, Best time: 3.1264
Epoch: 228, Runtime 0.027592, Loss 32600869568512.000000, Train: 0.0853, Val: 0.0986, Test: 0.0979, Best time: 3.1264
Epoch: 229, Runtime 0.033603, Loss 40057750683648.000000, Train: 0.0933, Val: 0.0651, Test: 0.0649, Best time: 3.1264
Epoch: 230, Runtime 0.037066, Loss 41895615004672.000000, Train: 0.0613, Val: 0.0984, Test: 0.0914, Best time: 3.1264
Epoch: 231, Runtime 0.029805, Loss 38033621516288.000000, Train: 0.0880, Val: 0.0880, Test: 0.0874, Best time: 3.1264
Epoch: 232, Runtime 0.027980, Loss 36128786743296.000000, Train: 0.1040, Val: 0.1219, Test: 0.1217, Best time: 3.1264
Epoch: 233, Runtime 0.030261, Loss 46761796173824.000000, Train: 0.0933, Val: 0.0575, Test: 0.0618, Best time: 3.1264
Epoch: 234, Runtime 0.031411, Loss 37598084988928.000000, Train: 0.0773, Val: 0.1142, Test: 0.1103, Best time: 3.1264
Epoch: 235, Runtime 0.033369, Loss 28942595522560.000000, Train: 0.0800, Val: 0.0257, Test: 0.0251, Best time: 3.1264
Epoch: 236, Runtime 0.028888, Loss 31933832626176.000000, Train: 0.0853, Val: 0.1635, Test: 0.1664, Best time: 3.1264
Epoch: 237, Runtime 0.056450, Loss 39878729400320.000000, Train: 0.0747, Val: 0.0467, Test: 0.0472, Best time: 3.1264
Epoch: 238, Runtime 0.032202, Loss 36064848773120.000000, Train: 0.0987, Val: 0.0796, Test: 0.0843, Best time: 3.1264
Epoch: 239, Runtime 0.027796, Loss 27648929562624.000000, Train: 0.1413, Val: 0.1062, Test: 0.1015, Best time: 3.1264
Epoch: 240, Runtime 0.036152, Loss 30437843927040.000000, Train: 0.0693, Val: 0.0886, Test: 0.0854, Best time: 3.1264
Epoch: 241, Runtime 0.030950, Loss 24291760406528.000000, Train: 0.0907, Val: 0.1256, Test: 0.1268, Best time: 3.1264
Epoch: 242, Runtime 0.031548, Loss 26768008282112.000000, Train: 0.0827, Val: 0.0990, Test: 0.0923, Best time: 3.1264
Epoch: 243, Runtime 0.028983, Loss 29904953409536.000000, Train: 0.0827, Val: 0.0878, Test: 0.0859, Best time: 3.1264
Epoch: 244, Runtime 0.028868, Loss 36276011008000.000000, Train: 0.0960, Val: 0.0824, Test: 0.0828, Best time: 3.1264
Epoch: 245, Runtime 0.035695, Loss 24852553531392.000000, Train: 0.0907, Val: 0.1070, Test: 0.0991, Best time: 3.1264
Epoch: 246, Runtime 0.030378, Loss 35962281263104.000000, Train: 0.0827, Val: 0.0692, Test: 0.0661, Best time: 3.1264
Epoch: 247, Runtime 0.028579, Loss 27508726562816.000000, Train: 0.0800, Val: 0.1230, Test: 0.1225, Best time: 3.1264
Epoch: 248, Runtime 0.027740, Loss 28361323708416.000000, Train: 0.0507, Val: 0.0590, Test: 0.0642, Best time: 3.1264
Epoch: 249, Runtime 0.030540, Loss 27034868776960.000000, Train: 0.0693, Val: 0.0757, Test: 0.0725, Best time: 3.1264
Epoch: 250, Runtime 0.028971, Loss 30440947712000.000000, Train: 0.0827, Val: 0.0605, Test: 0.0639, Best time: 3.1264

100%|████████████████████████████| 250/250 [00:09<00:00, 26.59it/s]