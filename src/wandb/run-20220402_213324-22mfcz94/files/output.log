GrandExtendDiscritizedNet
m1.weight
torch.Size([80, 3703])
m1.bias
torch.Size([80])
m2.weight
torch.Size([6, 80])
m2.bias
torch.Size([6])
mol_list.0.alpha_train
torch.Size([])
mol_list.0.beta_train
torch.Size([])
mol_list.0.alpha_sc
torch.Size([1])
mol_list.0.beta_sc
torch.Size([1])
mol_list.0.multihead_att_layer.Q.weight
torch.Size([32, 80])
mol_list.0.multihead_att_layer.Q.bias
torch.Size([32])
mol_list.0.multihead_att_layer.V.weight
torch.Size([32, 80])
mol_list.0.multihead_att_layer.V.bias
torch.Size([32])
mol_list.0.multihead_att_layer.K.weight
torch.Size([32, 80])
mol_list.0.multihead_att_layer.K.bias
torch.Size([32])
mol_list.0.multihead_att_layer.Wout.weight
torch.Size([80, 4])
mol_list.0.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.1.alpha_train
torch.Size([])
mol_list.1.beta_train
torch.Size([])
mol_list.1.alpha_sc
torch.Size([1])
mol_list.1.beta_sc
torch.Size([1])
mol_list.1.multihead_att_layer.Q.weight
torch.Size([32, 80])
mol_list.1.multihead_att_layer.Q.bias
torch.Size([32])
mol_list.1.multihead_att_layer.V.weight
torch.Size([32, 80])
mol_list.1.multihead_att_layer.V.bias
torch.Size([32])
mol_list.1.multihead_att_layer.K.weight
torch.Size([32, 80])
mol_list.1.multihead_att_layer.K.bias
torch.Size([32])
mol_list.1.multihead_att_layer.Wout.weight
torch.Size([80, 4])
mol_list.1.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.2.alpha_train
torch.Size([])
mol_list.2.beta_train
torch.Size([])
mol_list.2.alpha_sc
torch.Size([1])
mol_list.2.beta_sc
torch.Size([1])
mol_list.2.multihead_att_layer.Q.weight
torch.Size([32, 80])
mol_list.2.multihead_att_layer.Q.bias
torch.Size([32])
mol_list.2.multihead_att_layer.V.weight
torch.Size([32, 80])
mol_list.2.multihead_att_layer.V.bias
torch.Size([32])
mol_list.2.multihead_att_layer.K.weight
torch.Size([32, 80])
mol_list.2.multihead_att_layer.K.bias
torch.Size([32])
mol_list.2.multihead_att_layer.Wout.weight
torch.Size([80, 4])
mol_list.2.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.3.alpha_train
torch.Size([])
mol_list.3.beta_train
torch.Size([])
mol_list.3.alpha_sc
torch.Size([1])
mol_list.3.beta_sc
torch.Size([1])
mol_list.3.multihead_att_layer.Q.weight
torch.Size([32, 80])
mol_list.3.multihead_att_layer.Q.bias
torch.Size([32])
mol_list.3.multihead_att_layer.V.weight
torch.Size([32, 80])
mol_list.3.multihead_att_layer.V.bias
torch.Size([32])
mol_list.3.multihead_att_layer.K.weight
torch.Size([32, 80])
mol_list.3.multihead_att_layer.K.bias
torch.Size([32])
mol_list.3.multihead_att_layer.Wout.weight
torch.Size([80, 4])
mol_list.3.multihead_att_layer.Wout.bias
torch.Size([80])
Epoch: 001, Runtime 0.997162, Loss 1.795671, Train: 0.5733, Val: 0.4281, Test: 0.4833, Best time: 7.8741
Epoch: 002, Runtime 0.026598, Loss 1.759251, Train: 0.7867, Val: 0.6432, Test: 0.6917, Best time: 7.8741
Epoch: 003, Runtime 0.027399, Loss 1.733776, Train: 0.8400, Val: 0.6632, Test: 0.7167, Best time: 7.8741
Epoch: 004, Runtime 0.026721, Loss 1.702655, Train: 0.8200, Val: 0.6308, Test: 0.6667, Best time: 7.8741
Epoch: 005, Runtime 0.027377, Loss 1.688143, Train: 0.8200, Val: 0.6368, Test: 0.6500, Best time: 7.8741
Epoch: 006, Runtime 0.028686, Loss 1.663629, Train: 0.8133, Val: 0.6486, Test: 0.6833, Best time: 7.8741
Epoch: 007, Runtime 0.028160, Loss 1.632312, Train: 0.7933, Val: 0.6400, Test: 0.7000, Best time: 7.8741
Epoch: 008, Runtime 0.025086, Loss 1.599710, Train: 0.5600, Val: 0.4903, Test: 0.5583, Best time: 7.8741
Epoch: 009, Runtime 0.029915, Loss 9181.206055, Train: 0.8733, Val: 0.6173, Test: 0.6167, Best time: 7.8741
Epoch: 010, Runtime 0.025263, Loss 1.691878, Train: 0.3800, Val: 0.3168, Test: 0.3583, Best time: 7.8741
Epoch: 011, Runtime 0.020997, Loss 21234790170624.000000, Train: 0.3933, Val: 0.3205, Test: 0.3833, Best time: 7.8741
Epoch: 012, Runtime 0.021063, Loss 139104989741056.000000, Train: 0.3867, Val: 0.3232, Test: 0.3583, Best time: 7.8741
Epoch: 013, Runtime 0.023767, Loss 16164803575808.000000, Train: 0.3733, Val: 0.3173, Test: 0.3750, Best time: 7.8741
Epoch: 014, Runtime 0.028420, Loss 24105606709248.000000, Train: 0.3667, Val: 0.3162, Test: 0.3583, Best time: 7.8741
Epoch: 015, Runtime 0.026293, Loss 25260873220096.000000, Train: 0.3800, Val: 0.3005, Test: 0.3167, Best time: 7.8741
Epoch: 016, Runtime 0.024617, Loss 126003586269184.000000, Train: 0.3467, Val: 0.2849, Test: 0.3167, Best time: 7.8741
Epoch: 017, Runtime 0.025811, Loss 3606745186304.000000, Train: 0.3333, Val: 0.2719, Test: 0.3167, Best time: 7.8741
Epoch: 018, Runtime 0.028569, Loss 10027493490688.000000, Train: 0.3333, Val: 0.2546, Test: 0.3333, Best time: 7.8741
Epoch: 019, Runtime 0.026286, Loss 22478487289856.000000, Train: 0.3400, Val: 0.2508, Test: 0.3333, Best time: 7.8741
Epoch: 020, Runtime 0.024709, Loss 19108519215104.000000, Train: 0.3333, Val: 0.2227, Test: 0.3167, Best time: 7.8741
Epoch: 021, Runtime 0.027934, Loss 11546614824960.000000, Train: 0.3267, Val: 0.2200, Test: 0.2583, Best time: 7.8741
Epoch: 022, Runtime 0.026633, Loss 13196892045312.000000, Train: 0.3333, Val: 0.2043, Test: 0.2500, Best time: 7.8741
Epoch: 023, Runtime 0.025616, Loss 11189802237952.000000, Train: 0.3067, Val: 0.1849, Test: 0.2333, Best time: 7.8741
Epoch: 024, Runtime 0.026238, Loss 16679090257920.000000, Train: 0.2867, Val: 0.1816, Test: 0.1917, Best time: 7.8741
Epoch: 025, Runtime 0.027555, Loss 5928091385856.000000, Train: 0.2667, Val: 0.1838, Test: 0.1750, Best time: 7.8741
Epoch: 026, Runtime 0.029526, Loss 5635472621568.000000, Train: 0.2467, Val: 0.1838, Test: 0.1667, Best time: 7.8741
Epoch: 027, Runtime 0.027807, Loss 8840273723392.000000, Train: 0.2267, Val: 0.1751, Test: 0.1833, Best time: 7.8741
 10%|███                          | 26/250 [00:01<00:08, 27.58it/s]
Epoch: 028, Runtime 0.050263, Loss 14072408965120.000000, Train: 0.2200, Val: 0.1703, Test: 0.2167, Best time: 7.8741
Epoch: 029, Runtime 0.023002, Loss 19120475078656.000000, Train: 0.2000, Val: 0.1665, Test: 0.2083, Best time: 7.8741
Epoch: 030, Runtime 0.022371, Loss 8669315465216.000000, Train: 0.2067, Val: 0.1670, Test: 0.1917, Best time: 7.8741
Epoch: 031, Runtime 0.021216, Loss 3554850635776.000000, Train: 0.1933, Val: 0.1735, Test: 0.2250, Best time: 7.8741
Epoch: 032, Runtime 0.023324, Loss 106317838548992.000000, Train: 0.2000, Val: 0.1746, Test: 0.2083, Best time: 7.8741
Epoch: 033, Runtime 0.023649, Loss 3373205553152.000000, Train: 0.2200, Val: 0.1724, Test: 0.2167, Best time: 7.8741
Epoch: 034, Runtime 0.024134, Loss 11011855745024.000000, Train: 0.2200, Val: 0.1622, Test: 0.1833, Best time: 7.8741
Epoch: 035, Runtime 0.025271, Loss 6987220779008.000000, Train: 0.2067, Val: 0.1605, Test: 0.2000, Best time: 7.8741
Epoch: 036, Runtime 0.028513, Loss 2620490514432.000000, Train: 0.2267, Val: 0.1638, Test: 0.1833, Best time: 7.8741
Epoch: 037, Runtime 0.025692, Loss 6506974543872.000000, Train: 0.2200, Val: 0.1692, Test: 0.2000, Best time: 7.8741
Epoch: 038, Runtime 0.024977, Loss 9629646979072.000000, Train: 0.2133, Val: 0.1686, Test: 0.1750, Best time: 7.8741
Epoch: 039, Runtime 0.026069, Loss 65395142688768.000000, Train: 0.2400, Val: 0.1697, Test: 0.2000, Best time: 7.8741
Epoch: 040, Runtime 0.024023, Loss 46942608424960.000000, Train: 0.2000, Val: 0.1735, Test: 0.1583, Best time: 7.8741
Epoch: 041, Runtime 0.024420, Loss 6340408246272.000000, Train: 0.1800, Val: 0.1962, Test: 0.2083, Best time: 7.8741
Epoch: 042, Runtime 0.031247, Loss 16490759716864.000000, Train: 0.1933, Val: 0.1876, Test: 0.2250, Best time: 7.8741
Epoch: 043, Runtime 0.026146, Loss 40658324684800.000000, Train: 0.2000, Val: 0.1751, Test: 0.1917, Best time: 7.8741
Epoch: 044, Runtime 0.026554, Loss 11678269833216.000000, Train: 0.2000, Val: 0.1778, Test: 0.1833, Best time: 7.8741
Epoch: 045, Runtime 0.023633, Loss 13212936306688.000000, Train: 0.2200, Val: 0.1805, Test: 0.1750, Best time: 7.8741
Epoch: 046, Runtime 0.045323, Loss 18739737133056.000000, Train: 0.2467, Val: 0.1719, Test: 0.1667, Best time: 7.8741
Epoch: 047, Runtime 0.037296, Loss 28529131520000.000000, Train: 0.2533, Val: 0.1578, Test: 0.1667, Best time: 7.8741
Epoch: 048, Runtime 0.022298, Loss 4598014148608.000000, Train: 0.2533, Val: 0.1568, Test: 0.1750, Best time: 7.8741
Epoch: 049, Runtime 0.026212, Loss 8527247572992.000000, Train: 0.2200, Val: 0.1535, Test: 0.1417, Best time: 7.8741
Epoch: 050, Runtime 0.028542, Loss 5444418404352.000000, Train: 0.2133, Val: 0.1568, Test: 0.1167, Best time: 7.8741
Epoch: 051, Runtime 0.024721, Loss 8057586712576.000000, Train: 0.2267, Val: 0.1659, Test: 0.1500, Best time: 7.8741
Epoch: 052, Runtime 0.025107, Loss 3144203108352.000000, Train: 0.2267, Val: 0.1735, Test: 0.1500, Best time: 7.8741
Epoch: 053, Runtime 0.029427, Loss 53673149333504.000000, Train: 0.2467, Val: 0.1741, Test: 0.1417, Best time: 7.8741
Epoch: 054, Runtime 0.031853, Loss 6152313634816.000000, Train: 0.2533, Val: 0.1762, Test: 0.1500, Best time: 7.8741
Epoch: 055, Runtime 0.028687, Loss 10075111424000.000000, Train: 0.2800, Val: 0.1838, Test: 0.1667, Best time: 7.8741
Epoch: 056, Runtime 0.026473, Loss 2296689197056.000000, Train: 0.3067, Val: 0.1859, Test: 0.2167, Best time: 7.8741
Epoch: 057, Runtime 0.026616, Loss 8649080569856.000000, Train: 0.3333, Val: 0.1870, Test: 0.2333, Best time: 7.8741
Epoch: 058, Runtime 0.032581, Loss 6885883248640.000000, Train: 0.3467, Val: 0.1811, Test: 0.2667, Best time: 7.8741
Epoch: 059, Runtime 0.027363, Loss 612609622016.000000, Train: 0.3733, Val: 0.1886, Test: 0.2750, Best time: 7.8741
Epoch: 060, Runtime 0.025862, Loss 8094812733440.000000, Train: 0.3600, Val: 0.1941, Test: 0.2750, Best time: 7.8741
Epoch: 061, Runtime 0.025593, Loss 4578478129152.000000, Train: 0.3467, Val: 0.2076, Test: 0.2917, Best time: 7.8741
Epoch: 062, Runtime 0.026340, Loss 1020269232128.000000, Train: 0.3333, Val: 0.2092, Test: 0.2917, Best time: 7.8741
Epoch: 063, Runtime 0.024995, Loss 2120417935360.000000, Train: 0.3000, Val: 0.2130, Test: 0.3000, Best time: 7.8741
Epoch: 064, Runtime 0.040396, Loss 3351860740096.000000, Train: 0.3000, Val: 0.2157, Test: 0.2833, Best time: 7.8741
Epoch: 065, Runtime 0.027494, Loss 1213796843520.000000, Train: 0.3000, Val: 0.2157, Test: 0.2833, Best time: 7.8741
Epoch: 066, Runtime 0.024839, Loss 282334887936.000000, Train: 0.2933, Val: 0.2119, Test: 0.2750, Best time: 7.8741
Epoch: 067, Runtime 0.024695, Loss 549743394816.000000, Train: 0.2867, Val: 0.2114, Test: 0.2750, Best time: 7.8741
Epoch: 068, Runtime 0.026728, Loss 761376342016.000000, Train: 0.2867, Val: 0.2135, Test: 0.2750, Best time: 7.8741
Epoch: 069, Runtime 0.027095, Loss 932403216384.000000, Train: 0.2733, Val: 0.2114, Test: 0.2833, Best time: 7.8741
Epoch: 070, Runtime 0.025577, Loss 7860498989056.000000, Train: 0.2733, Val: 0.2119, Test: 0.2667, Best time: 7.8741
Epoch: 071, Runtime 0.026470, Loss 647099777024.000000, Train: 0.2867, Val: 0.2130, Test: 0.2583, Best time: 7.8741
Epoch: 072, Runtime 0.027582, Loss 750752235520.000000, Train: 0.3133, Val: 0.2103, Test: 0.2583, Best time: 7.8741
Epoch: 073, Runtime 0.026080, Loss 3949907935232.000000, Train: 0.3067, Val: 0.2097, Test: 0.2583, Best time: 7.8741
Epoch: 074, Runtime 0.026735, Loss 1277444358144.000000, Train: 0.3133, Val: 0.2005, Test: 0.2667, Best time: 7.8741
Epoch: 075, Runtime 0.025453, Loss 330000760832.000000, Train: 0.3067, Val: 0.1995, Test: 0.2333, Best time: 7.8741
Epoch: 076, Runtime 0.026895, Loss 59264684032.000000, Train: 0.3133, Val: 0.1973, Test: 0.2250, Best time: 7.8741
Epoch: 077, Runtime 0.026709, Loss 196392419328.000000, Train: 0.1800, Val: 0.2400, Test: 0.2250, Best time: 7.8741
Epoch: 078, Runtime 0.026861, Loss 327205453824.000000, Train: 0.1800, Val: 0.2389, Test: 0.2167, Best time: 7.8741
Epoch: 079, Runtime 0.026000, Loss 274916081664.000000, Train: 0.1933, Val: 0.2400, Test: 0.2167, Best time: 7.8741
Epoch: 080, Runtime 0.034552, Loss 137372262400.000000, Train: 0.2000, Val: 0.2411, Test: 0.2000, Best time: 7.8741
Epoch: 081, Runtime 0.027933, Loss 393390161920.000000, Train: 0.2000, Val: 0.2373, Test: 0.1917, Best time: 7.8741
Epoch: 082, Runtime 0.026560, Loss 235415371776.000000, Train: 0.1933, Val: 0.2330, Test: 0.2000, Best time: 7.8741
Epoch: 083, Runtime 0.046046, Loss 656637165568.000000, Train: 0.1933, Val: 0.2308, Test: 0.2000, Best time: 7.8741
Epoch: 084, Runtime 0.024283, Loss 399596191744.000000, Train: 0.1933, Val: 0.2308, Test: 0.2000, Best time: 7.8741
Epoch: 085, Runtime 0.024779, Loss 145889492992.000000, Train: 0.2000, Val: 0.2303, Test: 0.2000, Best time: 7.8741
Epoch: 086, Runtime 0.024663, Loss 38191153152.000000, Train: 0.1933, Val: 0.2292, Test: 0.2000, Best time: 7.8741
Epoch: 087, Runtime 0.021757, Loss 1095561510912.000000, Train: 0.2000, Val: 0.2308, Test: 0.1833, Best time: 7.8741
Epoch: 088, Runtime 0.022886, Loss 1296856121344.000000, Train: 0.2000, Val: 0.2303, Test: 0.1833, Best time: 7.8741
Epoch: 089, Runtime 0.027117, Loss 151267508224.000000, Train: 0.2000, Val: 0.2292, Test: 0.1833, Best time: 7.8741
Epoch: 090, Runtime 0.025016, Loss 128002007040.000000, Train: 0.2000, Val: 0.2276, Test: 0.1833, Best time: 7.8741
Epoch: 091, Runtime 0.030388, Loss 559518056448.000000, Train: 0.2000, Val: 0.2297, Test: 0.1750, Best time: 7.8741
Epoch: 092, Runtime 0.030511, Loss 180244561920.000000, Train: 0.2067, Val: 0.2297, Test: 0.1750, Best time: 7.8741
Epoch: 093, Runtime 0.029491, Loss 84137271296.000000, Train: 0.2133, Val: 0.2297, Test: 0.1750, Best time: 7.8741
Epoch: 094, Runtime 0.029392, Loss 205883506688.000000, Train: 0.2133, Val: 0.2292, Test: 0.1750, Best time: 7.8741
Epoch: 095, Runtime 0.028550, Loss 52416499712.000000, Train: 0.2200, Val: 0.2308, Test: 0.1917, Best time: 7.8741
Epoch: 096, Runtime 0.028110, Loss 43576422400.000000, Train: 0.2200, Val: 0.2308, Test: 0.2000, Best time: 7.8741
Epoch: 097, Runtime 0.024165, Loss 20546537472.000000, Train: 0.2933, Val: 0.1870, Test: 0.2000, Best time: 7.8741
Epoch: 098, Runtime 0.024203, Loss 947943040.000000, Train: 0.2933, Val: 0.1897, Test: 0.1833, Best time: 7.8741
Epoch: 099, Runtime 0.025936, Loss 71747346432.000000, Train: 0.3000, Val: 0.1897, Test: 0.1833, Best time: 7.8741

 46%|████████████▉               | 116/250 [00:04<00:03, 36.04it/s]
Epoch: 101, Runtime 0.048330, Loss 8571595776.000000, Train: 0.3067, Val: 0.1914, Test: 0.1917, Best time: 7.8741
Epoch: 102, Runtime 0.027203, Loss 212830666752.000000, Train: 0.3067, Val: 0.1908, Test: 0.1917, Best time: 7.8741
Epoch: 103, Runtime 0.025706, Loss 40550801408.000000, Train: 0.3067, Val: 0.1908, Test: 0.1917, Best time: 7.8741
Epoch: 104, Runtime 0.027043, Loss 102603767808.000000, Train: 0.3067, Val: 0.1919, Test: 0.1917, Best time: 7.8741
Epoch: 105, Runtime 0.030286, Loss 21718466560.000000, Train: 0.3067, Val: 0.1924, Test: 0.2083, Best time: 7.8741
Epoch: 106, Runtime 0.030117, Loss 190456479744.000000, Train: 0.3133, Val: 0.1919, Test: 0.2083, Best time: 7.8741
Epoch: 107, Runtime 0.030508, Loss 244924596224.000000, Train: 0.2267, Val: 0.2335, Test: 0.2167, Best time: 7.8741
Epoch: 108, Runtime 0.026961, Loss 45692641280.000000, Train: 0.2267, Val: 0.2351, Test: 0.2167, Best time: 7.8741
Epoch: 109, Runtime 0.025648, Loss 148827275264.000000, Train: 0.2267, Val: 0.2351, Test: 0.2250, Best time: 7.8741
Epoch: 110, Runtime 0.025260, Loss 210868011008.000000, Train: 0.2267, Val: 0.2351, Test: 0.2333, Best time: 7.8741
Epoch: 111, Runtime 0.025023, Loss 87104757760.000000, Train: 0.2267, Val: 0.2362, Test: 0.2333, Best time: 7.8741
Epoch: 112, Runtime 0.026582, Loss 903603683328.000000, Train: 0.2200, Val: 0.2357, Test: 0.2333, Best time: 7.8741
Epoch: 113, Runtime 0.023916, Loss 1205228273664.000000, Train: 0.2067, Val: 0.2378, Test: 0.2250, Best time: 7.8741
Epoch: 114, Runtime 0.024452, Loss 24396029952.000000, Train: 0.3067, Val: 0.1908, Test: 0.2083, Best time: 7.8741
Epoch: 115, Runtime 0.025913, Loss 89776226304.000000, Train: 0.3067, Val: 0.1876, Test: 0.2083, Best time: 7.8741
Epoch: 116, Runtime 0.026244, Loss 1239992631296.000000, Train: 0.3067, Val: 0.1854, Test: 0.2083, Best time: 7.8741
Epoch: 117, Runtime 0.200525, Loss 173422526464.000000, Train: 0.3067, Val: 0.1822, Test: 0.2083, Best time: 7.8741
Epoch: 118, Runtime 0.030458, Loss 145716674560.000000, Train: 0.3067, Val: 0.1811, Test: 0.2167, Best time: 7.8741
Epoch: 119, Runtime 0.027627, Loss 225596882944.000000, Train: 0.3067, Val: 0.1784, Test: 0.2083, Best time: 7.8741
Epoch: 120, Runtime 0.027193, Loss 563966640128.000000, Train: 0.3133, Val: 0.1773, Test: 0.2083, Best time: 7.8741
Epoch: 121, Runtime 0.028664, Loss 154387496960.000000, Train: 0.3133, Val: 0.1768, Test: 0.2083, Best time: 7.8741
Epoch: 122, Runtime 0.028092, Loss 121917718528.000000, Train: 0.3133, Val: 0.1773, Test: 0.2167, Best time: 7.8741
Epoch: 123, Runtime 0.031287, Loss 463346368512.000000, Train: 0.3200, Val: 0.1773, Test: 0.2167, Best time: 7.8741
Epoch: 124, Runtime 0.024507, Loss 74285318144.000000, Train: 0.3067, Val: 0.1762, Test: 0.2167, Best time: 7.8741
Epoch: 125, Runtime 0.024137, Loss 182573416448.000000, Train: 0.3000, Val: 0.1773, Test: 0.2083, Best time: 7.8741
Epoch: 126, Runtime 0.022363, Loss 108369870848.000000, Train: 0.3067, Val: 0.1762, Test: 0.2167, Best time: 7.8741
Epoch: 127, Runtime 0.021488, Loss 79844122624.000000, Train: 0.3133, Val: 0.1886, Test: 0.2333, Best time: 7.8741
Epoch: 128, Runtime 0.020801, Loss 132581400576.000000, Train: 0.3133, Val: 0.1881, Test: 0.2333, Best time: 7.8741
Epoch: 129, Runtime 0.025117, Loss 474836140032.000000, Train: 0.3133, Val: 0.1903, Test: 0.2417, Best time: 7.8741
Epoch: 130, Runtime 0.025441, Loss 458153263104.000000, Train: 0.3133, Val: 0.1908, Test: 0.2417, Best time: 7.8741
Epoch: 131, Runtime 0.019772, Loss 135164313600.000000, Train: 0.3133, Val: 0.1919, Test: 0.2417, Best time: 7.8741
Epoch: 132, Runtime 0.018234, Loss 39992270848.000000, Train: 0.3133, Val: 0.1908, Test: 0.2417, Best time: 7.8741
Epoch: 133, Runtime 0.018443, Loss 27199776768.000000, Train: 0.2133, Val: 0.2465, Test: 0.2167, Best time: 7.8741
Epoch: 134, Runtime 0.018627, Loss 29663019008.000000, Train: 0.2067, Val: 0.2492, Test: 0.2083, Best time: 7.8741
Epoch: 135, Runtime 0.019552, Loss 23833915392.000000, Train: 0.2067, Val: 0.2481, Test: 0.2083, Best time: 7.8741
Epoch: 136, Runtime 0.019050, Loss 232713093120.000000, Train: 0.2000, Val: 0.2476, Test: 0.2083, Best time: 7.8741
Epoch: 137, Runtime 0.017806, Loss 109218144256.000000, Train: 0.2000, Val: 0.2438, Test: 0.2167, Best time: 7.8741
Epoch: 138, Runtime 0.017693, Loss 466829180928.000000, Train: 0.2000, Val: 0.2432, Test: 0.2167, Best time: 7.8741
Epoch: 139, Runtime 0.035189, Loss 59378159616.000000, Train: 0.2000, Val: 0.2438, Test: 0.2250, Best time: 7.8741
Epoch: 140, Runtime 0.018021, Loss 17668689920.000000, Train: 0.2000, Val: 0.2443, Test: 0.2333, Best time: 7.8741
Epoch: 141, Runtime 0.018357, Loss 15063881728.000000, Train: 0.3133, Val: 0.1919, Test: 0.2333, Best time: 7.8741
Epoch: 142, Runtime 0.016134, Loss 7487725056.000000, Train: 0.3067, Val: 0.1843, Test: 0.2167, Best time: 7.8741
Epoch: 143, Runtime 0.016422, Loss 21040517120.000000, Train: 0.3067, Val: 0.1849, Test: 0.2167, Best time: 7.8741
Epoch: 144, Runtime 0.016963, Loss 2183987968.000000, Train: 0.3067, Val: 0.1849, Test: 0.2167, Best time: 7.8741
Epoch: 145, Runtime 0.019485, Loss 47203422208.000000, Train: 0.3067, Val: 0.1849, Test: 0.2083, Best time: 7.8741
Epoch: 146, Runtime 0.016648, Loss 53151080448.000000, Train: 0.3067, Val: 0.1859, Test: 0.2000, Best time: 7.8741
Epoch: 147, Runtime 0.016868, Loss 151937220608.000000, Train: 0.3067, Val: 0.1865, Test: 0.2000, Best time: 7.8741
Epoch: 148, Runtime 0.016760, Loss 78223065088.000000, Train: 0.3067, Val: 0.1854, Test: 0.2167, Best time: 7.8741
Epoch: 149, Runtime 0.017523, Loss 122155540480.000000, Train: 0.2067, Val: 0.2503, Test: 0.2250, Best time: 7.8741
Epoch: 150, Runtime 0.022229, Loss 108261498880.000000, Train: 0.2133, Val: 0.1600, Test: 0.1833, Best time: 7.8741
Epoch: 151, Runtime 0.017472, Loss 389655648.000000, Train: 0.2067, Val: 0.2497, Test: 0.1917, Best time: 7.8741
Epoch: 152, Runtime 0.017484, Loss 2437466112.000000, Train: 0.3200, Val: 0.1859, Test: 0.2333, Best time: 7.8741
Epoch: 153, Runtime 0.017848, Loss 2465489152.000000, Train: 0.2067, Val: 0.2524, Test: 0.2000, Best time: 7.8741
Epoch: 154, Runtime 0.017900, Loss 6940321792.000000, Train: 0.3133, Val: 0.1886, Test: 0.2250, Best time: 7.8741
Epoch: 155, Runtime 0.017675, Loss 1099466624.000000, Train: 0.3000, Val: 0.1978, Test: 0.2250, Best time: 7.8741
Epoch: 156, Runtime 0.021302, Loss 3132008704.000000, Train: 0.3000, Val: 0.1984, Test: 0.2250, Best time: 7.8741
Epoch: 157, Runtime 0.017578, Loss 3805616128.000000, Train: 0.3067, Val: 0.1957, Test: 0.2167, Best time: 7.8741
Epoch: 158, Runtime 0.018819, Loss 1808710016.000000, Train: 0.3200, Val: 0.1870, Test: 0.2250, Best time: 7.8741
Epoch: 159, Runtime 0.018975, Loss 1305549056.000000, Train: 0.2000, Val: 0.2535, Test: 0.2000, Best time: 7.8741
Epoch: 160, Runtime 0.023704, Loss 5838985728.000000, Train: 0.2000, Val: 0.2546, Test: 0.1667, Best time: 7.8741
Epoch: 161, Runtime 0.019852, Loss 273116160.000000, Train: 0.3000, Val: 0.1989, Test: 0.2167, Best time: 7.8741
Epoch: 162, Runtime 0.020355, Loss 13617757184.000000, Train: 0.3200, Val: 0.1870, Test: 0.2167, Best time: 7.8741
Epoch: 163, Runtime 0.020550, Loss 3335179264.000000, Train: 0.1933, Val: 0.2481, Test: 0.2167, Best time: 7.8741
Epoch: 164, Runtime 0.022946, Loss 4952338944.000000, Train: 0.1933, Val: 0.2486, Test: 0.2167, Best time: 7.8741
Epoch: 165, Runtime 0.041379, Loss 4620443648.000000, Train: 0.1933, Val: 0.2486, Test: 0.2250, Best time: 7.8741
Epoch: 166, Runtime 0.021728, Loss 103154974720.000000, Train: 0.1933, Val: 0.2481, Test: 0.2250, Best time: 7.8741
Epoch: 167, Runtime 0.021127, Loss 30016131072.000000, Train: 0.1933, Val: 0.2481, Test: 0.2167, Best time: 7.8741
Epoch: 168, Runtime 0.024376, Loss 7793865216.000000, Train: 0.2000, Val: 0.2524, Test: 0.2000, Best time: 7.8741
Epoch: 169, Runtime 0.025255, Loss 2059458304.000000, Train: 0.2933, Val: 0.1962, Test: 0.2167, Best time: 7.8741
Epoch: 170, Runtime 0.020824, Loss 17807507456.000000, Train: 0.2933, Val: 0.1886, Test: 0.2083, Best time: 7.8741
Epoch: 171, Runtime 0.023396, Loss 36149067776.000000, Train: 0.2933, Val: 0.1919, Test: 0.2083, Best time: 7.8741
Epoch: 172, Runtime 0.020984, Loss 24234473472.000000, Train: 0.3000, Val: 0.1962, Test: 0.2167, Best time: 7.8741
Epoch: 173, Runtime 0.020654, Loss 159236734976.000000, Train: 0.1933, Val: 0.2497, Test: 0.2250, Best time: 7.8741
Epoch: 174, Runtime 0.021992, Loss 49853984768.000000, Train: 0.1933, Val: 0.2492, Test: 0.2250, Best time: 7.8741
Epoch: 175, Runtime 0.023803, Loss 523934793728.000000, Train: 0.1933, Val: 0.2508, Test: 0.2250, Best time: 7.8741
Epoch: 176, Runtime 0.020306, Loss 113483538432.000000, Train: 0.1933, Val: 0.2514, Test: 0.2250, Best time: 7.8741
Epoch: 177, Runtime 0.020343, Loss 68865523712.000000, Train: 0.1933, Val: 0.2514, Test: 0.2167, Best time: 7.8741
Epoch: 178, Runtime 0.024087, Loss 466518999040.000000, Train: 0.2000, Val: 0.2514, Test: 0.2167, Best time: 7.8741
Epoch: 179, Runtime 0.020960, Loss 139628036096.000000, Train: 0.2000, Val: 0.2530, Test: 0.2250, Best time: 7.8741
Epoch: 180, Runtime 0.022000, Loss 980142653440.000000, Train: 0.2000, Val: 0.2524, Test: 0.2333, Best time: 7.8741
Epoch: 181, Runtime 0.020370, Loss 287309332480.000000, Train: 0.1933, Val: 0.2508, Test: 0.2333, Best time: 7.8741
Epoch: 182, Runtime 0.019388, Loss 160275267584.000000, Train: 0.1933, Val: 0.2492, Test: 0.2417, Best time: 7.8741
Epoch: 183, Runtime 0.020283, Loss 61790683136.000000, Train: 0.1933, Val: 0.2481, Test: 0.2417, Best time: 7.8741
Epoch: 184, Runtime 0.026240, Loss 284651356160.000000, Train: 0.2000, Val: 0.2486, Test: 0.2417, Best time: 7.8741
Epoch: 185, Runtime 0.019789, Loss 170210623488.000000, Train: 0.2000, Val: 0.2486, Test: 0.2417, Best time: 7.8741


100%|████████████████████████████| 250/250 [00:07<00:00, 32.51it/s]
Epoch: 187, Runtime 0.038816, Loss 36212461568.000000, Train: 0.2867, Val: 0.1897, Test: 0.2167, Best time: 7.8741
Epoch: 188, Runtime 0.028110, Loss 25967953920.000000, Train: 0.2867, Val: 0.1897, Test: 0.2167, Best time: 7.8741
Epoch: 189, Runtime 0.026553, Loss 70349938688.000000, Train: 0.2867, Val: 0.1886, Test: 0.2167, Best time: 7.8741
Epoch: 190, Runtime 0.026020, Loss 11380398080.000000, Train: 0.2867, Val: 0.1881, Test: 0.2167, Best time: 7.8741
Epoch: 191, Runtime 0.024693, Loss 33895010304.000000, Train: 0.2867, Val: 0.1892, Test: 0.2167, Best time: 7.8741
Epoch: 192, Runtime 0.029092, Loss 343084859392.000000, Train: 0.2867, Val: 0.1886, Test: 0.2083, Best time: 7.8741
Epoch: 193, Runtime 0.024034, Loss 40705204224.000000, Train: 0.2867, Val: 0.1881, Test: 0.2083, Best time: 7.8741
Epoch: 194, Runtime 0.023744, Loss 33415761920.000000, Train: 0.2867, Val: 0.1876, Test: 0.2167, Best time: 7.8741
Epoch: 195, Runtime 0.020165, Loss 3013133056.000000, Train: 0.2000, Val: 0.2422, Test: 0.2417, Best time: 7.8741
Epoch: 196, Runtime 0.025059, Loss 4878318592.000000, Train: 0.2067, Val: 0.2443, Test: 0.2333, Best time: 7.8741
Epoch: 197, Runtime 0.020647, Loss 61628551168.000000, Train: 0.2067, Val: 0.2449, Test: 0.2333, Best time: 7.8741
Epoch: 198, Runtime 0.022694, Loss 72147017728.000000, Train: 0.2067, Val: 0.2443, Test: 0.2333, Best time: 7.8741
Epoch: 199, Runtime 0.054830, Loss 146928386048.000000, Train: 0.3067, Val: 0.1924, Test: 0.2333, Best time: 7.8741
Epoch: 200, Runtime 0.021452, Loss 11920552960.000000, Train: 0.2867, Val: 0.1859, Test: 0.2083, Best time: 7.8741
Epoch: 201, Runtime 0.024572, Loss 20950196224.000000, Train: 0.2867, Val: 0.1849, Test: 0.2083, Best time: 7.8741
Epoch: 202, Runtime 0.024433, Loss 18712104960.000000, Train: 0.2933, Val: 0.1827, Test: 0.2083, Best time: 7.8741
Epoch: 203, Runtime 0.024454, Loss 7048695296.000000, Train: 0.2000, Val: 0.2432, Test: 0.2083, Best time: 7.8741
Epoch: 204, Runtime 0.019474, Loss 10804334592.000000, Train: 0.2933, Val: 0.1849, Test: 0.2167, Best time: 7.8741
Epoch: 205, Runtime 0.021699, Loss 12480854016.000000, Train: 0.2933, Val: 0.1865, Test: 0.2167, Best time: 7.8741
Epoch: 206, Runtime 0.038494, Loss 93344579584.000000, Train: 0.2933, Val: 0.1859, Test: 0.2167, Best time: 7.8741
Epoch: 207, Runtime 0.026603, Loss 53223538688.000000, Train: 0.2933, Val: 0.1854, Test: 0.2167, Best time: 7.8741
Epoch: 208, Runtime 0.021948, Loss 31713300480.000000, Train: 0.2933, Val: 0.1849, Test: 0.2167, Best time: 7.8741
Epoch: 209, Runtime 0.021662, Loss 22320490496.000000, Train: 0.2933, Val: 0.1832, Test: 0.2167, Best time: 7.8741
Epoch: 210, Runtime 0.020638, Loss 57567125504.000000, Train: 0.2933, Val: 0.1838, Test: 0.2167, Best time: 7.8741
Epoch: 211, Runtime 0.020001, Loss 76838289408.000000, Train: 0.2933, Val: 0.1832, Test: 0.2167, Best time: 7.8741
Epoch: 212, Runtime 0.020581, Loss 646032064512.000000, Train: 0.2933, Val: 0.1881, Test: 0.2167, Best time: 7.8741
Epoch: 213, Runtime 0.020879, Loss 121091022848.000000, Train: 0.2933, Val: 0.1881, Test: 0.2083, Best time: 7.8741
Epoch: 214, Runtime 0.021582, Loss 8359743488.000000, Train: 0.2133, Val: 0.2411, Test: 0.2417, Best time: 7.8741
Epoch: 215, Runtime 0.025261, Loss 61605216256.000000, Train: 0.2067, Val: 0.2416, Test: 0.2500, Best time: 7.8741
Epoch: 216, Runtime 0.025837, Loss 3227785728.000000, Train: 0.2133, Val: 0.2416, Test: 0.2500, Best time: 7.8741
Epoch: 217, Runtime 0.023920, Loss 51324055552.000000, Train: 0.2133, Val: 0.2422, Test: 0.2500, Best time: 7.8741
Epoch: 218, Runtime 0.023420, Loss 80938614784.000000, Train: 0.2067, Val: 0.2438, Test: 0.2500, Best time: 7.8741
Epoch: 219, Runtime 0.026002, Loss 101611520000.000000, Train: 0.2067, Val: 0.2422, Test: 0.2583, Best time: 7.8741
Epoch: 220, Runtime 0.025458, Loss 21595260928.000000, Train: 0.2133, Val: 0.2400, Test: 0.2583, Best time: 7.8741
Epoch: 221, Runtime 0.023836, Loss 17766875136.000000, Train: 0.3200, Val: 0.1951, Test: 0.2167, Best time: 7.8741
Epoch: 222, Runtime 0.028804, Loss 1249363584.000000, Train: 0.3067, Val: 0.1924, Test: 0.2250, Best time: 7.8741
Epoch: 223, Runtime 0.024098, Loss 54503137280.000000, Train: 0.3067, Val: 0.1930, Test: 0.2250, Best time: 7.8741
Epoch: 224, Runtime 0.028628, Loss 20768358400.000000, Train: 0.3067, Val: 0.1941, Test: 0.2167, Best time: 7.8741
Epoch: 225, Runtime 0.024334, Loss 15745592320.000000, Train: 0.3267, Val: 0.1968, Test: 0.2333, Best time: 7.8741
Epoch: 226, Runtime 0.022752, Loss 25109301248.000000, Train: 0.2067, Val: 0.2373, Test: 0.2500, Best time: 7.8741
Epoch: 227, Runtime 0.037716, Loss 63938097152.000000, Train: 0.2067, Val: 0.2368, Test: 0.2500, Best time: 7.8741
Epoch: 228, Runtime 0.026732, Loss 340569391104.000000, Train: 0.2067, Val: 0.2362, Test: 0.2500, Best time: 7.8741
Epoch: 229, Runtime 0.029998, Loss 1086936186880.000000, Train: 0.2067, Val: 0.2362, Test: 0.2500, Best time: 7.8741
Epoch: 230, Runtime 0.034414, Loss 73414967296.000000, Train: 0.2067, Val: 0.2373, Test: 0.2500, Best time: 7.8741
Epoch: 231, Runtime 0.026553, Loss 23242469376.000000, Train: 0.2133, Val: 0.2378, Test: 0.2500, Best time: 7.8741
Epoch: 232, Runtime 0.027457, Loss 2761678848.000000, Train: 0.3000, Val: 0.1984, Test: 0.2167, Best time: 7.8741
Epoch: 233, Runtime 0.027467, Loss 3268358144.000000, Train: 0.3000, Val: 0.1978, Test: 0.2250, Best time: 7.8741
Epoch: 234, Runtime 0.027385, Loss 21956317184.000000, Train: 0.3000, Val: 0.1973, Test: 0.2250, Best time: 7.8741
Epoch: 235, Runtime 0.026236, Loss 92902391808.000000, Train: 0.3000, Val: 0.1973, Test: 0.2250, Best time: 7.8741
Epoch: 236, Runtime 0.027900, Loss 67308056576.000000, Train: 0.3000, Val: 0.1973, Test: 0.2250, Best time: 7.8741
Epoch: 237, Runtime 0.029934, Loss 96556056576.000000, Train: 0.2933, Val: 0.1973, Test: 0.2250, Best time: 7.8741
Epoch: 238, Runtime 0.030421, Loss 361724739584.000000, Train: 0.3000, Val: 0.1919, Test: 0.2167, Best time: 7.8741
Epoch: 239, Runtime 0.028139, Loss 21612158976.000000, Train: 0.2000, Val: 0.2449, Test: 0.2333, Best time: 7.8741
Epoch: 240, Runtime 0.027571, Loss 14803434496.000000, Train: 0.2067, Val: 0.2427, Test: 0.2333, Best time: 7.8741
Epoch: 241, Runtime 0.028718, Loss 45317464064.000000, Train: 0.2067, Val: 0.2427, Test: 0.2250, Best time: 7.8741
Epoch: 242, Runtime 0.036230, Loss 84737835008.000000, Train: 0.2067, Val: 0.2411, Test: 0.2250, Best time: 7.8741
Epoch: 243, Runtime 0.031144, Loss 455861764096.000000, Train: 0.2067, Val: 0.2438, Test: 0.2250, Best time: 7.8741
Epoch: 244, Runtime 0.043555, Loss 135599054848.000000, Train: 0.2000, Val: 0.2443, Test: 0.2417, Best time: 7.8741
Epoch: 245, Runtime 0.029954, Loss 96632299520.000000, Train: 0.2000, Val: 0.2432, Test: 0.2333, Best time: 7.8741
Epoch: 246, Runtime 0.029044, Loss 724046118912.000000, Train: 0.1933, Val: 0.2427, Test: 0.2333, Best time: 7.8741
Epoch: 247, Runtime 0.026391, Loss 1279849529344.000000, Train: 0.2000, Val: 0.2470, Test: 0.2417, Best time: 7.8741
Epoch: 248, Runtime 0.027876, Loss 60762583040.000000, Train: 0.2000, Val: 0.2476, Test: 0.2667, Best time: 7.8741
Epoch: 249, Runtime 0.029599, Loss 68821622784.000000, Train: 0.1933, Val: 0.2503, Test: 0.2667, Best time: 7.8741
Epoch: 250, Runtime 0.027335, Loss 10017466368.000000, Train: 0.3133, Val: 0.1881, Test: 0.2250, Best time: 7.8741
best val accuracy 0.188108 with test accuracy 0.225000 at epoch 3 and best time 7.874113