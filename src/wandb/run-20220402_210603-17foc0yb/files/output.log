GrandExtendDiscritizedNet
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
mol_list.0.alpha_train
torch.Size([])
mol_list.0.beta_train
torch.Size([])
mol_list.0.alpha_sc
torch.Size([1])
mol_list.0.beta_sc
torch.Size([1])
mol_list.0.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.0.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.V.bias
torch.Size([128])
mol_list.0.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.K.bias
torch.Size([128])
mol_list.0.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.0.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.1.alpha_train
torch.Size([])
mol_list.1.beta_train
torch.Size([])
mol_list.1.alpha_sc
torch.Size([1])
mol_list.1.beta_sc
torch.Size([1])
mol_list.1.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.1.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.V.bias
torch.Size([128])
mol_list.1.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.K.bias
torch.Size([128])
mol_list.1.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.1.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.2.alpha_train
torch.Size([])
mol_list.2.beta_train
torch.Size([])
mol_list.2.alpha_sc
torch.Size([1])
mol_list.2.beta_sc
torch.Size([1])
mol_list.2.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.2.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.V.bias
torch.Size([128])
mol_list.2.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.K.bias
torch.Size([128])
mol_list.2.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.2.multihead_att_layer.Wout.bias
torch.Size([80])

 75%|█████████████████████▊       | 75/100 [00:03<00:00, 42.07it/s]
Epoch: 001, Runtime 1.457523, Loss 1.949762, Train: 0.6057, Val: 0.5507, Test: 0.5670, Best time: 18.2948
Epoch: 002, Runtime 0.024479, Loss 4.246593, Train: 0.1886, Val: 0.3140, Test: 0.3052, Best time: 18.2948
Epoch: 003, Runtime 0.027689, Loss 1.902557, Train: 0.1371, Val: 0.1386, Test: 0.1670, Best time: 18.2948
Epoch: 004, Runtime 0.023811, Loss 133684.265625, Train: 0.1543, Val: 0.1288, Test: 0.1567, Best time: 18.2948
Epoch: 005, Runtime 0.027218, Loss 6593209344.000000, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 006, Runtime 0.026741, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 007, Runtime 0.023326, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 008, Runtime 0.025030, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 009, Runtime 0.028246, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 010, Runtime 0.025143, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 011, Runtime 0.023330, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 012, Runtime 0.022486, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 013, Runtime 0.024390, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 014, Runtime 0.036353, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 015, Runtime 0.030452, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 016, Runtime 0.023968, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 017, Runtime 0.027563, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 018, Runtime 0.021435, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 019, Runtime 0.021943, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 020, Runtime 0.023074, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 021, Runtime 0.021536, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 022, Runtime 0.021597, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 023, Runtime 0.022536, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 024, Runtime 0.020947, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 025, Runtime 0.022743, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 026, Runtime 0.031212, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 027, Runtime 0.024633, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 028, Runtime 0.032888, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 029, Runtime 0.023943, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 030, Runtime 0.022975, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 031, Runtime 0.024091, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 032, Runtime 0.023518, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 033, Runtime 0.023454, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 034, Runtime 0.033218, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 035, Runtime 0.022052, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 036, Runtime 0.024071, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 037, Runtime 0.021629, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 038, Runtime 0.019979, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 039, Runtime 0.020136, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 040, Runtime 0.024343, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 041, Runtime 0.024152, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 042, Runtime 0.021106, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 043, Runtime 0.020944, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 044, Runtime 0.024744, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 045, Runtime 0.021835, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 046, Runtime 0.024776, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 047, Runtime 0.022862, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 048, Runtime 0.024083, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 049, Runtime 0.021550, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 050, Runtime 0.022392, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 051, Runtime 0.021784, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 052, Runtime 0.024097, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 053, Runtime 0.021349, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948

100%|████████████████████████████| 100/100 [00:03<00:00, 25.48it/s]
Epoch: 055, Runtime 0.035980, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 056, Runtime 0.021810, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 057, Runtime 0.020645, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 058, Runtime 0.019613, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 059, Runtime 0.021852, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 060, Runtime 0.021649, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 061, Runtime 0.022198, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 062, Runtime 0.026863, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 063, Runtime 0.023276, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 064, Runtime 0.023559, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 065, Runtime 0.022411, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 066, Runtime 0.021099, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 067, Runtime 0.022640, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 068, Runtime 0.023747, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 069, Runtime 0.021530, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 070, Runtime 0.022009, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 071, Runtime 0.022347, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 072, Runtime 0.027789, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 073, Runtime 0.022121, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 074, Runtime 0.020666, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 075, Runtime 0.020731, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 076, Runtime 0.049580, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 077, Runtime 0.028835, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 078, Runtime 0.024065, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 079, Runtime 0.022872, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 080, Runtime 0.024163, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 081, Runtime 0.021467, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 082, Runtime 0.022995, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 083, Runtime 0.023312, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 084, Runtime 0.026145, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 085, Runtime 0.026464, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 086, Runtime 0.024152, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 087, Runtime 0.027056, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 088, Runtime 0.021331, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 089, Runtime 0.021777, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 090, Runtime 0.023281, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 091, Runtime 0.022520, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 092, Runtime 0.026581, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 093, Runtime 0.022187, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 094, Runtime 0.021170, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 095, Runtime 0.022683, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 096, Runtime 0.020817, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 097, Runtime 0.038147, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 098, Runtime 0.026077, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 099, Runtime 0.022830, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
Epoch: 100, Runtime 0.021553, Loss nan, Train: 0.1429, Val: 0.1430, Test: 0.1196, Best time: 18.2948
best val accuracy 0.143014 with test accuracy 0.119588 at epoch 1 and best time 18.294754