
  0%|                                      | 0/100 [00:00<?, ?it/s]
GrandExtendDiscritizedNet
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
mol_list.0.alpha_train
torch.Size([])
mol_list.0.beta_train
torch.Size([])
mol_list.0.alpha_sc
torch.Size([1])
mol_list.0.beta_sc
torch.Size([1])
mol_list.0.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.0.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.V.bias
torch.Size([128])
mol_list.0.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.K.bias
torch.Size([128])
mol_list.0.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.0.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.1.alpha_train
torch.Size([])
mol_list.1.beta_train
torch.Size([])
mol_list.1.alpha_sc
torch.Size([1])
mol_list.1.beta_sc
torch.Size([1])
mol_list.1.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.1.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.V.bias
torch.Size([128])
mol_list.1.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.K.bias
torch.Size([128])
mol_list.1.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.1.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.2.alpha_train
torch.Size([])
mol_list.2.beta_train
torch.Size([])
mol_list.2.alpha_sc
torch.Size([1])
mol_list.2.beta_sc
torch.Size([1])
mol_list.2.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.2.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.V.bias
torch.Size([128])
mol_list.2.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.K.bias
torch.Size([128])
mol_list.2.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.2.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.3.alpha_train
torch.Size([])
mol_list.3.beta_train
torch.Size([])
mol_list.3.alpha_sc
torch.Size([1])
mol_list.3.beta_sc
torch.Size([1])
mol_list.3.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.3.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.V.bias
torch.Size([128])
mol_list.3.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.K.bias
torch.Size([128])
mol_list.3.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.3.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.4.alpha_train
torch.Size([])
mol_list.4.beta_train
torch.Size([])
mol_list.4.alpha_sc
torch.Size([1])
mol_list.4.beta_sc
torch.Size([1])
mol_list.4.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.4.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.V.bias
torch.Size([128])
mol_list.4.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.K.bias
torch.Size([128])
mol_list.4.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.4.multihead_att_layer.Wout.bias
torch.Size([80])
Epoch: 001, Runtime 1.769237, Loss 1.948028, Train: 0.1486, Val: 0.1556, Test: 0.1505, Best time: 18.2948
Epoch: 002, Runtime 0.055264, Loss 6476102012764160.000000, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 003, Runtime 0.049607, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 004, Runtime 0.048870, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 005, Runtime 0.050718, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 006, Runtime 0.049674, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948


 41%|███████████▉                 | 41/100 [00:03<00:03, 18.26it/s]
Epoch: 008, Runtime 0.055190, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 009, Runtime 0.054854, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 010, Runtime 0.047471, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 011, Runtime 0.051009, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 012, Runtime 0.050235, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 013, Runtime 0.045779, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 014, Runtime 0.051055, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 015, Runtime 0.047133, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 016, Runtime 0.047741, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 017, Runtime 0.055473, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 018, Runtime 0.061114, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 019, Runtime 0.063755, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 020, Runtime 0.044165, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 021, Runtime 0.068429, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 022, Runtime 0.075022, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 023, Runtime 0.057532, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 024, Runtime 0.043494, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 025, Runtime 0.056123, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 026, Runtime 0.053520, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 027, Runtime 0.045845, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 028, Runtime 0.046646, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 029, Runtime 0.047482, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 030, Runtime 0.074335, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 031, Runtime 0.056832, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 032, Runtime 0.061185, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 033, Runtime 0.061910, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 034, Runtime 0.055311, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 035, Runtime 0.062670, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 036, Runtime 0.050963, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 037, Runtime 0.062918, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 038, Runtime 0.055767, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 039, Runtime 0.046782, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 040, Runtime 0.047729, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 041, Runtime 0.047289, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 042, Runtime 0.046558, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948

 78%|██████████████████████▌      | 78/100 [00:05<00:01, 18.75it/s]
Epoch: 044, Runtime 0.072676, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 045, Runtime 0.052561, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 046, Runtime 0.049003, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 047, Runtime 0.053255, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 048, Runtime 0.046388, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 049, Runtime 0.045429, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 050, Runtime 0.048399, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 051, Runtime 0.046986, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 052, Runtime 0.047970, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 053, Runtime 0.080721, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 054, Runtime 0.056787, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 055, Runtime 0.050983, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 056, Runtime 0.079420, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 057, Runtime 0.064540, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 058, Runtime 0.046953, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 059, Runtime 0.047304, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 060, Runtime 0.049105, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 061, Runtime 0.047398, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 062, Runtime 0.048864, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 063, Runtime 0.053373, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 064, Runtime 0.045527, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 065, Runtime 0.045827, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 066, Runtime 0.057453, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 067, Runtime 0.049606, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 068, Runtime 0.054368, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 069, Runtime 0.059519, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 070, Runtime 0.054853, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 071, Runtime 0.047901, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 072, Runtime 0.056695, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 073, Runtime 0.051581, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 074, Runtime 0.055902, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 075, Runtime 0.049333, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 076, Runtime 0.058676, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 077, Runtime 0.053820, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 078, Runtime 0.047903, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 079, Runtime 0.048416, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 080, Runtime 0.050096, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948

100%|████████████████████████████| 100/100 [00:07<00:00, 13.64it/s]
Epoch: 082, Runtime 0.050967, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 083, Runtime 0.048080, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 084, Runtime 0.046718, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 085, Runtime 0.050410, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 086, Runtime 0.045821, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 087, Runtime 0.066234, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 088, Runtime 0.050428, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 089, Runtime 0.076319, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 090, Runtime 0.080965, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 091, Runtime 0.060210, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 092, Runtime 0.050986, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 093, Runtime 0.059965, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 094, Runtime 0.056659, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 095, Runtime 0.054833, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 096, Runtime 0.053988, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 097, Runtime 0.058819, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 098, Runtime 0.056061, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 099, Runtime 0.178618, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
Epoch: 100, Runtime 0.046425, Loss nan, Train: 0.1429, Val: 0.1392, Test: 0.1340, Best time: 18.2948
best val accuracy 0.139178 with test accuracy 0.134021 at epoch 1 and best time 18.294754