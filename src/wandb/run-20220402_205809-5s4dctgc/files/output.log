GrandExtendDiscritizedNet
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
mol_list.0.alpha_train
torch.Size([])
mol_list.0.beta_train
torch.Size([])
mol_list.0.alpha_sc
torch.Size([1])
mol_list.0.beta_sc
torch.Size([1])
mol_list.0.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.0.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.V.bias
torch.Size([128])
mol_list.0.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.K.bias
torch.Size([128])
mol_list.0.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.0.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.1.alpha_train
torch.Size([])
mol_list.1.beta_train
torch.Size([])
mol_list.1.alpha_sc
torch.Size([1])
mol_list.1.beta_sc
torch.Size([1])
mol_list.1.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.1.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.V.bias
torch.Size([128])
mol_list.1.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.K.bias
torch.Size([128])
mol_list.1.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.1.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.2.alpha_train
torch.Size([])
mol_list.2.beta_train
torch.Size([])
mol_list.2.alpha_sc
torch.Size([1])
mol_list.2.beta_sc
torch.Size([1])
mol_list.2.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.2.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.V.bias
torch.Size([128])
mol_list.2.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.K.bias
torch.Size([128])
mol_list.2.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.2.multihead_att_layer.Wout.bias
torch.Size([80])

 69%|████████████████████         | 69/100 [00:03<00:00, 39.97it/s]
Epoch: 001, Runtime 1.433440, Loss 1.943529, Train: 0.8000, Val: 0.5792, Test: 0.5278, Best time: 18.2948
Epoch: 002, Runtime 0.030160, Loss 1.810270, Train: 0.4343, Val: 0.2110, Test: 0.2124, Best time: 18.2948
Epoch: 003, Runtime 0.022181, Loss 4.072600, Train: 0.9257, Val: 0.5786, Test: 0.5856, Best time: 18.2948
Epoch: 004, Runtime 0.026967, Loss 1.741806, Train: 0.2057, Val: 0.1770, Test: 0.1938, Best time: 18.2948
Epoch: 005, Runtime 0.023846, Loss 872.219849, Train: 0.2914, Val: 0.2899, Test: 0.2990, Best time: 18.2948
Epoch: 006, Runtime 0.023545, Loss 65385041920.000000, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 007, Runtime 0.023012, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 008, Runtime 0.041912, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 009, Runtime 0.024423, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 010, Runtime 0.021521, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 011, Runtime 0.020916, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 012, Runtime 0.020314, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 013, Runtime 0.022151, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 014, Runtime 0.021798, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 015, Runtime 0.020809, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 016, Runtime 0.020964, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 017, Runtime 0.021990, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 018, Runtime 0.021225, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 019, Runtime 0.023207, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 020, Runtime 0.021924, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 021, Runtime 0.022027, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 022, Runtime 0.021673, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 023, Runtime 0.023633, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 024, Runtime 0.021547, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 025, Runtime 0.021964, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 026, Runtime 0.024132, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 027, Runtime 0.025159, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 028, Runtime 0.021439, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 029, Runtime 0.023040, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 030, Runtime 0.038264, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 031, Runtime 0.023663, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 032, Runtime 0.025762, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 033, Runtime 0.022724, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 034, Runtime 0.023796, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 035, Runtime 0.024764, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 036, Runtime 0.022975, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 037, Runtime 0.021459, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 038, Runtime 0.024068, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 039, Runtime 0.021582, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 040, Runtime 0.020452, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 041, Runtime 0.022792, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 042, Runtime 0.025631, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 043, Runtime 0.023630, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 044, Runtime 0.025223, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 045, Runtime 0.023521, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 046, Runtime 0.022933, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 047, Runtime 0.024382, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 048, Runtime 0.025450, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 049, Runtime 0.026795, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 050, Runtime 0.040674, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 051, Runtime 0.023112, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 052, Runtime 0.022181, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 053, Runtime 0.025357, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 054, Runtime 0.021278, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 055, Runtime 0.021858, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 056, Runtime 0.021794, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 057, Runtime 0.021706, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 058, Runtime 0.021652, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 059, Runtime 0.025112, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 060, Runtime 0.021802, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 061, Runtime 0.022260, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 062, Runtime 0.022884, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 063, Runtime 0.022166, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 064, Runtime 0.022454, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 065, Runtime 0.023949, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 066, Runtime 0.024153, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 067, Runtime 0.024894, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 068, Runtime 0.025306, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 069, Runtime 0.023789, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 070, Runtime 0.023552, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 071, Runtime 0.040384, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 072, Runtime 0.025765, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 073, Runtime 0.021180, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 074, Runtime 0.029430, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 075, Runtime 0.022734, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 076, Runtime 0.026544, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 077, Runtime 0.023330, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 078, Runtime 0.021233, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 079, Runtime 0.022587, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 080, Runtime 0.022449, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 081, Runtime 0.023654, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 082, Runtime 0.023594, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 083, Runtime 0.030082, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 084, Runtime 0.023246, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 085, Runtime 0.024043, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 086, Runtime 0.026792, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 087, Runtime 0.026815, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 088, Runtime 0.046923, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 089, Runtime 0.023842, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 090, Runtime 0.031413, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 091, Runtime 0.024282, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 092, Runtime 0.038122, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 093, Runtime 0.022837, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 094, Runtime 0.026937, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 095, Runtime 0.023612, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 096, Runtime 0.023715, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 097, Runtime 0.021472, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 098, Runtime 0.021762, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 099, Runtime 0.028111, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948
Epoch: 100, Runtime 0.025239, Loss nan, Train: 0.1429, Val: 0.1364, Test: 0.1443, Best time: 18.2948

100%|████████████████████████████| 100/100 [00:03<00:00, 25.38it/s]