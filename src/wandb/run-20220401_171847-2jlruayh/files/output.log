GrandExtendDiscritizedNet
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
mol_list.0.alpha_train
torch.Size([])
mol_list.0.beta_train
torch.Size([])
mol_list.0.alpha_sc
torch.Size([1])
mol_list.0.beta_sc
torch.Size([1])
mol_list.0.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.0.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.V.bias
torch.Size([128])
mol_list.0.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.K.bias
torch.Size([128])
mol_list.0.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.0.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.1.alpha_train
torch.Size([])
mol_list.1.beta_train
torch.Size([])
mol_list.1.alpha_sc
torch.Size([1])
mol_list.1.beta_sc
torch.Size([1])
mol_list.1.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.1.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.V.bias
torch.Size([128])
mol_list.1.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.K.bias
torch.Size([128])
mol_list.1.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.1.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.2.alpha_train
torch.Size([])
mol_list.2.beta_train
torch.Size([])
mol_list.2.alpha_sc
torch.Size([1])
mol_list.2.beta_sc
torch.Size([1])
mol_list.2.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.2.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.V.bias
torch.Size([128])
mol_list.2.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.K.bias
torch.Size([128])
mol_list.2.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.2.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.3.alpha_train
torch.Size([])
mol_list.3.beta_train
torch.Size([])
mol_list.3.alpha_sc
torch.Size([1])
mol_list.3.beta_sc
torch.Size([1])
mol_list.3.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.3.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.V.bias
torch.Size([128])
mol_list.3.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.K.bias
torch.Size([128])
mol_list.3.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.3.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.4.alpha_train
torch.Size([])
mol_list.4.beta_train
torch.Size([])
mol_list.4.alpha_sc
torch.Size([1])
mol_list.4.beta_sc
torch.Size([1])
mol_list.4.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.4.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.V.bias
torch.Size([128])
mol_list.4.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.K.bias
torch.Size([128])
mol_list.4.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.4.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.5.alpha_train
torch.Size([])
mol_list.5.beta_train
torch.Size([])
mol_list.5.alpha_sc
torch.Size([1])
mol_list.5.beta_sc
torch.Size([1])
mol_list.5.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.5.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.5.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.5.multihead_att_layer.V.bias
torch.Size([128])
mol_list.5.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.5.multihead_att_layer.K.bias
torch.Size([128])
mol_list.5.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.5.multihead_att_layer.Wout.bias
torch.Size([80])
  0%|                                      | 0/100 [00:00<?, ?it/s]
Epoch: 001, Runtime 2.093302, Loss 1.949689, Train: 0.9086, Val: 0.4329, Test: 0.4887, Best time: 18.2948
Epoch: 002, Runtime 0.055765, Loss 1.737339, Train: 0.9429, Val: 0.4789, Test: 0.5526, Best time: 18.2948
Epoch: 003, Runtime 0.049829, Loss 1.423847, Train: 0.9486, Val: 0.4915, Test: 0.5464, Best time: 18.2948
Epoch: 004, Runtime 0.056333, Loss 1.119252, Train: 0.9600, Val: 0.5145, Test: 0.5546, Best time: 18.2948
Epoch: 005, Runtime 0.068972, Loss 0.789963, Train: 0.9600, Val: 0.5485, Test: 0.6000, Best time: 18.2948
Epoch: 006, Runtime 0.058382, Loss 0.564339, Train: 0.9600, Val: 0.5501, Test: 0.6082, Best time: 18.2948
Epoch: 007, Runtime 0.054507, Loss 0.550033, Train: 0.9657, Val: 0.5540, Test: 0.5959, Best time: 18.2948
Epoch: 008, Runtime 0.059419, Loss 0.471846, Train: 0.9771, Val: 0.5556, Test: 0.5959, Best time: 18.2948
Epoch: 009, Runtime 0.066457, Loss 0.435822, Train: 0.9829, Val: 0.5589, Test: 0.5938, Best time: 18.2948
Epoch: 010, Runtime 0.056638, Loss 0.450158, Train: 0.9829, Val: 0.5562, Test: 0.5856, Best time: 18.2948
Epoch: 011, Runtime 0.054335, Loss 0.429087, Train: 0.9829, Val: 0.5534, Test: 0.5814, Best time: 18.2948
Epoch: 012, Runtime 0.066404, Loss 0.388735, Train: 0.9829, Val: 0.5474, Test: 0.5856, Best time: 18.2948
Epoch: 013, Runtime 0.059810, Loss 0.391543, Train: 0.9829, Val: 0.5425, Test: 0.5856, Best time: 18.2948
Epoch: 014, Runtime 0.056066, Loss 0.437054, Train: 0.9829, Val: 0.5397, Test: 0.5794, Best time: 18.2948

 23%|██████▋                      | 23/100 [00:03<00:05, 15.30it/s]
Epoch: 016, Runtime 0.061916, Loss 0.396720, Train: 0.9829, Val: 0.5332, Test: 0.5732, Best time: 18.2948
Epoch: 017, Runtime 0.059321, Loss 0.381141, Train: 0.9829, Val: 0.5332, Test: 0.5691, Best time: 18.2948
Epoch: 018, Runtime 0.056459, Loss 0.407281, Train: 0.9829, Val: 0.5293, Test: 0.5670, Best time: 18.2948
Epoch: 019, Runtime 0.049493, Loss 0.372933, Train: 0.9829, Val: 0.5266, Test: 0.5649, Best time: 18.2948
Epoch: 020, Runtime 0.055820, Loss 0.368101, Train: 0.9829, Val: 0.5244, Test: 0.5649, Best time: 18.2948
Epoch: 021, Runtime 0.067964, Loss 0.361923, Train: 0.9829, Val: 0.5233, Test: 0.5629, Best time: 18.2948
Epoch: 022, Runtime 0.057190, Loss 0.377004, Train: 0.9829, Val: 0.5227, Test: 0.5608, Best time: 18.2948
Epoch: 023, Runtime 0.057009, Loss 0.335051, Train: 0.9829, Val: 0.5271, Test: 0.5629, Best time: 18.2948
Epoch: 024, Runtime 0.056486, Loss 0.354951, Train: 0.9829, Val: 0.5304, Test: 0.5608, Best time: 18.2948
Epoch: 025, Runtime 0.075561, Loss 0.362357, Train: 0.9829, Val: 0.5288, Test: 0.5588, Best time: 18.2948
Epoch: 026, Runtime 0.077411, Loss 0.359913, Train: 0.9829, Val: 0.5288, Test: 0.5546, Best time: 18.2948
Epoch: 027, Runtime 0.059657, Loss 0.346904, Train: 0.9829, Val: 0.5304, Test: 0.5505, Best time: 18.2948
Epoch: 028, Runtime 0.059126, Loss 0.329353, Train: 0.9829, Val: 0.5293, Test: 0.5546, Best time: 18.2948
Epoch: 029, Runtime 0.067446, Loss 0.291501, Train: 0.9829, Val: 0.5282, Test: 0.5567, Best time: 18.2948
Epoch: 030, Runtime 0.057474, Loss 0.366590, Train: 0.9829, Val: 0.5293, Test: 0.5649, Best time: 18.2948
Epoch: 031, Runtime 0.051352, Loss 0.387141, Train: 0.9829, Val: 0.5299, Test: 0.5649, Best time: 18.2948
Epoch: 032, Runtime 0.058515, Loss 0.341603, Train: 0.9829, Val: 0.5315, Test: 0.5711, Best time: 18.2948
Epoch: 033, Runtime 0.072269, Loss 0.365201, Train: 0.9829, Val: 0.5321, Test: 0.5732, Best time: 18.2948
Epoch: 034, Runtime 0.061337, Loss 0.313632, Train: 0.9829, Val: 0.5299, Test: 0.5753, Best time: 18.2948
Epoch: 035, Runtime 0.052392, Loss 0.336444, Train: 0.9829, Val: 0.5299, Test: 0.5691, Best time: 18.2948
Epoch: 036, Runtime 0.048684, Loss 0.306552, Train: 0.9829, Val: 0.5299, Test: 0.5711, Best time: 18.2948
Epoch: 037, Runtime 0.057348, Loss 0.333966, Train: 0.9829, Val: 0.5288, Test: 0.5670, Best time: 18.2948
Epoch: 038, Runtime 0.065418, Loss 0.336413, Train: 0.9829, Val: 0.5288, Test: 0.5608, Best time: 18.2948
Epoch: 039, Runtime 0.058274, Loss 0.352179, Train: 0.9829, Val: 0.5403, Test: 0.5794, Best time: 18.2948
Epoch: 040, Runtime 0.057889, Loss 0.305867, Train: 0.9829, Val: 0.5463, Test: 0.5856, Best time: 18.2948
Epoch: 041, Runtime 0.071858, Loss 0.299878, Train: 0.9829, Val: 0.5419, Test: 0.5835, Best time: 18.2948
Epoch: 042, Runtime 0.055656, Loss 0.265599, Train: 0.9829, Val: 0.5479, Test: 0.5897, Best time: 18.2948
Epoch: 043, Runtime 0.057252, Loss 0.275363, Train: 0.9829, Val: 0.5468, Test: 0.5918, Best time: 18.2948
Epoch: 044, Runtime 0.066740, Loss 0.245722, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 045, Runtime 0.057442, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 046, Runtime 0.052566, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 047, Runtime 0.055146, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948

 55%|███████████████▉             | 55/100 [00:05<00:02, 16.66it/s]
Epoch: 049, Runtime 0.059144, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 050, Runtime 0.056357, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 051, Runtime 0.049669, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 052, Runtime 0.060287, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 053, Runtime 0.067395, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 054, Runtime 0.060008, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 055, Runtime 0.057223, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 056, Runtime 0.071345, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 057, Runtime 0.068273, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 058, Runtime 0.052095, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 059, Runtime 0.048015, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 060, Runtime 0.057363, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 061, Runtime 0.073573, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 062, Runtime 0.074322, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 063, Runtime 0.059289, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 064, Runtime 0.048507, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 065, Runtime 0.059509, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 066, Runtime 0.071326, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 067, Runtime 0.056796, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 068, Runtime 0.050469, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 069, Runtime 0.051578, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 070, Runtime 0.061646, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 071, Runtime 0.065360, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 072, Runtime 0.052333, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 073, Runtime 0.059145, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 074, Runtime 0.070625, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 075, Runtime 0.057794, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 076, Runtime 0.057881, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 077, Runtime 0.067159, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 078, Runtime 0.057133, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 079, Runtime 0.049854, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 080, Runtime 0.049603, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 081, Runtime 0.048149, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 082, Runtime 0.052307, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948


100%|████████████████████████████| 100/100 [00:08<00:00, 12.26it/s]
Epoch: 084, Runtime 0.180405, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 085, Runtime 0.052051, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 086, Runtime 0.076309, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 087, Runtime 0.055890, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 088, Runtime 0.051863, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 089, Runtime 0.080977, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 090, Runtime 0.052872, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 091, Runtime 0.073346, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 092, Runtime 0.057621, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 093, Runtime 0.048308, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 094, Runtime 0.048527, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 095, Runtime 0.059126, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 096, Runtime 0.067326, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 097, Runtime 0.054628, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 098, Runtime 0.057680, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 099, Runtime 0.049595, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
Epoch: 100, Runtime 0.057195, Loss nan, Train: 0.1429, Val: 0.1447, Test: 0.1134, Best time: 18.2948
best val accuracy 0.144658 with test accuracy 0.113402 at epoch 9 and best time 18.294754