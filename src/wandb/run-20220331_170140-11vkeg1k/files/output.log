
  0%|                                                                                                          | 0/100 [00:00<?, ?it/s]
GrandExtendDiscritizedNet
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
mol_list.0.alpha_train
torch.Size([])
mol_list.0.beta_train
torch.Size([])
mol_list.0.alpha_sc
torch.Size([1])
mol_list.0.beta_sc
torch.Size([1])
mol_list.0.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.0.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.V.bias
torch.Size([128])
mol_list.0.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.K.bias
torch.Size([128])
mol_list.0.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.0.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.1.alpha_train
torch.Size([])
mol_list.1.beta_train
torch.Size([])
mol_list.1.alpha_sc
torch.Size([1])
mol_list.1.beta_sc
torch.Size([1])
mol_list.1.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.1.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.V.bias
torch.Size([128])
mol_list.1.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.K.bias
torch.Size([128])
mol_list.1.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.1.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.2.alpha_train
torch.Size([])
mol_list.2.beta_train
torch.Size([])
mol_list.2.alpha_sc
torch.Size([1])
mol_list.2.beta_sc
torch.Size([1])
mol_list.2.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.2.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.V.bias
torch.Size([128])
mol_list.2.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.K.bias
torch.Size([128])
mol_list.2.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.2.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.3.alpha_train
torch.Size([])
mol_list.3.beta_train
torch.Size([])
mol_list.3.alpha_sc
torch.Size([1])
mol_list.3.beta_sc
torch.Size([1])
mol_list.3.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.3.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.V.bias
torch.Size([128])
mol_list.3.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.K.bias
torch.Size([128])
mol_list.3.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.3.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.4.alpha_train
torch.Size([])
mol_list.4.beta_train
torch.Size([])
mol_list.4.alpha_sc
torch.Size([1])
mol_list.4.beta_sc
torch.Size([1])
mol_list.4.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.4.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.V.bias
torch.Size([128])
mol_list.4.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.K.bias
torch.Size([128])
mol_list.4.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.4.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.5.alpha_train
torch.Size([])
mol_list.5.beta_train
torch.Size([])
mol_list.5.alpha_sc
torch.Size([1])
mol_list.5.beta_sc
torch.Size([1])
mol_list.5.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.5.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.5.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.5.multihead_att_layer.V.bias
torch.Size([128])
mol_list.5.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.5.multihead_att_layer.K.bias
torch.Size([128])
mol_list.5.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.5.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.6.alpha_train
torch.Size([])
mol_list.6.beta_train
torch.Size([])
mol_list.6.alpha_sc
torch.Size([1])
mol_list.6.beta_sc
torch.Size([1])
mol_list.6.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.6.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.6.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.6.multihead_att_layer.V.bias
torch.Size([128])
mol_list.6.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.6.multihead_att_layer.K.bias
torch.Size([128])
mol_list.6.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.6.multihead_att_layer.Wout.bias

 39%|█████████████████████████████████████▊                                                           | 39/100 [00:03<00:03, 19.05it/s]
Epoch: 001, Runtime 1.394022, Loss 1.943383, Train: 0.8629, Val: 0.3090, Test: 0.3464, Best time: 18.2948
Epoch: 002, Runtime 0.047566, Loss 1.719997, Train: 0.9257, Val: 0.3540, Test: 0.3794, Best time: 18.2948
Epoch: 003, Runtime 0.048245, Loss 1.446933, Train: 0.9486, Val: 0.4400, Test: 0.4577, Best time: 18.2948
Epoch: 004, Runtime 0.046342, Loss 1.108397, Train: 0.9714, Val: 0.4948, Test: 0.5031, Best time: 18.2948
Epoch: 005, Runtime 0.047595, Loss 0.777867, Train: 0.9771, Val: 0.5392, Test: 0.5608, Best time: 18.2948
Epoch: 006, Runtime 0.044891, Loss 0.523651, Train: 0.9829, Val: 0.5638, Test: 0.5856, Best time: 18.2948
Epoch: 007, Runtime 0.045296, Loss 0.417149, Train: 1.0000, Val: 0.5852, Test: 0.5876, Best time: 18.2948
Epoch: 008, Runtime 0.046561, Loss 0.266472, Train: 1.0000, Val: 0.5973, Test: 0.6041, Best time: 18.2948
Epoch: 009, Runtime 0.048746, Loss 0.290462, Train: 1.0000, Val: 0.5973, Test: 0.6144, Best time: 18.2948
Epoch: 010, Runtime 0.047007, Loss 0.245622, Train: 1.0000, Val: 0.5973, Test: 0.6021, Best time: 18.2948
Epoch: 011, Runtime 0.077973, Loss 0.182679, Train: 1.0000, Val: 0.5923, Test: 0.5979, Best time: 18.2948
Epoch: 012, Runtime 0.045690, Loss 0.179562, Train: 1.0000, Val: 0.5726, Test: 0.5753, Best time: 18.2948
Epoch: 013, Runtime 0.040470, Loss 0.111122, Train: 1.0000, Val: 0.5584, Test: 0.5629, Best time: 18.2948
Epoch: 014, Runtime 0.042149, Loss 0.126686, Train: 1.0000, Val: 0.5551, Test: 0.5464, Best time: 18.2948
Epoch: 015, Runtime 0.047797, Loss 0.170493, Train: 1.0000, Val: 0.5518, Test: 0.5402, Best time: 18.2948
Epoch: 016, Runtime 0.053158, Loss 0.127778, Train: 1.0000, Val: 0.5501, Test: 0.5402, Best time: 18.2948
Epoch: 017, Runtime 0.049188, Loss 0.208327, Train: 1.0000, Val: 0.5452, Test: 0.5443, Best time: 18.2948
Epoch: 018, Runtime 0.045413, Loss 0.171880, Train: 1.0000, Val: 0.5496, Test: 0.5464, Best time: 18.2948
Epoch: 019, Runtime 0.048790, Loss 0.141112, Train: 1.0000, Val: 0.5600, Test: 0.5629, Best time: 18.2948
Epoch: 020, Runtime 0.046146, Loss 0.177204, Train: 1.0000, Val: 0.5732, Test: 0.5711, Best time: 18.2948
Epoch: 021, Runtime 0.052754, Loss 0.156422, Train: 1.0000, Val: 0.5808, Test: 0.5938, Best time: 18.2948
Epoch: 022, Runtime 0.047307, Loss 0.133832, Train: 1.0000, Val: 0.5781, Test: 0.6021, Best time: 18.2948
Epoch: 023, Runtime 0.046285, Loss 0.187612, Train: 1.0000, Val: 0.5770, Test: 0.6041, Best time: 18.2948
Epoch: 024, Runtime 0.049455, Loss 0.154915, Train: 1.0000, Val: 0.5759, Test: 0.5979, Best time: 18.2948
Epoch: 025, Runtime 0.050392, Loss 0.221255, Train: 1.0000, Val: 0.5644, Test: 0.5835, Best time: 18.2948
Epoch: 026, Runtime 0.050145, Loss 0.180067, Train: 1.0000, Val: 0.5534, Test: 0.5794, Best time: 18.2948
Epoch: 027, Runtime 0.046654, Loss 0.224370, Train: 1.0000, Val: 0.5370, Test: 0.5732, Best time: 18.2948
Epoch: 028, Runtime 0.046939, Loss 0.169619, Train: 1.0000, Val: 0.5403, Test: 0.5711, Best time: 18.2948
Epoch: 029, Runtime 0.044147, Loss 0.196411, Train: 1.0000, Val: 0.5375, Test: 0.5649, Best time: 18.2948
Epoch: 030, Runtime 0.047012, Loss 0.199378, Train: 1.0000, Val: 0.5441, Test: 0.5711, Best time: 18.2948
Epoch: 031, Runtime 0.046773, Loss 0.175443, Train: 1.0000, Val: 0.5523, Test: 0.5814, Best time: 18.2948
Epoch: 032, Runtime 0.058600, Loss 0.141213, Train: 1.0000, Val: 0.5699, Test: 0.5918, Best time: 18.2948
Epoch: 033, Runtime 0.052018, Loss 0.155255, Train: 1.0000, Val: 0.5847, Test: 0.5794, Best time: 18.2948
Epoch: 034, Runtime 0.052674, Loss 0.162897, Train: 1.0000, Val: 0.5940, Test: 0.5835, Best time: 18.2948
Epoch: 035, Runtime 0.048185, Loss 0.147038, Train: 1.0000, Val: 0.5973, Test: 0.5918, Best time: 18.2948
Epoch: 036, Runtime 0.049150, Loss 0.217080, Train: 1.0000, Val: 0.5984, Test: 0.5959, Best time: 18.2948
Epoch: 037, Runtime 0.050788, Loss 0.192065, Train: 1.0000, Val: 0.5907, Test: 0.5918, Best time: 18.2948
Epoch: 038, Runtime 0.050974, Loss 0.189438, Train: 1.0000, Val: 0.5819, Test: 0.5835, Best time: 18.2948
Epoch: 039, Runtime 0.055733, Loss 0.140545, Train: 1.0000, Val: 0.5677, Test: 0.5876, Best time: 18.2948
Epoch: 040, Runtime 0.049899, Loss 0.151867, Train: 1.0000, Val: 0.5567, Test: 0.5670, Best time: 18.2948
Epoch: 041, Runtime 0.056977, Loss 0.175629, Train: 1.0000, Val: 0.5485, Test: 0.5588, Best time: 18.2948
Epoch: 042, Runtime 0.045026, Loss 0.180838, Train: 1.0000, Val: 0.5523, Test: 0.5588, Best time: 18.2948
Epoch: 043, Runtime 0.047821, Loss 0.191172, Train: 1.0000, Val: 0.5512, Test: 0.5608, Best time: 18.2948
Epoch: 044, Runtime 0.045630, Loss 0.169987, Train: 1.0000, Val: 0.5573, Test: 0.5546, Best time: 18.2948
Epoch: 045, Runtime 0.043459, Loss 0.155456, Train: 1.0000, Val: 0.5534, Test: 0.5505, Best time: 18.2948
Epoch: 046, Runtime 0.046217, Loss 0.141491, Train: 1.0000, Val: 0.5518, Test: 0.5588, Best time: 18.2948
Epoch: 047, Runtime 0.048353, Loss 0.168789, Train: 1.0000, Val: 0.5545, Test: 0.5546, Best time: 18.2948
Epoch: 048, Runtime 0.047543, Loss 0.146544, Train: 1.0000, Val: 0.5578, Test: 0.5629, Best time: 18.2948
Epoch: 049, Runtime 0.046742, Loss 0.160468, Train: 1.0000, Val: 0.5545, Test: 0.5629, Best time: 18.2948
Epoch: 050, Runtime 0.048151, Loss 0.153213, Train: 1.0000, Val: 0.5518, Test: 0.5608, Best time: 18.2948
Epoch: 051, Runtime 0.077626, Loss 0.148885, Train: 1.0000, Val: 0.5518, Test: 0.5732, Best time: 18.2948
Epoch: 052, Runtime 0.048645, Loss 0.180646, Train: 1.0000, Val: 0.5512, Test: 0.5835, Best time: 18.2948
Epoch: 053, Runtime 0.046830, Loss 0.155520, Train: 1.0000, Val: 0.5474, Test: 0.5691, Best time: 18.2948
Epoch: 054, Runtime 0.046545, Loss 0.131134, Train: 1.0000, Val: 0.5468, Test: 0.5649, Best time: 18.2948
Epoch: 055, Runtime 0.046817, Loss 0.183197, Train: 1.0000, Val: 0.5452, Test: 0.5546, Best time: 18.2948
Epoch: 056, Runtime 0.045562, Loss 0.160276, Train: 1.0000, Val: 0.5403, Test: 0.5464, Best time: 18.2948
Epoch: 057, Runtime 0.048589, Loss 0.140640, Train: 1.0000, Val: 0.5332, Test: 0.5505, Best time: 18.2948
Epoch: 058, Runtime 0.049581, Loss 0.177010, Train: 1.0000, Val: 0.5315, Test: 0.5464, Best time: 18.2948
Epoch: 059, Runtime 0.046705, Loss 0.155598, Train: 1.0000, Val: 0.5304, Test: 0.5485, Best time: 18.2948
Epoch: 060, Runtime 0.043949, Loss 0.138908, Train: 1.0000, Val: 0.5337, Test: 0.5505, Best time: 18.2948
Epoch: 061, Runtime 0.049945, Loss 0.162175, Train: 1.0000, Val: 0.5452, Test: 0.5546, Best time: 18.2948
Epoch: 062, Runtime 0.058399, Loss 0.152840, Train: 1.0000, Val: 0.5474, Test: 0.5505, Best time: 18.2948
Epoch: 063, Runtime 0.046913, Loss 0.108715, Train: 1.0000, Val: 0.5518, Test: 0.5443, Best time: 18.2948
Epoch: 064, Runtime 0.045870, Loss 0.149241, Train: 1.0000, Val: 0.5551, Test: 0.5546, Best time: 18.2948
Epoch: 065, Runtime 0.054969, Loss 0.162730, Train: 1.0000, Val: 0.5595, Test: 0.5588, Best time: 18.2948
Epoch: 066, Runtime 0.042511, Loss 0.158472, Train: 1.0000, Val: 0.5644, Test: 0.5691, Best time: 18.2948
Epoch: 067, Runtime 0.044421, Loss 0.167604, Train: 1.0000, Val: 0.5726, Test: 0.5691, Best time: 18.2948
Epoch: 068, Runtime 0.047480, Loss 0.138819, Train: 1.0000, Val: 0.5748, Test: 0.5732, Best time: 18.2948
Epoch: 069, Runtime 0.048497, Loss 0.156177, Train: 1.0000, Val: 0.5803, Test: 0.5691, Best time: 18.2948
Epoch: 070, Runtime 0.040821, Loss 0.154960, Train: 1.0000, Val: 0.5737, Test: 0.5649, Best time: 18.2948
Epoch: 071, Runtime 0.043545, Loss 0.162608, Train: 1.0000, Val: 0.5704, Test: 0.5567, Best time: 18.2948
Epoch: 072, Runtime 0.178090, Loss 0.108326, Train: 1.0000, Val: 0.5644, Test: 0.5546, Best time: 18.2948
Epoch: 073, Runtime 0.046485, Loss 0.139629, Train: 1.0000, Val: 0.5584, Test: 0.5526, Best time: 18.2948
Epoch: 074, Runtime 0.045286, Loss 0.124989, Train: 1.0000, Val: 0.5501, Test: 0.5464, Best time: 18.2948
Epoch: 075, Runtime 0.051461, Loss 0.156077, Train: 1.0000, Val: 0.5425, Test: 0.5340, Best time: 18.2948
Epoch: 076, Runtime 0.044595, Loss 0.112925, Train: 1.0000, Val: 0.5332, Test: 0.5196, Best time: 18.2948
Epoch: 077, Runtime 0.044392, Loss 0.124351, Train: 1.0000, Val: 0.5288, Test: 0.5216, Best time: 18.2948
Epoch: 078, Runtime 0.047133, Loss 0.148375, Train: 1.0000, Val: 0.5238, Test: 0.5237, Best time: 18.2948
Epoch: 079, Runtime 0.045119, Loss 0.142822, Train: 1.0000, Val: 0.5277, Test: 0.5258, Best time: 18.2948
Epoch: 080, Runtime 0.049863, Loss 0.129753, Train: 1.0000, Val: 0.5342, Test: 0.5361, Best time: 18.2948
Epoch: 081, Runtime 0.046796, Loss 0.181333, Train: 1.0000, Val: 0.5419, Test: 0.5381, Best time: 18.2948

 77%|██████████████████████████████████████████████████████████████████████████▋                      | 77/100 [00:05<00:01, 17.66it/s]
Epoch: 083, Runtime 0.055050, Loss 0.136159, Train: 1.0000, Val: 0.5551, Test: 0.5526, Best time: 18.2948
Epoch: 084, Runtime 0.042485, Loss 0.141919, Train: 1.0000, Val: 0.5611, Test: 0.5546, Best time: 18.2948
Epoch: 085, Runtime 0.049123, Loss 0.149656, Train: 1.0000, Val: 0.5671, Test: 0.5608, Best time: 18.2948
Epoch: 086, Runtime 0.046283, Loss 0.173364, Train: 1.0000, Val: 0.5732, Test: 0.5649, Best time: 18.2948
Epoch: 087, Runtime 0.063325, Loss 0.173792, Train: 1.0000, Val: 0.5759, Test: 0.5753, Best time: 18.2948
Epoch: 088, Runtime 0.045595, Loss 0.148092, Train: 1.0000, Val: 0.5764, Test: 0.5753, Best time: 18.2948
Epoch: 089, Runtime 0.044567, Loss 0.158263, Train: 1.0000, Val: 0.5742, Test: 0.5773, Best time: 18.2948
Epoch: 090, Runtime 0.067267, Loss 0.170253, Train: 1.0000, Val: 0.5770, Test: 0.5670, Best time: 18.2948
Epoch: 091, Runtime 0.049642, Loss 0.135101, Train: 1.0000, Val: 0.5715, Test: 0.5649, Best time: 18.2948
Epoch: 092, Runtime 0.045597, Loss 0.165053, Train: 1.0000, Val: 0.5638, Test: 0.5629, Best time: 18.2948
Epoch: 093, Runtime 0.054644, Loss 0.139067, Train: 1.0000, Val: 0.5611, Test: 0.5588, Best time: 18.2948
Epoch: 094, Runtime 0.048494, Loss 0.155832, Train: 1.0000, Val: 0.5611, Test: 0.5608, Best time: 18.2948
Epoch: 095, Runtime 0.046740, Loss 0.120685, Train: 1.0000, Val: 0.5589, Test: 0.5567, Best time: 18.2948
Epoch: 096, Runtime 0.047695, Loss 0.188526, Train: 1.0000, Val: 0.5611, Test: 0.5526, Best time: 18.2948
Epoch: 097, Runtime 0.048880, Loss 0.168638, Train: 1.0000, Val: 0.5567, Test: 0.5423, Best time: 18.2948
Epoch: 098, Runtime 0.046366, Loss 0.140481, Train: 1.0000, Val: 0.5584, Test: 0.5361, Best time: 18.2948
Epoch: 099, Runtime 0.047272, Loss 0.142793, Train: 1.0000, Val: 0.5600, Test: 0.5340, Best time: 18.2948
Epoch: 100, Runtime 0.063987, Loss 0.169130, Train: 1.0000, Val: 0.5578, Test: 0.5443, Best time: 18.2948

100%|████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:06<00:00, 15.54it/s]