GrandExtendDiscritizedNet
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
mol_list.0.alpha_train
torch.Size([])
mol_list.0.beta_train
torch.Size([])
mol_list.0.alpha_sc
torch.Size([1])
mol_list.0.beta_sc
torch.Size([1])
mol_list.0.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.0.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.V.bias
torch.Size([128])
mol_list.0.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.0.multihead_att_layer.K.bias
torch.Size([128])
mol_list.0.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.0.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.1.alpha_train
torch.Size([])
mol_list.1.beta_train
torch.Size([])
mol_list.1.alpha_sc
torch.Size([1])
mol_list.1.beta_sc
torch.Size([1])
mol_list.1.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.1.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.V.bias
torch.Size([128])
mol_list.1.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.1.multihead_att_layer.K.bias
torch.Size([128])
mol_list.1.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.1.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.2.alpha_train
torch.Size([])
mol_list.2.beta_train
torch.Size([])
mol_list.2.alpha_sc
torch.Size([1])
mol_list.2.beta_sc
torch.Size([1])
mol_list.2.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.2.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.V.bias
torch.Size([128])
mol_list.2.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.2.multihead_att_layer.K.bias
torch.Size([128])
mol_list.2.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.2.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.3.alpha_train
torch.Size([])
mol_list.3.beta_train
torch.Size([])
mol_list.3.alpha_sc
torch.Size([1])
mol_list.3.beta_sc
torch.Size([1])
mol_list.3.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.3.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.V.bias
torch.Size([128])
mol_list.3.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.3.multihead_att_layer.K.bias
torch.Size([128])
mol_list.3.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.3.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.4.alpha_train
torch.Size([])
mol_list.4.beta_train
torch.Size([])
mol_list.4.alpha_sc
torch.Size([1])
mol_list.4.beta_sc
torch.Size([1])
mol_list.4.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.4.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.V.bias
torch.Size([128])
mol_list.4.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.4.multihead_att_layer.K.bias
torch.Size([128])
mol_list.4.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.4.multihead_att_layer.Wout.bias
torch.Size([80])
mol_list.5.alpha_train
torch.Size([])
mol_list.5.beta_train
torch.Size([])
mol_list.5.alpha_sc
torch.Size([1])
mol_list.5.beta_sc
torch.Size([1])
mol_list.5.multihead_att_layer.Q.weight
torch.Size([128, 80])
mol_list.5.multihead_att_layer.Q.bias
torch.Size([128])
mol_list.5.multihead_att_layer.V.weight
torch.Size([128, 80])
mol_list.5.multihead_att_layer.V.bias
torch.Size([128])
mol_list.5.multihead_att_layer.K.weight
torch.Size([128, 80])
mol_list.5.multihead_att_layer.K.bias
torch.Size([128])
mol_list.5.multihead_att_layer.Wout.weight
torch.Size([80, 16])
mol_list.5.multihead_att_layer.Wout.bias
torch.Size([80])

 28%|████████                     | 28/100 [00:02<00:03, 21.15it/s]
Epoch: 001, Runtime 1.443822, Loss 1.948545, Train: 0.8400, Val: 0.5019, Test: 0.4722, Best time: 18.2948
Epoch: 002, Runtime 0.045977, Loss 1.794461, Train: 0.8971, Val: 0.7430, Test: 0.7320, Best time: 18.2948
Epoch: 003, Runtime 0.041676, Loss 1.569759, Train: 0.9257, Val: 0.7945, Test: 0.7856, Best time: 18.2948
Epoch: 004, Runtime 0.042282, Loss 1.366277, Train: 0.9314, Val: 0.8055, Test: 0.8124, Best time: 18.2948
Epoch: 005, Runtime 0.039325, Loss 1.154929, Train: 0.9314, Val: 0.8027, Test: 0.8268, Best time: 18.2948
Epoch: 006, Runtime 0.039809, Loss 0.931033, Train: 0.9257, Val: 0.8088, Test: 0.8268, Best time: 18.2948
Epoch: 007, Runtime 0.046723, Loss 0.667213, Train: 0.7314, Val: 0.7162, Test: 0.6804, Best time: 18.2948
Epoch: 008, Runtime 0.039715, Loss 12.920851, Train: 0.9371, Val: 0.8164, Test: 0.8309, Best time: 18.2948
Epoch: 009, Runtime 0.039921, Loss 0.517862, Train: 0.9429, Val: 0.8077, Test: 0.8227, Best time: 18.2948
Epoch: 010, Runtime 0.040016, Loss 0.622494, Train: 0.9543, Val: 0.7923, Test: 0.8144, Best time: 18.2948
Epoch: 011, Runtime 0.039975, Loss 0.752886, Train: 0.9429, Val: 0.7808, Test: 0.8041, Best time: 18.2948
Epoch: 012, Runtime 0.040745, Loss 0.862015, Train: 0.9371, Val: 0.7737, Test: 0.7856, Best time: 18.2948
Epoch: 013, Runtime 0.039987, Loss 0.982837, Train: 0.9314, Val: 0.7545, Test: 0.7608, Best time: 18.2948
Epoch: 014, Runtime 0.038752, Loss 1.070393, Train: 0.8800, Val: 0.7332, Test: 0.7381, Best time: 18.2948
Epoch: 015, Runtime 0.041795, Loss 1.171375, Train: 0.8743, Val: 0.7282, Test: 0.7299, Best time: 18.2948
Epoch: 016, Runtime 0.039369, Loss 1.275913, Train: 0.8629, Val: 0.7348, Test: 0.7155, Best time: 18.2948
Epoch: 017, Runtime 0.047114, Loss 1.352368, Train: 0.8343, Val: 0.7375, Test: 0.7278, Best time: 18.2948
Epoch: 018, Runtime 0.041324, Loss 1.425743, Train: 0.8114, Val: 0.7277, Test: 0.7113, Best time: 18.2948
Epoch: 019, Runtime 0.045771, Loss 1.506062, Train: 0.7829, Val: 0.7479, Test: 0.7278, Best time: 18.2948
Epoch: 020, Runtime 0.038010, Loss 1.511108, Train: 0.7543, Val: 0.7299, Test: 0.7072, Best time: 18.2948
Epoch: 021, Runtime 0.037507, Loss 2.102949, Train: 0.7371, Val: 0.7123, Test: 0.6845, Best time: 18.2948
Epoch: 022, Runtime 0.038602, Loss 19.724718, Train: 0.7200, Val: 0.7058, Test: 0.6887, Best time: 18.2948
Epoch: 023, Runtime 0.040395, Loss 1.739039, Train: 0.7143, Val: 0.6992, Test: 0.6784, Best time: 18.2948
Epoch: 024, Runtime 0.036795, Loss 2.791291, Train: 0.7086, Val: 0.6937, Test: 0.6619, Best time: 18.2948
Epoch: 025, Runtime 0.040502, Loss 1.795384, Train: 0.6914, Val: 0.6860, Test: 0.6474, Best time: 18.2948
Epoch: 026, Runtime 0.039740, Loss 1.651906, Train: 0.6800, Val: 0.6778, Test: 0.6371, Best time: 18.2948
Epoch: 027, Runtime 0.045625, Loss 1.912825, Train: 0.6800, Val: 0.6647, Test: 0.6227, Best time: 18.2948
Epoch: 028, Runtime 0.040515, Loss 2.151078, Train: 0.6743, Val: 0.6526, Test: 0.6144, Best time: 18.2948
Epoch: 029, Runtime 0.042101, Loss 2.096119, Train: 0.5086, Val: 0.5068, Test: 0.4619, Best time: 18.2948

 73%|█████████████████████▏       | 73/100 [00:04<00:01, 21.31it/s]
Epoch: 031, Runtime 0.048909, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 032, Runtime 0.039945, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 033, Runtime 0.041298, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 034, Runtime 0.044356, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 035, Runtime 0.035593, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 036, Runtime 0.040615, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 037, Runtime 0.039541, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 038, Runtime 0.040692, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 039, Runtime 0.046866, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 040, Runtime 0.043748, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 041, Runtime 0.041341, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 042, Runtime 0.064708, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 043, Runtime 0.057660, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 044, Runtime 0.041866, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 045, Runtime 0.048284, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 046, Runtime 0.043223, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 047, Runtime 0.042165, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 048, Runtime 0.043684, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 049, Runtime 0.044519, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 050, Runtime 0.041956, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 051, Runtime 0.042969, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 052, Runtime 0.046145, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 053, Runtime 0.054138, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 054, Runtime 0.043658, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 055, Runtime 0.040697, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 056, Runtime 0.040157, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 057, Runtime 0.044121, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 058, Runtime 0.049771, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 059, Runtime 0.041623, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 060, Runtime 0.041816, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 061, Runtime 0.040661, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 062, Runtime 0.040784, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 063, Runtime 0.043359, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 064, Runtime 0.056108, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 065, Runtime 0.049803, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 066, Runtime 0.044574, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 067, Runtime 0.045203, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 068, Runtime 0.044725, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 069, Runtime 0.045404, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 070, Runtime 0.043446, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 071, Runtime 0.056657, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 072, Runtime 0.044164, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 073, Runtime 0.043417, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948

100%|████████████████████████████| 100/100 [00:06<00:00, 16.39it/s]
Epoch: 075, Runtime 0.051699, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 076, Runtime 0.044218, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 077, Runtime 0.043051, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 078, Runtime 0.042805, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 079, Runtime 0.051362, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 080, Runtime 0.052974, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 081, Runtime 0.052595, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 082, Runtime 0.045928, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 083, Runtime 0.046820, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 084, Runtime 0.041738, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 085, Runtime 0.272130, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 086, Runtime 0.039632, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 087, Runtime 0.043827, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 088, Runtime 0.043054, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 089, Runtime 0.041995, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 090, Runtime 0.047983, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 091, Runtime 0.043916, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 092, Runtime 0.042147, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 093, Runtime 0.040985, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 094, Runtime 0.040518, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 095, Runtime 0.046749, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 096, Runtime 0.041487, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 097, Runtime 0.035688, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 098, Runtime 0.045523, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 099, Runtime 0.041936, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
Epoch: 100, Runtime 0.042299, Loss nan, Train: 0.1429, Val: 0.1381, Test: 0.1381, Best time: 18.2948
best val accuracy 0.138082 with test accuracy 0.138144 at epoch 8 and best time 18.294754